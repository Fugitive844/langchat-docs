import{_ as a,c as s,o as i,ag as l}from"./chunks/framework.ByciF0Oj.js";const g=JSON.parse('{"title":"模型选择","description":"","frontmatter":{"title":"模型选择"},"headers":[],"relativePath":"course/docs/01Models.md","filePath":"course/docs/01Models.md","lastUpdated":1738637454000}'),e={name:"course/docs/01Models.md"};function n(d,t,r,h,o,p){return i(),s("div",null,t[0]||(t[0]=[l(`<ul><li><p>本系列课程以 <a href="https://bailian.console.aliyun.com/" target="_blank" rel="noreferrer">阿里百炼平台</a>为主，辅以Ollama本地模型，同时也适用于其他模型，提供更广泛的适用性和灵活性。</p></li><li><p>所有调用均基于 OpenAI 协议标准，实现一致的接口设计与规范，确保多模型切换的便利性，提供高度可扩展的开发支持</p></li></ul><table tabindex="0"><thead><tr><th>模型供应商</th><th>主要特点</th><th>优势</th><th>备注</th></tr></thead><tbody><tr><td><strong>OpenAI</strong></td><td>GPT系列（如GPT-4），具备强大的文本生成与理解能力</td><td>灵活性高，适用于多种应用场景。YYDS 大模型界的事实标准</td><td>暂停对国服的API服务，需要通过 Azure 接入</td></tr><tr><td><strong>阿里百炼</strong></td><td>提供多种大模型服务（如通义千问系列）</td><td>性能接近GPT-4，API价格较低，支持企业迁移解决方案</td><td>主要面向企业用户<br>所有新用户可获得超过5000万Tokens的免费额度及4500张图片生成额度，以鼓励更多企业使用。</td></tr><tr><td><strong>DeepSeek</strong></td><td>开源大模型，支持多语言</td><td>推理与编码任务表现优异，社区活跃，支持多样化应用</td><td>性价比高，输入价格（缓存命中）:<br>缓存未命中）:1元/百万Tokens <br> <strong>敏感词封号严重</strong></td></tr><tr><td><strong>智谱清言</strong></td><td>基于GLM架构，支持多轮对话与复杂指令处理</td><td>指令理解能力强，支持多场景下的定制化解决方案</td><td>模型全面；在国庆月特别活动中，智谱清言宣布用户可以以最低1折调用所有模型，并每位用户将获赠1亿Tokens的额度</td></tr><tr><td><strong>硅基流动</strong></td><td>专注于AI基础设施，提供SiliconCloud平台</td><td>高效推理，多模态支持，降低使用门槛，提升开发效率</td><td>主要面向技术开发者。提供了一系列开源大模型的API服务，其中多个开源大模型如Qwen2、GLM4和Yi1.5均为永久免费，这使得开发者可以自由使用这些模型进行应用开发，而无需承担费用</td></tr><tr><td><strong>Ollama</strong></td><td>支持本地部署，集成多种开源模型，隐私保护优先</td><td>强调用户隐私和自主性</td><td>需要较高的硬件配置以支持本地部署</td></tr></tbody></table><h2 id="ollama-上手" tabindex="-1">Ollama 上手 <a class="header-anchor" href="#ollama-上手" aria-label="Permalink to &quot;Ollama 上手&quot;">​</a></h2><h3 id="安装ollama" tabindex="-1">安装Ollama <a class="header-anchor" href="#安装ollama" aria-label="Permalink to &quot;安装Ollama&quot;">​</a></h3><ol><li><p><strong>下载Ollama</strong></p><ul><li>访问Ollama官网（<a href="https://ollama.com" target="_blank" rel="noreferrer">https://ollama.com</a>），选择适合您操作系统的版本进行下载。</li></ul></li><li><p><strong>安装Ollama</strong></p><ul><li>双击下载的安装包，按照提示完成安装过程。</li></ul></li></ol><h3 id="下载和运行模型" tabindex="-1">下载和运行模型 <a class="header-anchor" href="#下载和运行模型" aria-label="Permalink to &quot;下载和运行模型&quot;">​</a></h3><ol><li><strong>查看可用模型</strong>， 使用以下命令列出所有可用的模型：</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> list</span></span></code></pre></div><ol start="2"><li><strong>下载并运行模型</strong><ul><li>例如，要运行名为<code>qwen2.5</code>的模型，可以输入：</li></ul></li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> qwen2.5:14b</span></span></code></pre></div><ol start="3"><li><strong>与模型交互</strong><ul><li>模型运行后，您可以在终端中输入问题或指令，与模型进行交互，例如输入“北京美食推荐”。</li></ul></li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">lengleng@huawei</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ~</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> qwen2.5:14b</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;&gt;&gt; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Send</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> a</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> message</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (/? </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">for</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> help</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>国内大模型市场中，阿里通义系列无疑是首选，属于第一梯队。</p><p>尽管DeepSeek系列在价格和推理效率方面具备较高性价比，但其模型的全面性不及阿里云提供的服务。</p><p>阿里通义不仅覆盖了文本生成，还在向量、图形、视觉、声音等多模态领域表现出色，提供了更广泛的应用支持</p>`,16)]))}const c=a(e,[["render",n]]);export{g as __pageData,c as default};
