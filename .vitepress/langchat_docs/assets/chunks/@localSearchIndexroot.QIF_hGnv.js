const e='{"documentCount":162,"nextId":162,"documentIds":{"0":"/langchat/docs/deepseek-r1-distilled-models.html#deepseek-r1蒸馏模型","1":"/langchat/docs/deepseek-r1-distilled-models.html#_1、什么是蒸馏","2":"/langchat/docs/deepseek-r1-distilled-models.html#_2、deepseek-r1-蒸馏模型","3":"/langchat/docs/deepseek-r1-distilled-models.html#_2-1-蒸馏的目的","4":"/langchat/docs/deepseek-r1-distilled-models.html#_2-2-蒸馏过程","5":"/langchat/docs/deepseek-r1-distilled-models.html#_2-3-蒸馏模型变体","6":"/langchat/docs/deepseek-r1-distilled-models.html#_2-4-蒸馏模型的性能","7":"/langchat/docs/deepseek-r1-distilled-models.html#_2-5-蒸馏模型的优势","8":"/langchat/docs/deepseek-r1-distilled-models.html#_2-6-与-rl-训练模型的比较","9":"/langchat/docs/deepseek-r1-distilled-models.html#_3、使用-deepseek-r1-蒸馏模型","10":"/langchat/docs/deepseek-r1-distilled-models.html#_3-1-使用-ollama","11":"/langchat/docs/deepseek-r1-distilled-models.html#_3-2-使用-vllm","12":"/langchat/docs/deepseek-r1-distilled-models.html#_4、结束语","13":"/langchat/docs/deepseek-r1-architecture-and-training.html#deepseek-r1架构和训练过程图解","14":"/langchat/docs/deepseek-r1-architecture-and-training.html#_1、快速概览","15":"/langchat/docs/deepseek-r1-architecture-and-training.html#_2、deepseek-v3-moe-如何思考","16":"/langchat/docs/deepseek-r1-architecture-and-training.html#_3、deepseek-v3-作为-rl-设置中的策略模型","17":"/langchat/docs/deepseek-r1-architecture-and-training.html#_4、grpo-算法如何工作","18":"/langchat/docs/deepseek-r1-architecture-and-training.html#_5、grpo-的目标函数","19":"/langchat/docs/deepseek-r1-architecture-and-training.html#_6、deepseek-r1-zero-的奖励建模","20":"/langchat/docs/deepseek-r1-architecture-and-training.html#_6-1-基于规则的检查","21":"/langchat/docs/deepseek-r1-architecture-and-training.html#_6-2-格式化奖励","22":"/langchat/docs/deepseek-r1-architecture-and-training.html#_7、奖励训练模板","23":"/langchat/docs/deepseek-r1-architecture-and-training.html#_8、deepseek-r1-zero-的强化学习训练过程","24":"/langchat/docs/deepseek-r1-architecture-and-training.html#_9、r1-zero-的两个主要问题","25":"/langchat/docs/deepseek-r1-architecture-and-training.html#_10、冷启动数据","26":"/langchat/docs/deepseek-r1-architecture-and-training.html#_10-1-使用长-cot-进行少量提示","27":"/langchat/docs/deepseek-r1-architecture-and-training.html#_10-2-直接提示","28":"/langchat/docs/deepseek-r1-architecture-and-training.html#_10-3-后处理细化","29":"/langchat/docs/deepseek-r1-architecture-and-training.html#_11、监督微调","30":"/langchat/docs/deepseek-r1-architecture-and-training.html#_12、推理导向强化学习","31":"/langchat/docs/deepseek-r1-architecture-and-training.html#_13、拒绝抽样","32":"/langchat/docs/deepseek-r1-architecture-and-training.html#_14、适用于所有场景的-rl","33":"/langchat/docs/deepseek-r1-architecture-and-training.html#_15、蒸馏","34":"/README.html#langchat-document","35":"/README.html#商业化支持","36":"/README.html#特性","37":"/README.html#赞助","38":"/README.html#版权和协议","39":"/README.html#代码","40":"/README.html#版本更新","41":"/README.html#star-history","42":"/README.html#感谢","43":"/README.html#联系","44":"/langchat/docs/deepseek-r1-tuning.html#deepseek-r1微调指南","45":"/langchat/docs/deepseek-r1-tuning.html#_1、了解-deepseek-r1","46":"/langchat/docs/deepseek-r1-tuning.html#_1-1-为什么需要微调","47":"/langchat/docs/deepseek-r1-tuning.html#_1-2-微调中的常见挑战及其克服方法","48":"/langchat/docs/deepseek-r1-tuning.html#_2、设置环境","49":"/langchat/docs/deepseek-r1-tuning.html#_3、加载预训练模型和-tokenizer","50":"/langchat/docs/deepseek-r1-tuning.html#_4、准备数据集","51":"/langchat/docs/deepseek-r1-tuning.html#_5、应用-lora-进行高效微调","52":"/langchat/docs/deepseek-r1-tuning.html#_6、评估和保存模型","53":"/langchat/docs/deepseek-r1-tuning.html#_7、部署模型进行推理","54":"/langchat/docs/deepseek-r1-tuning.html#_8、结束语","55":"/langchat/docs/distill-deepseek-r1-into-your-model.html#蒸馏deepseek-r1到自己的模型","56":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_1、什么是蒸馏","57":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_2、蒸馏类型","58":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_3、deepseek-的蒸馏模型","59":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_4、为什么要蒸馏自己的模型","60":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5、将-deepseek-r1-知识蒸馏成自定义小模型","61":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-1-生成和格式化数据集","62":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-2-加载模型和标记器","63":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-3-配置-lora-以实现高效微调","64":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-4-设置训练参数","65":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-5-训练模型","66":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-6-合并保存最终模型","67":"/langchat/docs/distill-deepseek-r1-into-your-model.html#_5-7-推理","68":"/langchat/docs/introduce.html#langchat介绍","69":"/langchat/docs/introduce.html#适合人群","70":"/langchat/docs/introduce.html#项目架构","71":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#deepseek-r1的推理能力分析","72":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_1、基础模型","73":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_2、deepseek-的方法","74":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_2-1-rl-简介","75":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_2-2-deepseek-r1-zero-的强化学习策略","76":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_3、结果如何","77":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_4、deepseek-r1","78":"/langchat/docs/deepseek-r1-reasoning-capabilities-analysis.html#_5、结束语","79":"/langchat/docs/rag.html#langchain如何实现rag","80":"/langchat/docs/rag.html#_1-文档处理","81":"/langchat/docs/rag.html#_2-ocr文本提取","82":"/langchat/docs/rag.html#_3-文本拆分","83":"/langchat/docs/rag.html#_4-文本嵌入","84":"/langchat/docs/rag.html#_5-向量存储","85":"/langchat/docs/rag.html#_6-输入问题并检索","86":"/langchat/docs/rag.html#_7-输入嵌入","87":"/langchat/docs/rag.html#_8-向量匹配","88":"/langchat/docs/rag.html#_9-数据处理","89":"/langchat/docs/rag.html#_10-数据呈现","90":"/langchat/docs/run/environment.html#环境准备","91":"/langchat/docs/run/environment.html#前端基础环境","92":"/langchat/docs/run/environment.html#后端基础环境","93":"/langchat/docs/run/environment.html#安装pgvector","94":"/langchat/docs/run/getting-started.html#本地启动项目","95":"/langchat/docs/run/getting-started.html#clone-open","96":"/langchat/docs/run/getting-started.html#下载依赖","97":"/langchat/docs/run/getting-started.html#环境配置","98":"/langchat/docs/run/getting-started.html#导入sql","99":"/langchat/docs/run/getting-started.html#修改application-yml","100":"/langchat/docs/run/getting-started.html#启动后端项目","101":"/langchat/docs/run/getting-started.html#启动langchat-ui前端","102":"/langchat/docs/run/getting-started.html#启动langchat-ui-client前端","103":"/langchat/docs/run/login.html#如何登录系统","104":"/langchat/docs/run/login.html#账号体系","105":"/langchat/docs/run/login.html#登录","106":"/langchat/docs/server/knowledge.html#在langchat中配置知识库","107":"/langchat/docs/server/knowledge.html#导入知识库","108":"/langchat/docs/server/knowledge.html#文档管理","109":"/langchat/docs/server/knowledge.html#切片管理","110":"/langchat/docs/server/knowledge.html#切片检索","111":"/langchat/docs/langchat-deepseek-r1.html#langchat如何接入deepseek-r1模型","112":"/langchat/docs/langchat-deepseek-r1.html#关于langchat","113":"/langchat/docs/langchat-deepseek-r1.html#安装deepseek-r1","114":"/langchat/docs/langchat-deepseek-r1.html#基础概念","115":"/langchat/docs/langchat-deepseek-r1.html#deepseek-r1下载哪个版本","116":"/langchat/docs/langchat-deepseek-r1.html#_1-安装ollama","117":"/langchat/docs/langchat-deepseek-r1.html#_2-安装deepseek-r1","118":"/langchat/docs/langchat-deepseek-r1.html#_3-验证deepseek-r1模型是否启动","119":"/langchat/docs/langchat-deepseek-r1.html#启动langchat","120":"/langchat/docs/langchat-deepseek-r1.html#_1-执行数据库脚本","121":"/langchat/docs/langchat-deepseek-r1.html#_2-修改配置文件","122":"/langchat/docs/langchat-deepseek-r1.html#_3-安装pgvector","123":"/langchat/docs/langchat-deepseek-r1.html#_4-运行langchat","124":"/langchat/docs/langchat-deepseek-r1.html#测试langchat","125":"/langchat/docs/langchat-deepseek-r1.html#测试langchat聊天功能","126":"/langchat/docs/langchat-deepseek-r1.html#配置langchat知识库","127":"/langchat/docs/langchat-deepseek-r1.html#_1-配置向量数据库","128":"/langchat/docs/langchat-deepseek-r1.html#_2-本地下载embedding模型","129":"/langchat/docs/langchat-deepseek-r1.html#_3-测试embedding模型","130":"/langchat/docs/langchat-deepseek-r1.html#_4-langchat配置embedding","131":"/langchat/docs/langchat-deepseek-r1.html#_5-创建langchat知识库","132":"/langchat/docs/langchat-deepseek-r1.html#_6-导入知识库文档","133":"/langchat/docs/langchat-deepseek-r1.html#为什么报错error-expected-1024","134":"/langchat/docs/langchat-deepseek-r1.html#_7-重新导入知识库文档","135":"/langchat/docs/langchat-deepseek-r1.html#_8-向量搜索测试","136":"/langchat/docs/langchat-deepseek-r1.html#创建langchat-ai应用","137":"/langchat/docs/langchat-deepseek-r1.html#配置langchat应用","138":"/langchat/docs/langchat-deepseek-r1.html#测试langchat应用","139":"/langchat/docs/langchat-deepseek-r1.html#验证是否查询向量文本","140":"/langchat/docs/show.html#如何部署langchat到云端服务器","141":"/langchat/docs/show.html#商业化技术支持","142":"/langchat/docs/server/models.html#在langchat中配置模型","143":"/langchat/docs/server/models.html#配置官方模型","144":"/langchat/docs/server/models.html#配置openai","145":"/langchat/docs/server/models.html#配置千帆大模型","146":"/langchat/docs/server/models.html#配置千问大模型","147":"/langchat/docs/server/models.html#配置智谱ai","148":"/langchat/docs/server/models.html#配置ollama","149":"/langchat/docs/server/models.html#配置ollama-1","150":"/langchat/docs/server/models.html#配置azure-openai","151":"/langchat/docs/server/models.html#配置gemini","152":"/langchat/docs/server/models.html#配置claude","153":"/langchat/docs/questions.html#常见的错误解决方案","154":"/langchat/docs/questions.html#maven-langchat构建失败","155":"/langchat/docs/questions.html#consider-defining-a-bean-error-creating-bean","156":"/langchat/docs/questions.html#error-invalid-content-type-text-html-charset-utf-8","157":"/langchat/docs/questions.html#没有匹配到模型","158":"/langchat/docs/questions.html#invalid-content-type-application-json","159":"/langchat/docs/server/models-proxy.html#在langchat中使用第三方代理配置模型","160":"/langchat/docs/server/models-proxy.html#openai接口格式","161":"/langchat/docs/server/models-proxy.html#代理官方接口格式"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[2,1,35],"1":[3,2,16],"2":[4,2,20],"3":[3,5,15],"4":[2,5,21],"5":[3,5,17],"6":[3,5,40],"7":[3,5,16],"8":[5,5,16],"9":[5,2,3],"10":[4,6,1],"11":[4,6,20],"12":[2,2,12],"13":[2,1,24],"14":[2,2,45],"15":[6,2,33],"16":[6,2,41],"17":[4,2,46],"18":[3,2,121],"19":[5,2,18],"20":[3,6,28],"21":[3,6,21],"22":[2,2,102],"23":[5,2,115],"24":[4,2,62],"25":[2,2,17],"26":[5,4,85],"27":[3,4,63],"28":[3,4,80],"29":[2,2,77],"30":[2,2,105],"31":[2,2,60],"32":[3,2,63],"33":[2,2,38],"34":[2,1,51],"35":[1,2,17],"36":[1,2,37],"37":[1,2,19],"38":[1,2,18],"39":[1,2,1],"40":[1,2,29],"41":[2,2,1],"42":[1,2,2],"43":[1,2,11],"44":[2,1,39],"45":[4,2,12],"46":[3,5,24],"47":[3,5,55],"48":[2,2,18],"49":[3,2,31],"50":[2,2,71],"51":[4,2,47],"52":[2,2,23],"53":[2,2,39],"54":[2,2,16],"55":[2,1,26],"56":[3,2,26],"57":[2,2,27],"58":[3,2,30],"59":[3,2,35],"60":[5,2,15],"61":[3,7,111],"62":[3,7,62],"63":[5,7,45],"64":[3,7,49],"65":[2,7,42],"66":[3,7,22],"67":[3,7,99],"68":[1,1,38],"69":[1,1,9],"70":[1,1,54],"71":[2,1,58],"72":[2,2,37],"73":[3,2,15],"74":[4,4,30],"75":[5,4,84],"76":[3,2,30],"77":[3,2,44],"78":[2,2,32],"79":[2,1,11],"80":[2,2,3],"81":[2,2,8],"82":[2,2,4],"83":[2,2,4],"84":[2,2,4],"85":[2,2,4],"86":[2,2,5],"87":[2,2,3],"88":[2,2,4],"89":[2,2,5],"90":[1,1,4],"91":[1,1,27],"92":[1,1,36],"93":[1,1,21],"94":[1,1,4],"95":[3,1,11],"96":[1,1,17],"97":[1,1,3],"98":[1,2,4],"99":[2,2,30],"100":[1,1,3],"101":[2,1,16],"102":[3,1,17],"103":[1,1,13],"104":[1,1,11],"105":[1,1,1],"106":[1,1,2],"107":[1,1,12],"108":[1,1,7],"109":[1,1,11],"110":[1,1,18],"111":[2,1,4],"112":[1,2,33],"113":[2,2,8],"114":[1,4,36],"115":[3,4,39],"116":[2,4,7],"117":[3,4,13],"118":[3,4,11],"119":[1,2,20],"120":[2,3,8],"121":[2,3,9],"122":[2,3,36],"123":[2,3,8],"124":[1,2,15],"125":[1,3,15],"126":[1,2,2],"127":[2,3,8],"128":[2,3,35],"129":[2,3,25],"130":[2,3,10],"131":[2,3,2],"132":[2,3,7],"133":[3,3,37],"134":[2,3,7],"135":[2,3,7],"136":[2,2,7],"137":[1,4,6],"138":[1,4,4],"139":[2,4,7],"140":[1,1,15],"141":[1,1,14],"142":[1,1,8],"143":[1,1,15],"144":[1,1,8],"145":[1,1,24],"146":[1,1,10],"147":[1,1,6],"148":[1,1,31],"149":[1,2,25],"150":[2,1,16],"151":[1,1,25],"152":[1,1,8],"153":[1,1,5],"154":[2,1,7],"155":[7,1,8],"156":[8,1,7],"157":[1,1,4],"158":[5,1,11],"159":[1,1,16],"160":[1,1,10],"161":[1,1,4]},"averageFieldLength":[2.246913580246914,2.395061728395062,25.203703703703678],"storedFields":{"0":{"title":"DeepSeek-R1蒸馏模型","titles":[]},"1":{"title":"1、什么是蒸馏？","titles":["DeepSeek-R1蒸馏模型"]},"2":{"title":"2、DeepSeek-R1 蒸馏模型","titles":["DeepSeek-R1蒸馏模型"]},"3":{"title":"2.1 蒸馏的目的","titles":["DeepSeek-R1蒸馏模型","2、DeepSeek-R1 蒸馏模型"]},"4":{"title":"2.2 蒸馏过程","titles":["DeepSeek-R1蒸馏模型","2、DeepSeek-R1 蒸馏模型"]},"5":{"title":"2.3 蒸馏模型变体","titles":["DeepSeek-R1蒸馏模型","2、DeepSeek-R1 蒸馏模型"]},"6":{"title":"2.4 蒸馏模型的性能","titles":["DeepSeek-R1蒸馏模型","2、DeepSeek-R1 蒸馏模型"]},"7":{"title":"2.5 蒸馏模型的优势","titles":["DeepSeek-R1蒸馏模型","2、DeepSeek-R1 蒸馏模型"]},"8":{"title":"2.6 与 RL 训练模型的比较","titles":["DeepSeek-R1蒸馏模型","2、DeepSeek-R1 蒸馏模型"]},"9":{"title":"3、使用 DeepSeek-R1 蒸馏模型","titles":["DeepSeek-R1蒸馏模型"]},"10":{"title":"3.1 使用 Ollama","titles":["DeepSeek-R1蒸馏模型","3、使用 DeepSeek-R1 蒸馏模型"]},"11":{"title":"3.2 使用 vLLM","titles":["DeepSeek-R1蒸馏模型","3、使用 DeepSeek-R1 蒸馏模型"]},"12":{"title":"4、结束语","titles":["DeepSeek-R1蒸馏模型"]},"13":{"title":"DeepSeek R1架构和训练过程图解","titles":[]},"14":{"title":"1、快速概览","titles":["DeepSeek R1架构和训练过程图解"]},"15":{"title":"2、DeepSeek V3 (MOE) 如何思考？","titles":["DeepSeek R1架构和训练过程图解"]},"16":{"title":"3、DeepSeek V3 作为 RL 设置中的策略模型","titles":["DeepSeek R1架构和训练过程图解"]},"17":{"title":"4、GRPO 算法如何工作？","titles":["DeepSeek R1架构和训练过程图解"]},"18":{"title":"5、GRPO 的目标函数","titles":["DeepSeek R1架构和训练过程图解"]},"19":{"title":"6、DeepSeek R1 Zero 的奖励建模","titles":["DeepSeek R1架构和训练过程图解"]},"20":{"title":"6.1 基于规则的检查","titles":["DeepSeek R1架构和训练过程图解","6、DeepSeek R1 Zero 的奖励建模"]},"21":{"title":"6.2 格式化奖励","titles":["DeepSeek R1架构和训练过程图解","6、DeepSeek R1 Zero 的奖励建模"]},"22":{"title":"7、奖励训练模板","titles":["DeepSeek R1架构和训练过程图解"]},"23":{"title":"8、DeepSeek R1 Zero 的强化学习训练过程","titles":["DeepSeek R1架构和训练过程图解"]},"24":{"title":"9、R1 Zero 的两个主要问题","titles":["DeepSeek R1架构和训练过程图解"]},"25":{"title":"10、冷启动数据","titles":["DeepSeek R1架构和训练过程图解"]},"26":{"title":"10.1 使用长 CoT 进行少量提示","titles":["DeepSeek R1架构和训练过程图解","10、冷启动数据"]},"27":{"title":"10.2 直接提示","titles":["DeepSeek R1架构和训练过程图解","10、冷启动数据"]},"28":{"title":"10.3 后处理细化","titles":["DeepSeek R1架构和训练过程图解","10、冷启动数据"]},"29":{"title":"11、监督微调","titles":["DeepSeek R1架构和训练过程图解"]},"30":{"title":"12、推理导向强化学习","titles":["DeepSeek R1架构和训练过程图解"]},"31":{"title":"13、拒绝抽样","titles":["DeepSeek R1架构和训练过程图解"]},"32":{"title":"14、适用于所有场景的 RL","titles":["DeepSeek R1架构和训练过程图解"]},"33":{"title":"15、蒸馏","titles":["DeepSeek R1架构和训练过程图解"]},"34":{"title":"LangChat Document","titles":[]},"35":{"title":"商业化支持","titles":["LangChat Document"]},"36":{"title":"特性","titles":["LangChat Document"]},"37":{"title":"赞助","titles":["LangChat Document"]},"38":{"title":"版权和协议","titles":["LangChat Document"]},"39":{"title":"代码","titles":["LangChat Document"]},"40":{"title":"版本更新","titles":["LangChat Document"]},"41":{"title":"Star History","titles":["LangChat Document"]},"42":{"title":"感谢","titles":["LangChat Document"]},"43":{"title":"联系","titles":["LangChat Document"]},"44":{"title":"DeepSeek-R1微调指南","titles":[]},"45":{"title":"1、了解 DeepSeek-R1","titles":["DeepSeek-R1微调指南"]},"46":{"title":"1.1 为什么需要微调？","titles":["DeepSeek-R1微调指南","1、了解 DeepSeek-R1"]},"47":{"title":"1.2 微调中的常见挑战及其克服方法","titles":["DeepSeek-R1微调指南","1、了解 DeepSeek-R1"]},"48":{"title":"2、设置环境","titles":["DeepSeek-R1微调指南"]},"49":{"title":"3、加载预训练模型和 Tokenizer","titles":["DeepSeek-R1微调指南"]},"50":{"title":"4、准备数据集","titles":["DeepSeek-R1微调指南"]},"51":{"title":"5、应用 LoRA 进行高效微调","titles":["DeepSeek-R1微调指南"]},"52":{"title":"6、评估和保存模型","titles":["DeepSeek-R1微调指南"]},"53":{"title":"7、部署模型进行推理","titles":["DeepSeek-R1微调指南"]},"54":{"title":"8、结束语","titles":["DeepSeek-R1微调指南"]},"55":{"title":"蒸馏DeepSeek-R1到自己的模型","titles":[]},"56":{"title":"1、什么是蒸馏？","titles":["蒸馏DeepSeek-R1到自己的模型"]},"57":{"title":"2、蒸馏类型","titles":["蒸馏DeepSeek-R1到自己的模型"]},"58":{"title":"3、Deepseek 的蒸馏模型","titles":["蒸馏DeepSeek-R1到自己的模型"]},"59":{"title":"4、为什么要蒸馏自己的模型？","titles":["蒸馏DeepSeek-R1到自己的模型"]},"60":{"title":"5、将 DeepSeek-R1 知识蒸馏成自定义小模型","titles":["蒸馏DeepSeek-R1到自己的模型"]},"61":{"title":"5.1 生成和格式化数据集","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"62":{"title":"5.2 加载模型和标记器","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"63":{"title":"5.3 配置 LoRA 以实现高效微调","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"64":{"title":"5.4 设置训练参数","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"65":{"title":"5.5 训练模型","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"66":{"title":"5.6 合并保存最终模型","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"67":{"title":"5.7 推理","titles":["蒸馏DeepSeek-R1到自己的模型","5、将 DeepSeek-R1 知识蒸馏成自定义小模型"]},"68":{"title":"LangChat介绍","titles":[]},"69":{"title":"适合人群","titles":["LangChat介绍"]},"70":{"title":"项目架构","titles":["LangChat介绍"]},"71":{"title":"DeepSeek-R1的推理能力分析","titles":[]},"72":{"title":"1、基础模型","titles":["DeepSeek-R1的推理能力分析"]},"73":{"title":"2、DeepSeek 的方法","titles":["DeepSeek-R1的推理能力分析"]},"74":{"title":"2.1 RL 简介","titles":["DeepSeek-R1的推理能力分析","2、DeepSeek 的方法"]},"75":{"title":"2.2 DeepSeek-R1-Zero 的强化学习策略","titles":["DeepSeek-R1的推理能力分析","2、DeepSeek 的方法"]},"76":{"title":"3、结果如何？","titles":["DeepSeek-R1的推理能力分析"]},"77":{"title":"4、DeepSeek-R1","titles":["DeepSeek-R1的推理能力分析"]},"78":{"title":"5、结束语","titles":["DeepSeek-R1的推理能力分析"]},"79":{"title":"LangChain如何实现RAG？","titles":[]},"80":{"title":"1. 文档处理","titles":["LangChain如何实现RAG？"]},"81":{"title":"2. OCR文本提取","titles":["LangChain如何实现RAG？"]},"82":{"title":"3. 文本拆分","titles":["LangChain如何实现RAG？"]},"83":{"title":"4. 文本嵌入","titles":["LangChain如何实现RAG？"]},"84":{"title":"5. 向量存储","titles":["LangChain如何实现RAG？"]},"85":{"title":"6. 输入问题并检索","titles":["LangChain如何实现RAG？"]},"86":{"title":"7. 输入嵌入","titles":["LangChain如何实现RAG？"]},"87":{"title":"8. 向量匹配","titles":["LangChain如何实现RAG？"]},"88":{"title":"9. 数据处理","titles":["LangChain如何实现RAG？"]},"89":{"title":"10. 数据呈现","titles":["LangChain如何实现RAG？"]},"90":{"title":"环境准备","titles":[]},"91":{"title":"前端基础环境","titles":["环境准备"]},"92":{"title":"后端基础环境","titles":["环境准备"]},"93":{"title":"安装PgVector","titles":["环境准备"]},"94":{"title":"本地启动项目","titles":[]},"95":{"title":"Clone &amp; Open","titles":["本地启动项目"]},"96":{"title":"下载依赖","titles":["本地启动项目"]},"97":{"title":"环境配置","titles":["本地启动项目"]},"98":{"title":"导入sql","titles":["本地启动项目","环境配置"]},"99":{"title":"修改application.yml","titles":["本地启动项目","环境配置"]},"100":{"title":"启动后端项目","titles":["本地启动项目"]},"101":{"title":"启动langchat-ui前端","titles":["本地启动项目"]},"102":{"title":"启动langchat-ui-client前端","titles":["本地启动项目"]},"103":{"title":"如何登录系统","titles":[]},"104":{"title":"账号体系","titles":["如何登录系统"]},"105":{"title":"登录","titles":["如何登录系统"]},"106":{"title":"在LangChat中配置知识库","titles":[]},"107":{"title":"导入知识库","titles":["在LangChat中配置知识库"]},"108":{"title":"文档管理","titles":["在LangChat中配置知识库"]},"109":{"title":"切片管理","titles":["在LangChat中配置知识库"]},"110":{"title":"切片检索","titles":["在LangChat中配置知识库"]},"111":{"title":"LangChat如何接入DeepSeek-R1模型","titles":[]},"112":{"title":"关于LangChat","titles":["LangChat如何接入DeepSeek-R1模型"]},"113":{"title":"安装DeepSeek-R1","titles":["LangChat如何接入DeepSeek-R1模型"]},"114":{"title":"基础概念","titles":["LangChat如何接入DeepSeek-R1模型","安装DeepSeek-R1"]},"115":{"title":"DeepSeek-R1下载哪个版本？","titles":["LangChat如何接入DeepSeek-R1模型","安装DeepSeek-R1"]},"116":{"title":"1. 安装Ollama","titles":["LangChat如何接入DeepSeek-R1模型","安装DeepSeek-R1"]},"117":{"title":"2. 安装DeepSeek-R1","titles":["LangChat如何接入DeepSeek-R1模型","安装DeepSeek-R1"]},"118":{"title":"3. 验证DeepSeek-R1模型是否启动","titles":["LangChat如何接入DeepSeek-R1模型","安装DeepSeek-R1"]},"119":{"title":"启动LangChat","titles":["LangChat如何接入DeepSeek-R1模型"]},"120":{"title":"1. 执行数据库脚本","titles":["LangChat如何接入DeepSeek-R1模型","启动LangChat"]},"121":{"title":"2. 修改配置文件","titles":["LangChat如何接入DeepSeek-R1模型","启动LangChat"]},"122":{"title":"3. 安装PgVector","titles":["LangChat如何接入DeepSeek-R1模型","启动LangChat"]},"123":{"title":"4. 运行LangChat","titles":["LangChat如何接入DeepSeek-R1模型","启动LangChat"]},"124":{"title":"测试LangChat","titles":["LangChat如何接入DeepSeek-R1模型"]},"125":{"title":"测试LangChat聊天功能","titles":["LangChat如何接入DeepSeek-R1模型","测试LangChat"]},"126":{"title":"配置LangChat知识库","titles":["LangChat如何接入DeepSeek-R1模型"]},"127":{"title":"1. 配置向量数据库","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"128":{"title":"2. 本地下载Embedding模型","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"129":{"title":"3. 测试Embedding模型","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"130":{"title":"4. LangChat配置Embedding","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"131":{"title":"5. 创建LangChat知识库","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"132":{"title":"6. 导入知识库文档","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"133":{"title":"为什么报错ERROR: expected 1024","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"134":{"title":"7. 重新导入知识库文档","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"135":{"title":"8. 向量搜索测试","titles":["LangChat如何接入DeepSeek-R1模型","配置LangChat知识库"]},"136":{"title":"创建LangChat AI应用","titles":["LangChat如何接入DeepSeek-R1模型"]},"137":{"title":"配置LangChat应用","titles":["LangChat如何接入DeepSeek-R1模型","创建LangChat AI应用"]},"138":{"title":"测试LangChat应用","titles":["LangChat如何接入DeepSeek-R1模型","创建LangChat AI应用"]},"139":{"title":"验证是否查询向量文本？","titles":["LangChat如何接入DeepSeek-R1模型","创建LangChat AI应用"]},"140":{"title":"如何部署LangChat到云端服务器","titles":[]},"141":{"title":"商业化技术支持","titles":["如何部署LangChat到云端服务器"]},"142":{"title":"在LangChat中配置模型","titles":[]},"143":{"title":"配置官方模型","titles":["在LangChat中配置模型"]},"144":{"title":"配置OpenAI","titles":["在LangChat中配置模型"]},"145":{"title":"配置千帆大模型","titles":["在LangChat中配置模型"]},"146":{"title":"配置千问大模型","titles":["在LangChat中配置模型"]},"147":{"title":"配置智谱AI","titles":["在LangChat中配置模型"]},"148":{"title":"配置Ollama","titles":["在LangChat中配置模型"]},"149":{"title":"配置Ollama","titles":["在LangChat中配置模型","配置Ollama"]},"150":{"title":"配置Azure OpenAI","titles":["在LangChat中配置模型"]},"151":{"title":"配置Gemini","titles":["在LangChat中配置模型"]},"152":{"title":"配置Claude","titles":["在LangChat中配置模型"]},"153":{"title":"常见的错误解决方案","titles":[]},"154":{"title":"Maven: langchat构建失败","titles":["常见的错误解决方案"]},"155":{"title":"Consider defining a bean/Error creating bean...","titles":["常见的错误解决方案"]},"156":{"title":"Error: Invalid content-type: text/html; charset=utf-8","titles":["常见的错误解决方案"]},"157":{"title":"没有匹配到模型","titles":["常见的错误解决方案"]},"158":{"title":"Invalid content-type: application/json","titles":["常见的错误解决方案"]},"159":{"title":"在LangChat中使用第三方代理配置模型","titles":[]},"160":{"title":"OpenAI接口格式","titles":["在LangChat中使用第三方代理配置模型"]},"161":{"title":"代理官方接口格式","titles":["在LangChat中使用第三方代理配置模型"]}},"dirtCount":0,"index":[["仅仅需要修改baseurl即可",{"2":{"161":1}}],["仅修改baseurl",{"2":{"159":1}}],["仍按照模型官方的接口格式转发请求",{"2":{"159":1}}],["统一使用openai接口格式分发请求",{"2":{"159":1}}],["统一使用阿里的灵积服务平台",{"2":{"146":1}}],["认证失败",{"2":{"158":1}}],["出现这种情况的可能",{"2":{"158":1}}],["出现此错误的原因一般是因为模型接口返回是其他的错误消息",{"2":{"158":1}}],["出现的基础模型不一定会给出有用的答案",{"2":{"72":1}}],["产生是因为后台没有配置模型信息",{"2":{"157":1}}],["产品变现等",{"2":{"37":1}}],["没有匹配到模型",{"0":{"157":1}}],["没有就直接运行模型",{"2":{"114":1}}],["切换本地电脑网络",{"2":{"154":1}}],["切换阿里国内源",{"2":{"154":1}}],["切片检索",{"0":{"110":1}}],["切片管理",{"0":{"109":1}}],["常见的错误解决方案",{"0":{"153":1},"1":{"154":1,"155":1,"156":1,"157":1,"158":1}}],["按照表单配置参数即可",{"2":{"150":1}}],["按照如下步骤开始解决此问题",{"2":{"133":1}}],["填写你运行的模型名称即可",{"2":{"149":1}}],["越大的模型对电脑配置要求越高",{"2":{"148":1}}],["默认读取",{"2":{"155":1}}],["默认会下载最小的模型",{"2":{"148":1}}],["默认的local代表了使用tomcat的地址",{"2":{"121":1}}],["zhipuai",{"2":{"147":1}}],["zero版本",{"2":{"16":1}}],["zero",{"0":{"19":1,"23":1,"24":1,"75":1},"1":{"20":1,"21":1},"2":{"0":1,"8":2,"14":1,"16":1,"19":2,"21":2,"22":1,"24":5,"25":1,"28":4,"30":2,"75":1,"77":5}}],["千问的模型也是按量计费",{"2":{"146":1}}],["注册成功后转到控制台页面",{"2":{"145":1}}],["注意此表是项目启动自动生成的",{"2":{"93":1}}],["注意",{"2":{"34":1,"93":1,"99":1,"103":1,"113":1,"115":1,"119":1,"120":1,"122":2,"123":1,"125":1,"127":3,"143":1,"144":1,"149":1,"151":1,"159":3,"160":1}}],["官方文档看这里",{"2":{"147":1,"150":1,"151":1,"152":1}}],["官方模型指的是使用官方渠道购买的模型key",{"2":{"143":1}}],["官网购买的",{"2":{"143":1}}],["官网地址",{"2":{"112":1}}],["及时应用",{"2":{"142":1}}],["说明了他刚才引用了我们上传的langchat",{"2":{"138":1}}],["关联好我们创建的知识库后",{"2":{"137":1}}],["关联刚才创建的知识库",{"2":{"137":1}}],["关于embedding模型的定义如下",{"2":{"133":1}}],["关于langchat",{"0":{"112":1}}],["关于知识蒸馏的开创性论文中提出的",{"2":{"56":1}}],["遇到这种情况怎么处理",{"2":{"133":1}}],["往知识库导入文档",{"2":{"132":1}}],["访问地址是",{"2":{"129":1}}],["了embedding模型就自动启用了",{"2":{"128":1}}],["了解",{"0":{"45":1},"1":{"46":1,"47":1}}],["很快运行结束",{"2":{"128":1}}],["很多次",{"2":{"74":1}}],["进入官网",{"2":{"128":1}}],["进行高效微调",{"0":{"51":1}}],["进行微调进行了高度优化",{"2":{"44":1}}],["进行微调",{"2":{"44":2}}],["进行微调而创建的",{"2":{"4":1}}],["进行优势估计",{"2":{"30":1}}],["进行少量提示",{"0":{"26":1}}],["进行了比较",{"2":{"8":1}}],["百度",{"2":{"128":1}}],["百度千帆大模型对于新用户注册",{"2":{"145":1}}],["百度千帆",{"2":{"34":1,"112":1}}],["到此为止",{"2":{"125":1,"135":1}}],["到底是什么",{"2":{"73":1}}],["太麻烦了",{"2":{"122":1}}],["尽量不要自己手动编译pgvector源码",{"2":{"122":1}}],["尽管其参数只是",{"2":{"71":2}}],["尽管比",{"2":{"58":1}}],["尽管",{"2":{"28":1}}],["尽管本文没有指定强化学习预训练的确切初始数据集",{"2":{"23":1}}],["尽管本文在这个阶段为了简单起见重点关注",{"2":{"20":1}}],["尽管规模较小",{"2":{"7":1}}],["应该在数据库能看到langchat",{"2":{"122":1}}],["应用",{"0":{"51":1}}],["应用去偏差技术并使用公平性指标评估模型",{"2":{"47":1}}],["省去了上麦那一系列步骤",{"2":{"122":1}}],["执行如下脚本",{"2":{"129":1}}],["执行命令",{"2":{"128":1}}],["执行数据库脚本",{"0":{"120":1}}],["执行正确的操作顺序",{"2":{"23":1}}],["能看到如下分段信息",{"2":{"134":1}}],["能看到如下信息",{"2":{"118":1}}],["能够以更少的训练迭代取得更大的进步",{"2":{"77":1}}],["地址",{"2":{"118":1}}],["验证此回答是否查询了知识库的向量信息",{"2":{"139":1}}],["验证是否查询向量文本",{"0":{"139":1}}],["验证deepseek",{"0":{"118":1}}],["验证其答案并给出更准确的答案",{"2":{"78":1}}],["否则建议安装1",{"2":{"117":1}}],["否则会惩罚它",{"2":{"14":1}}],["作者提供各种商业化技术支持服务",{"2":{"141":1}}],["作者贴心的给大家编译了一个pgvector发布到了阿里云仓库",{"2":{"122":1}}],["作者本地电脑是",{"2":{"115":1}}],["作为一个开发人员",{"2":{"154":1}}],["作为最终答案",{"2":{"76":1}}],["作为代理工作流程",{"2":{"16":1}}],["作为",{"0":{"16":1},"2":{"75":1}}],["作为基础模型",{"2":{"15":1}}],["作为示例",{"2":{"13":1}}],["至少本地电脑有32g内存",{"2":{"115":1}}],["至少本地电脑有16g内存",{"2":{"115":1}}],["至关重要的是",{"2":{"17":1}}],["命令默认安装的",{"2":{"115":1}}],["真实的场景下",{"2":{"115":1}}],["真实世界性能",{"2":{"59":1}}],["测试效果如下",{"2":{"149":1}}],["测试embedding模型",{"0":{"129":1}}],["测试langchat应用",{"0":{"138":1}}],["测试langchat聊天功能",{"0":{"125":1}}],["测试langchat",{"0":{"124":1},"1":{"125":1}}],["测试即可",{"2":{"115":1}}],["测量新模型与参考模型",{"2":{"18":1}}],["查看",{"2":{"114":1}}],["避免大家有各种疑惑",{"2":{"114":1}}],["避免在最终确定答案之前犯愚蠢的错误",{"2":{"71":1}}],["登录",{"0":{"105":1}}],["客户端系统用户表",{"2":{"104":1}}],["客户端账号密码",{"2":{"103":1}}],["业务是完全分离的",{"2":{"104":1}}],["业务模块化",{"2":{"68":1}}],["账号体系",{"0":{"104":1}}],["体验账号密码",{"2":{"103":1}}],["管理端系统用户表",{"2":{"104":1}}],["管理员账号密码",{"2":{"103":1}}],["管理员账号拥有页面所有权限",{"2":{"103":1}}],["管道在很大程度上促进了推理",{"2":{"78":1}}],["建议不要修改向量维度这个参数",{"2":{"127":1}}],["建议使用管理员账号",{"2":{"103":1}}],["建议安装并使用",{"2":{"91":1}}],["跳转到客户端系统首页",{"2":{"102":1}}],["跳转到后台系统登录页",{"2":{"101":1}}],["先安装依赖再启动项目",{"2":{"101":1,"102":1}}],["先乘后加",{"2":{"22":1}}],["启动完成后",{"2":{"149":1}}],["启动成功后如上图",{"2":{"123":1}}],["启动后访问",{"2":{"101":1,"102":1}}],["启动后端项目",{"0":{"100":1}}],["启动langchat",{"0":{"101":1,"102":1,"119":1},"1":{"120":1,"121":1,"122":1,"123":1}}],["另外本地访问",{"2":{"118":1}}],["另外",{"2":{"99":1}}],["另一个问题是语言混合",{"2":{"24":1}}],["目录下找到langchat",{"2":{"120":1}}],["目前最强的低成本推理模型",{"2":{"113":1}}],["目前langchat采用pgvector向量数据库",{"2":{"99":1}}],["目标是保留老师的大部分表现",{"2":{"56":1}}],["目标是创建一个较小的模型",{"2":{"1":1}}],["目标推理",{"2":{"29":1}}],["目标对",{"2":{"29":1}}],["目标函数",{"2":{"18":1}}],["目标",{"2":{"18":1}}],["必须修改",{"2":{"121":1}}],["必须给大家介绍一些基础的概念",{"2":{"114":1}}],["必须配置好mysql",{"2":{"99":1}}],["必须将",{"2":{"66":1}}],["修改baseurl",{"2":{"159":1}}],["修改后模型的baseurl配置应该是这样的",{"2":{"156":1}}],["修改后的薛定谔猫问题提交给",{"2":{"71":1}}],["修改配置文件",{"0":{"121":1}}],["修改application",{"0":{"99":1}}],["导入文档",{"2":{"107":1}}],["导入知识库文档",{"0":{"132":1}}],["导入知识库",{"0":{"107":1}}],["导入sql",{"0":{"98":1}}],["导致输出不一致和混乱",{"2":{"24":1}}],["两个模块",{"2":{"96":1}}],["下载完成后会直接运行模型",{"2":{"148":1}}],["下载依赖",{"0":{"96":1}}],["下面开始创建langchat",{"2":{"136":1}}],["下面你可以看到",{"2":{"67":1}}],["创建应用的时候会提醒你开通哪些模型",{"2":{"145":1}}],["创建langchat应用后",{"2":{"137":1}}],["创建langchat",{"0":{"136":1},"1":{"137":1,"138":1,"139":1}}],["创建langchat知识库",{"0":{"131":1}}],["创建完成后",{"2":{"107":1}}],["创建完成即可",{"2":{"93":1}}],["创下了密集模型的新纪录",{"2":{"6":1}}],["主要是遵循openai接口格式",{"2":{"160":1}}],["主要包含",{"2":{"96":1}}],["主要说一下pgvector向量数据库的安装",{"2":{"93":1}}],["主要问题是",{"2":{"24":1}}],["安装ollama的步骤这里就不再解释了",{"2":{"116":1}}],["安装ollama",{"0":{"116":1}}],["安装deepseek",{"0":{"113":1,"117":1},"1":{"114":1,"115":1,"116":1,"117":1,"118":1}}],["安装后需要创建langchat数据库",{"2":{"93":1}}],["安装pgvector后仍需要有postgres",{"2":{"122":1}}],["安装pgvector",{"0":{"93":1,"122":1}}],["安全性和性能的考虑",{"2":{"92":1}}],["除此之外",{"2":{"92":1}}],["除了ollama这种本地模型必须配置baseurl之外",{"2":{"143":1}}],["除了上面两个ui模块",{"2":{"96":1}}],["除了精炼推理数据外",{"2":{"31":1}}],["除了",{"2":{"0":1}}],["内容",{"2":{"92":1}}],["内存使用和推理速度方面更高效",{"2":{"1":1}}],["≥",{"2":{"92":2}}],["推荐使用以下镜像源",{"2":{"91":1}}],["推理失败的例子",{"2":{"71":1}}],["推理样本",{"2":{"61":1}}],["推理",{"0":{"67":1},"2":{"31":1,"32":1,"67":2}}],["推理导向循环",{"2":{"30":1}}],["推理导向强化学习",{"0":{"30":1}}],["推理教育",{"2":{"30":1}}],["推理正确",{"2":{"23":1,"25":1}}],["推理错误且较差",{"2":{"23":1}}],["推理错误",{"2":{"23":1}}],["推理步骤是否使用",{"2":{"23":1}}],["推理过程",{"2":{"24":1}}],["推理过程在这里",{"2":{"22":2}}],["推理过程和答案分别包含在",{"2":{"22":2}}],["推理能力",{"2":{"7":1}}],["推理模型",{"2":{"0":2}}],["处理相关信息以对用户的问题制定详细的答案",{"2":{"88":1}}],["才能从向量数据库中匹配到相似的数据",{"2":{"86":1}}],["才能在现实世界中使用并进行更广泛的研究",{"2":{"24":1}}],["其他模型按量收费",{"2":{"145":1}}],["其他模型的部署方式可以参考官方文档",{"2":{"113":1}}],["其他的官方模型其实都不需要配置baseurl",{"2":{"143":1}}],["其他所有的llm",{"2":{"114":1}}],["其实区别都不大",{"2":{"114":1}}],["其实就是从向量库中匹配相似的数据",{"2":{"85":1}}],["其余模块都是后端的",{"2":{"96":1}}],["其中一个例子就是",{"2":{"71":1}}],["其中包含",{"2":{"61":1}}],["其中较小的模型",{"2":{"56":1}}],["其中人类指出两个模型输出中的哪一个在有用性和无害性方面更好",{"2":{"32":1}}],["其中",{"2":{"16":1}}],["向量搜索测试",{"0":{"135":1}}],["向量数据库的纬度配置",{"2":{"133":1}}],["向量数据表一旦初始化",{"2":{"127":1}}],["向量化",{"2":{"108":1}}],["向量匹配",{"0":{"87":1}}],["向量存储",{"0":{"84":1}}],["向标记器添加特殊标记",{"2":{"62":1}}],["易于管理的部分",{"2":{"82":1}}],["文本块写法非常方便",{"2":{"92":1}}],["文本嵌入",{"0":{"83":1}}],["文本被分成更小的",{"2":{"82":1}}],["文本拆分",{"0":{"82":1}}],["文档管理",{"0":{"108":1}}],["文档由",{"2":{"81":1}}],["文档处理",{"0":{"80":1}}],["文档摘要或问答等任务",{"2":{"46":1}}],["图片转文本",{"2":{"81":1}}],["检索增强生成",{"2":{"79":1}}],["检查整个输出是否安全且无偏见",{"2":{"32":1}}],["检查模型输出是否正确地将推理过程包含在",{"2":{"21":1}}],["行为并未明确编入llm的程序中",{"2":{"78":1}}],["行业或数据集的关键步骤",{"2":{"46":1}}],["智谱的embedding模型",{"2":{"128":1}}],["智谱清言",{"2":{"34":1,"112":1}}],["智能",{"2":{"78":1}}],["考虑所有可能性以及重新审视",{"2":{"78":1}}],["考虑第一个输出",{"2":{"30":1}}],["聪明",{"2":{"78":1}}],["某些",{"2":{"78":1}}],["过程",{"2":{"77":1}}],["过程显然会随着时间的推移提高",{"2":{"76":1}}],["会有如下日志",{"2":{"134":1}}],["会经历相同的",{"2":{"77":1}}],["会犯错误但更具创造性",{"2":{"0":1}}],["冷启动有助于跳过",{"2":{"77":1}}],["冷启动后",{"2":{"77":1}}],["冷启动数据",{"0":{"25":1},"1":{"26":1,"27":1,"28":1}}],["变得可读",{"2":{"77":1}}],["变现等方式",{"2":{"34":1}}],["找到了答案",{"2":{"77":1}}],["红色图表表示",{"2":{"76":1}}],["蓝色图表显示通过单个模型的预测获得的准确率",{"2":{"76":1}}],["论文",{"2":{"76":1}}],["论文明确提到避免使用",{"2":{"21":1}}],["人类反馈数据可能很嘈杂",{"2":{"75":1}}],["人工智能系统就可以开发出人类都不知道的新推理规则",{"2":{"78":1}}],["人工反馈",{"2":{"75":1}}],["人工检查",{"2":{"28":1}}],["鼓励",{"2":{"75":1,"78":1}}],["鼓励模型改进而不会过度补偿",{"2":{"18":1}}],["加上测试用例",{"2":{"75":1}}],["加载模型和标记器",{"0":{"62":1}}],["加载预训练模型和",{"0":{"49":1}}],["类似于",{"2":{"75":1}}],["良好输出",{"2":{"75":1}}],["良好的推理和答案",{"2":{"29":1}}],["良好的推理是什么样子以及如何清晰地呈现它",{"2":{"25":1}}],["早些时候",{"2":{"75":1}}],["究竟用强化学习做了什么",{"2":{"74":1}}],["学习如何优化以获得正确答案",{"2":{"75":1}}],["学习一个策略",{"2":{"74":1}}],["学生可以学习更丰富",{"2":{"57":1}}],["学生",{"2":{"55":1,"56":1}}],["学生模型经过训练以匹配教师的",{"2":{"57":1}}],["学生模型现在被精炼成更小的版本",{"2":{"33":1}}],["学生模型",{"2":{"33":1}}],["给定一个特定状态",{"2":{"74":1}}],["给予特定答案的奖励",{"2":{"18":1}}],["动作对应于",{"2":{"75":1}}],["动作和奖励",{"2":{"74":1}}],["动态配置",{"2":{"36":1}}],["状态",{"2":{"74":1}}],["强化学习会成为实现目标的秘诀吗",{"2":{"78":1}}],["强化学习策略的目标是让",{"2":{"75":1}}],["强化学习问题有三个变量",{"2":{"74":1}}],["强化学习第",{"2":{"32":1}}],["利用",{"2":{"74":1}}],["利用梯度检查点和低秩自适应",{"2":{"47":1}}],["尝试随机动作并查看哪些有效",{"2":{"74":1}}],["探索",{"2":{"74":1}}],["老版本官方已经不再提供支持",{"2":{"92":1}}],["老鼠应该",{"2":{"74":1}}],["老鼠需要选择能够让它最大化奖励的动作",{"2":{"74":1}}],["老鼠",{"2":{"74":1}}],["老鼠会学会优先考虑这些动作",{"2":{"74":1}}],["老鼠会",{"2":{"74":1}}],["老师",{"2":{"56":1}}],["自主",{"2":{"73":1}}],["自定义数据集可帮助模型理解小众术语",{"2":{"46":1}}],["大多数基础模型都可以在",{"2":{"72":1}}],["大规模成本效率",{"2":{"59":1}}],["暴露于大量的互联网文本语料库",{"2":{"72":1}}],["涉及将",{"2":{"72":1}}],["涉及的技术栈包括",{"2":{"68":1}}],["都从预训练阶段开始",{"2":{"72":1}}],["都使用特定格式来执行指令跟踪任务",{"2":{"61":1}}],["所有模型的请求响应接口都是安装openai格式",{"2":{"160":1}}],["所有训练方法",{"2":{"72":1}}],["所以请先阅读一遍文档再运行系统",{"2":{"153":1}}],["所以这里不再演示",{"2":{"150":1}}],["所以这里直接按照默认的下载7b模型",{"2":{"117":1}}],["所以生成的表也只接收1024维度的数据",{"2":{"133":1}}],["所以有多种安装方式",{"2":{"122":1}}],["所以如果你是第一次安装",{"2":{"122":1}}],["所以我推荐各位安装",{"2":{"115":1}}],["所以大家不要被营销号带偏",{"2":{"114":1}}],["所以",{"2":{"14":1}}],["所以才想到这次发布蒸馏版本",{"2":{"3":1}}],["改进推理的秘诀是什么",{"2":{"71":1}}],["改进其预测",{"2":{"29":1}}],["同样",{"2":{"128":1}}],["同样的",{"2":{"109":1}}],["同样的问题问了",{"2":{"71":1}}],["同上",{"2":{"87":1}}],["同时显着降低计算成本和内存占用",{"2":{"56":1}}],["同时保持效率",{"2":{"47":1}}],["同时保持开源",{"2":{"44":1}}],["同时保持用户友好性",{"2":{"31":1}}],["同时减少不正确或不完整的响应",{"2":{"23":1}}],["同时降低生成不正确或不完整输出的概率",{"2":{"23":1}}],["同时确保训练过程稳定且不会失控",{"2":{"18":1}}],["同时在计算上更高效且更易于部署",{"2":{"2":1}}],["同时在计算资源",{"2":{"1":1}}],["试图考虑所有可能性",{"2":{"71":1}}],["像一个聪明的人一样思考",{"2":{"71":1}}],["猫还活着的概率是",{"2":{"71":1}}],["他告诉我",{"2":{"71":1}}],["他们的模型一般都能支持生成多维度的数据768",{"2":{"133":1}}],["他们的最终检查点",{"2":{"32":1}}],["他们实施了一些额外的步骤",{"2":{"77":1}}],["他们首次介绍了这种强化学习策略",{"2":{"75":1}}],["他们首先尝试了纯",{"2":{"14":1}}],["他们使用",{"2":{"58":1}}],["他们使用了一种称为拒绝抽样的技术",{"2":{"31":1}}],["他们使用了强化学习",{"2":{"14":1}}],["他们进一步将更大的模型提炼为性能更高的小型模型",{"2":{"33":1}}],["他们进行了监督微调",{"2":{"28":1}}],["他们还添加了非推理数据",{"2":{"31":1}}],["他们会从上一阶段模型生成许多输出",{"2":{"31":1}}],["他们专门增加了保持语言一致性的奖励",{"2":{"30":1}}],["他们添加了一些新的",{"2":{"30":1}}],["他们已经为",{"2":{"30":1}}],["他们已经有了",{"2":{"14":1}}],["他们确实使用了相同的",{"2":{"30":1}}],["他们确实期望输出包含推理步骤和验证部分",{"2":{"27":1}}],["他们确保过滤掉任何不好的例子",{"2":{"28":1}}],["他们最终获得的冷启动数据非常好",{"2":{"28":1}}],["他们采用了",{"2":{"28":1}}],["他们甚至使用了已经训练过的",{"2":{"28":1}}],["他们收集数据的另一种方法是直接提示模型不仅解决问题",{"2":{"27":1}}],["他们可能会显示如下提示",{"2":{"26":1}}],["他们为",{"2":{"26":1}}],["他们想教",{"2":{"25":1}}],["他们所做的第一步是使用旧策略",{"2":{"23":1}}],["他们没有使用花哨的神经网络来判断答案",{"2":{"19":1}}],["他们保持简单直接",{"2":{"19":1}}],["他们给它一些起始数据来启动它",{"2":{"14":1}}],["他们通过不同的阶段使其更有条理",{"2":{"14":1}}],["他们称之为管道",{"2":{"14":1}}],["他们从一个非常聪明的",{"2":{"14":1}}],["死薛定谔猫",{"2":{"71":1}}],["展示了",{"2":{"71":1}}],["└──",{"2":{"70":5}}],["│",{"2":{"70":33}}],["├──",{"2":{"70":37}}],["具备完善且规范的代码分层结构",{"2":{"70":1}}],["具体取决于硬件和数据集大小",{"2":{"47":1}}],["具体来说",{"2":{"18":1}}],["项目代码中会有很多",{"2":{"92":1}}],["项目架构",{"0":{"70":1}}],["项目合作也欢迎联系我",{"2":{"37":1}}],["想要更好的效果",{"2":{"149":1}}],["想要学习ai在java生态下集成方案的同学或企业",{"2":{"69":1}}],["想要学习vue",{"2":{"69":1}}],["想象一下得到",{"2":{"31":1}}],["jdk17+",{"2":{"119":1}}],["jdk17",{"2":{"92":2}}],["jdk8",{"2":{"92":4}}],["jdk",{"2":{"92":1}}],["js",{"2":{"91":1}}],["jsonl",{"2":{"50":2}}],["json",{"0":{"158":1},"2":{"50":1,"70":3}}],["java的main函数启动",{"2":{"100":1}}],["java",{"2":{"68":1}}],["java工具类",{"2":{"68":1}}],["权限框架",{"2":{"68":1}}],["持久层框架",{"2":{"68":1}}],["持续关注",{"2":{"34":1}}],["前言",{"2":{"153":1}}],["前端",{"2":{"96":1}}],["前端基于node",{"2":{"101":1,"102":1}}],["前端基于vue3",{"2":{"68":1}}],["前端基础环境",{"0":{"91":1}}],["前端技术",{"2":{"68":1}}],["前后端分离",{"2":{"68":1}}],["前台地址",{"2":{"34":1}}],["概述了思维过程和推理",{"2":{"67":1}}],["部署并配置域名映射等全套技术支持",{"2":{"141":1}}],["部署模型进行推理",{"0":{"53":1}}],["部分",{"2":{"67":1}}],["合并保存最终模型",{"0":{"66":1}}],["批量处理示例",{"2":{"65":1}}],["批评家",{"2":{"17":1}}],["配置claude",{"0":{"152":1}}],["配置gemini",{"0":{"151":1}}],["配置azure",{"0":{"150":1}}],["配置ollama",{"0":{"148":1,"149":1},"1":{"149":1}}],["配置openai",{"0":{"144":1}}],["配置智谱ai",{"0":{"147":1}}],["配置千问大模型",{"0":{"146":1}}],["配置千帆大模型",{"0":{"145":1}}],["配置官方模型",{"0":{"143":1}}],["配置后系统会动态刷新配置",{"2":{"142":1}}],["配置中配置大模型即可",{"2":{"142":1}}],["配置langchat应用",{"0":{"137":1}}],["配置langchat知识库",{"0":{"126":1},"1":{"127":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1,"134":1,"135":1}}],["配置向量数据库",{"0":{"127":1}}],["配置",{"0":{"63":1}}],["配置训练参数",{"2":{"51":1}}],["yml配置文件",{"2":{"121":1}}],["yml包含了最基础的环境配置要求",{"2":{"99":1}}],["yml文件",{"2":{"99":1,"155":1}}],["yml中环境为dev",{"2":{"155":1}}],["yml中的配置",{"2":{"99":1}}],["yml中默认配置local环境",{"2":{"99":1}}],["yml中写了表名vector",{"2":{"93":1}}],["yml",{"0":{"99":1}}],["yarnpkg",{"2":{"91":1}}],["yarn",{"2":{"91":3}}],["yaml",{"2":{"70":3}}],["your",{"2":{"61":1}}],["yes",{"2":{"27":1}}],["xx域名",{"2":{"156":1}}],["xxx",{"2":{"110":1,"128":1}}],["xml",{"2":{"70":4}}],["x",{"2":{"61":2}}],["x3c",{"2":{"22":24,"28":4,"30":8,"53":2,"61":6,"62":2,"67":3}}],["示例",{"2":{"61":1}}],["示例场景",{"2":{"59":1}}],["响应简单明了",{"2":{"67":1}}],["响应",{"2":{"61":1}}],["解决这个数学问题",{"2":{"61":1}}],["解决方案",{"2":{"47":5}}],["任务描述",{"2":{"61":1}}],["任务适应",{"2":{"46":1}}],["编码和一般问题解决等各种任务",{"2":{"61":1}}],["思考",{"2":{"67":1,"75":1,"78":1}}],["思路链",{"2":{"61":1}}],["思维",{"2":{"24":1}}],["知识蒸馏成自定义小模型",{"0":{"60":1},"1":{"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1}}],["知识库中只关联embedding数据库和embedding模型",{"2":{"131":1}}],["知识库",{"2":{"36":1}}],["迭代改进",{"2":{"59":1}}],["迭代地改进模型",{"2":{"17":1}}],["≠",{"2":{"59":1}}],["虽然它在推理方面表现出色",{"2":{"77":1}}],["虽然预蒸馏模型效率很高",{"2":{"59":1}}],["虽然准确度奖励仍然强化了正确答案",{"2":{"32":1}}],["风险分析",{"2":{"59":1}}],["股票价格预测",{"2":{"59":1}}],["现实世界的应用程序通常需要专业化",{"2":{"59":1}}],["现在已针对使用",{"2":{"44":1}}],["现在",{"2":{"32":1}}],["现在是一个完美精炼的推理示例",{"2":{"31":1}}],["现在考虑输出",{"2":{"30":1}}],["现在计算每个输出的优势",{"2":{"23":1}}],["现在我们已经了解了主要的理论概念",{"2":{"19":1}}],["现在我们已经了解了",{"2":{"16":1}}],["预测下一个单词的能力",{"2":{"72":1}}],["预训练过程的说明",{"2":{"72":1}}],["预训练",{"2":{"72":1}}],["预训练模型是在大量通用知识库上进行训练的",{"2":{"46":1}}],["预蒸馏模型是静态的",{"2":{"59":1}}],["预蒸馏模型在基准测试中表现出色",{"2":{"59":1}}],["预蒸馏模型在广泛的数据集上进行训练",{"2":{"59":1}}],["小得多",{"2":{"58":1}}],["策划的",{"2":{"58":1}}],["策略比率",{"2":{"23":1}}],["特定的动作序列会引导老鼠获得奖励",{"2":{"74":1}}],["特定任务优化",{"2":{"59":1}}],["特征提炼涉及将知识从教师模型的中间层转移到学生",{"2":{"57":1}}],["特征蒸馏",{"2":{"57":1}}],["特性",{"0":{"36":1}}],["函数之前神经网络的原始输出分数",{"2":{"57":1}}],["函数在两个选项中选择较小的值",{"2":{"18":1}}],["信息量较少的任务",{"2":{"57":1}}],["专业化",{"2":{"56":1}}],["边缘设备",{"2":{"56":1}}],["速度",{"2":{"56":1}}],["较小的模型需要更少的计算资源",{"2":{"56":1}}],["较大的",{"2":{"18":1}}],["成本也并不高",{"2":{"92":1}}],["成本效率",{"2":{"56":1}}],["成为此训练数据的一部分",{"2":{"31":1}}],["成为专家混合模型",{"2":{"15":1}}],["经过训练以模仿较大的预训练模型",{"2":{"56":1}}],["经过多次训练迭代后",{"2":{"32":1}}],["教师",{"2":{"55":1}}],["教师模型生成合成数据或伪标签",{"2":{"57":1}}],["教师模型",{"2":{"33":1}}],["深度学习模型彻底改变了人工智能领域",{"2":{"55":1}}],["运行langchat",{"0":{"123":1},"2":{"123":1}}],["运行如下命令",{"2":{"101":1,"102":1}}],["运行",{"2":{"53":1,"115":1}}],["运算顺序不正确",{"2":{"23":1}}],["运算顺序",{"2":{"22":1}}],["评估并保存微调后的模型",{"2":{"52":1}}],["评估和保存模型",{"0":{"52":1}}],["评估摘要",{"2":{"32":1}}],["初始化并开始训练",{"2":{"51":1}}],["初始版本",{"2":{"16":1}}],["允许通过仅训练模型的特定部分进行微调",{"2":{"51":1}}],["允许研究人员和开发人员在各种应用中使用和构建它们",{"2":{"7":1}}],["准备数据集",{"0":{"50":1}}],["准确率奖励",{"2":{"23":1}}],["准确度奖励自然是",{"2":{"30":1}}],["准确度奖励",{"2":{"23":1}}],["准确的输出",{"2":{"15":1}}],["位量化加载模型以减少内存使用量",{"2":{"49":1}}],["位量化来减少计算负荷",{"2":{"47":1}}],["需要本地电脑安装一些google身份认证工具cli",{"2":{"151":1}}],["需要自行开通",{"2":{"145":1}}],["需要的朋友请加我的微信详聊",{"2":{"141":1}}],["需要删除原表",{"2":{"127":1}}],["需要用pnpm下载依赖",{"2":{"96":1}}],["需要确保已经搭建好与之相匹配的开发环境",{"2":{"90":1}}],["需要构建高级流程化编排机器人的企业",{"2":{"69":1}}],["需要快速定制化开发企业机器人应用的企业",{"2":{"69":1}}],["需要搭建企业知识库平台的企业",{"2":{"69":1}}],["需要一套快速上手ai集成方案的企业级项目",{"2":{"69":1}}],["需要大量计算资源",{"2":{"48":1}}],["需要具有大量",{"2":{"47":1}}],["灾难性遗忘",{"2":{"47":1}}],["来源",{"2":{"76":1}}],["来验证",{"2":{"75":1}}],["来生成自定义域相关数据集",{"2":{"61":1}}],["来解决这一挑战",{"2":{"55":1}}],["来加快训练速度",{"2":{"47":1}}],["来防止过度拟合",{"2":{"47":1}}],["来鼓励语言模型中的推理是一种很有前途的方法",{"2":{"24":1}}],["将会删除向量数据库中原始数据并重新做embedding",{"2":{"108":1}}],["将文本内容转换成不同维度的有上下文关系的二进制数组数据",{"2":{"107":1}}],["将嵌入后的问题在向量存储库中检索匹配相似的数据",{"2":{"87":1}}],["将蒸馏后的模型权重推送到",{"2":{"67":1}}],["将数据集与此结构对齐可确保模型学习正确的对话模式",{"2":{"61":1}}],["将数据集构造为",{"2":{"61":1}}],["将",{"0":{"60":1},"1":{"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1}}],["将某些进程卸载到",{"2":{"47":1}}],["将ai智能客服快速嵌入任意第三方web应用中",{"2":{"36":1}}],["挑战",{"2":{"47":5}}],["根据当前状态确定老鼠移动到哪里",{"2":{"74":1}}],["根据特定数据集调整模型权重有助于减轻原始训练数据中可能存在的偏差",{"2":{"46":1}}],["根本不需要单独的批评家模型",{"2":{"17":1}}],["减少偏差",{"2":{"46":1}}],["金融或法律分析等特定领域进行专业化",{"2":{"46":1}}],["领域特定知识",{"2":{"46":1}}],["领域很流行",{"2":{"13":1}}],["原因如下",{"2":{"46":1}}],["原始与简化",{"2":{"18":1}}],["原始函数很吓人",{"2":{"18":1}}],["适配器与基础模型合并以进行推理",{"2":{"66":1}}],["适合人群",{"0":{"69":1}}],["适合",{"2":{"45":1}}],["适用于所有场景的",{"0":{"32":1}}],["数据呈现",{"0":{"89":1}}],["数据处理",{"0":{"88":1}}],["数据集结构",{"2":{"61":1}}],["数据集",{"2":{"61":1}}],["数据蒸馏",{"2":{"57":1}}],["数据准备",{"2":{"33":1}}],["数学问题解决和实时决策的任务中表现出色",{"2":{"45":1}}],["⚙",{"2":{"44":1}}],["优化",{"2":{"44":1}}],["优势有助于通过强化更好的输出来优化策略",{"2":{"23":1}}],["优势公式",{"2":{"18":1}}],["优势",{"2":{"17":1,"18":1}}],["对思考过程的奖励",{"2":{"75":1}}],["对",{"2":{"44":2}}],["对于第二种情况",{"2":{"161":1}}],["对于购买了第三方代理平台的同学非常有用",{"2":{"159":1}}],["对于使用第三方代理的情况",{"2":{"143":1}}],["对于这种情况",{"2":{"160":1}}],["对于这种方式",{"2":{"143":1}}],["对于这个",{"2":{"30":1}}],["对于学习大模型aigc产品设计流程非常有帮助",{"2":{"79":1}}],["对于本教程",{"2":{"61":1}}],["对于每个样本",{"2":{"33":1}}],["对于每个问题",{"2":{"18":1}}],["对于复杂的推理",{"2":{"31":1}}],["对于推理数据",{"2":{"31":1}}],["对于数据集中的每个推理问题",{"2":{"29":1}}],["对于我们的示例",{"2":{"32":1}}],["对于我们的示例问题",{"2":{"22":1,"26":1}}],["对于我们的数学问题",{"2":{"19":1}}],["对于",{"2":{"19":1,"27":1,"29":1,"31":1}}],["低秩自适应",{"2":{"44":3,"55":1}}],["邮箱",{"2":{"43":1}}],["博客",{"2":{"43":1}}],["联系",{"0":{"43":1}}],["感谢",{"0":{"42":1}}],["感兴趣",{"2":{"13":1}}],["公开仓库",{"2":{"40":1}}],["公式",{"2":{"18":2}}],["保持业务分离",{"2":{"40":1}}],["腾讯云oss服务",{"2":{"40":1}}],["阿里千问模型服务",{"2":{"146":1}}],["阿里云",{"2":{"40":1}}],["阿里通义",{"2":{"34":1,"112":1}}],["七牛云",{"2":{"40":1}}],["分页等分割方式",{"2":{"109":1}}],["分步的解决方案",{"2":{"62":1}}],["分包设计",{"2":{"40":1}}],["分数告诉我们答案是否优于该组内的平均水平",{"2":{"18":1}}],["分数表明与同一组中的其他答案相比",{"2":{"18":1}}],["版本",{"2":{"115":1}}],["版本更新",{"0":{"40":1}}],["版权和协议",{"0":{"38":1}}],["代码层面并没有太多变化",{"2":{"92":1}}],["代码输出的正确性",{"2":{"75":1}}],["代码",{"0":{"39":1}}],["代理官方接口格式",{"0":{"161":1}}],["代理",{"2":{"16":2,"20":1,"75":1}}],["添加微信",{"2":{"37":1}}],["也就必须使用显存更高的机器",{"2":{"149":1}}],["也就是没有读取到springboot的application",{"2":{"155":1}}],["也就是我们最终会使用http",{"2":{"149":1}}],["也就是将文本细化",{"2":{"107":1}}],["也可以在这里编辑需要开通的模型",{"2":{"145":1}}],["也可以请作者喝一杯咖啡加入我的langchat交流群",{"2":{"37":1}}],["也有可能例如分段",{"2":{"109":1}}],["也是一个完整的java企业级应用案例",{"2":{"68":1}}],["也会有所帮助",{"2":{"47":1}}],["也更易于小型模型使用",{"2":{"4":1}}],["接口和ollama模型聊天",{"2":{"149":1}}],["接口已经掉通了",{"2":{"125":1}}],["接入api",{"2":{"40":1}}],["接单",{"2":{"37":1}}],["接下来需要将用户输入的问题转换成相同的向量纬度",{"2":{"86":1}}],["接下来",{"2":{"18":1,"81":1}}],["二开",{"2":{"37":1}}],["闲聊",{"2":{"37":1}}],["备注",{"2":{"37":2}}],["赞助",{"0":{"37":1},"2":{"37":1}}],["待完善",{"2":{"36":2}}],["钉钉等消息通信渠道",{"2":{"36":1}}],["飞书",{"2":{"36":1}}],["计划开发可视化llm流程设计器",{"2":{"36":1}}],["计划支持微信",{"2":{"36":1}}],["计划封装web",{"2":{"36":1}}],["计算限制",{"2":{"47":1}}],["计算损失",{"2":{"29":1}}],["计算每个输出的奖励",{"2":{"23":1}}],["计算效率更高",{"2":{"7":1}}],["集成rbac和aigc大模型能力",{"2":{"112":1}}],["集成web",{"2":{"36":1}}],["集成aigc大模型能力",{"2":{"34":1}}],["从上表中你可以查看到不同模型能生成什么维度的数据",{"2":{"133":1}}],["从向量数据库中检索相似的文本",{"2":{"110":1}}],["从向量库中匹配到相似的数据后",{"2":{"88":1}}],["从第三方加载数据并提供给llm",{"2":{"36":1}}],["从知识库中精确搜索",{"2":{"36":1}}],["从而提高",{"2":{"72":1}}],["从而提高其有效性和可靠性",{"2":{"46":1}}],["从而提高其性能并帮助其胜过所有其他模型",{"2":{"24":1}}],["从而显著减少内存使用量",{"2":{"51":1}}],["从而获得更准确的响应",{"2":{"46":1}}],["从而实现更快",{"2":{"44":1}}],["从而保持模型的学习稳定",{"2":{"18":1}}],["定制化prompt对话场景",{"2":{"36":1}}],["k",{"2":{"53":2,"63":1}}],["key就可以了",{"2":{"151":1}}],["key后在langchat模型管理页面配置模型信息即可",{"2":{"146":1}}],["key信息配置langchat",{"2":{"145":1}}],["keywork",{"2":{"110":1}}],["key",{"2":{"51":1,"144":1,"145":1}}],["key等信息",{"2":{"36":1}}],["kl",{"2":{"23":1}}],["支持基于",{"2":{"65":1}}],["支持本地",{"2":{"40":1}}],["支持iframe嵌入",{"2":{"40":1}}],["支持gitee",{"2":{"40":1}}],["支持不同的知识库关联不同的模型和向量数据库",{"2":{"36":1}}],["支持动态配置embedding模型和向量数据库",{"2":{"36":1}}],["支持定制化tool工具类",{"2":{"36":1}}],["支持embedding模型",{"2":{"36":1}}],["支持向量化知识库文档",{"2":{"36":1}}],["支持再页面上可视化动态配置大模型参数",{"2":{"36":1}}],["支持集成国内外数十家ai大模型",{"2":{"36":1}}],["支持的ai大模型",{"2":{"34":1,"112":1}}],["多数票",{"2":{"76":1}}],["多模块的形式开发",{"2":{"70":1}}],["多模态",{"2":{"36":1}}],["多渠道发布",{"2":{"36":1}}],["多样化组合",{"2":{"32":1}}],["跟我沟通",{"2":{"35":1}}],["希望有需要的朋友都可以加我微信",{"2":{"35":1}}],["商业化技术支持",{"0":{"141":1}}],["商业化支持",{"0":{"35":1}}],["商业应用请联系作者授权",{"2":{"38":1}}],["商用请联系作者授权",{"2":{"35":1}}],["远程部署到服务器",{"2":{"35":1}}],["技术支持",{"2":{"35":2}}],["技术报告的每个组成部分",{"2":{"13":1}}],["欢迎star",{"2":{"34":1}}],["讯飞星火",{"2":{"34":1,"112":1}}],["零一万物",{"2":{"34":1,"112":1}}],["抖音豆包",{"2":{"34":1,"112":1}}],["企业ai机器人",{"2":{"34":1,"112":1}}],["帮助企业快速定制ai知识库",{"2":{"34":1,"112":1}}],["帮助它学习和调整未来如何采取行动以获得更好的奖励",{"2":{"16":1}}],["随时可以部署",{"2":{"33":1}}],["随着时间的推移",{"2":{"23":1,"74":1}}],["监督式微调",{"2":{"33":1}}],["监督微调",{"0":{"29":1}}],["收集",{"2":{"33":1}}],["供社区使用",{"2":{"33":1}}],["之前",{"2":{"71":1}}],["之间取得良好平衡",{"2":{"32":1}}],["之后发布了另一个革命性的模型",{"2":{"0":1}}],["循环",{"2":{"32":1}}],["包括前端和后端",{"2":{"92":1}}],["包括令人反感的答案或无法拒绝有害的请求",{"2":{"72":1}}],["包括",{"2":{"72":1}}],["包括一个明确的",{"2":{"67":1}}],["包括推理问题",{"2":{"32":1}}],["包括语言一致性",{"2":{"30":1}}],["无论什么模型都在可以这里配置",{"2":{"160":1}}],["无论什么模型都将使用统一的请求响应格式",{"2":{"159":1}}],["无论用的哪个模型",{"2":{"133":1}}],["无论你下载哪个版本",{"2":{"115":1}}],["无论本地安装deepseek",{"2":{"114":1}}],["无论是企业开发",{"2":{"68":1}}],["无论是开源的还是封闭的",{"2":{"24":1}}],["无害",{"2":{"77":1}}],["无害性",{"2":{"32":2}}],["无法有效推理的实例",{"2":{"71":1}}],["无需手动创建",{"2":{"93":1}}],["无需重新训练巨型模型即可针对特定领域定制模型",{"2":{"56":1}}],["无需每次重启服务",{"2":{"36":1}}],["无感刷新",{"2":{"36":1}}],["步骤非常不同",{"2":{"73":1}}],["步骤",{"2":{"32":1,"73":1}}],["把它看作是让deepseek",{"2":{"32":1}}],["上面知识库配置成功后",{"2":{"136":1}}],["上面导入了知识库文档后",{"2":{"109":1}}],["上面导入的知识库文档",{"2":{"108":1}}],["上述配置完毕后",{"2":{"123":1}}],["上一步将文本转换为向量数据库需要存储到向量数据库中",{"2":{"84":1}}],["上找到",{"2":{"72":1}}],["上尝试同样的问题时",{"2":{"71":1}}],["上尝试了同样的提示",{"2":{"71":1}}],["上微调了",{"2":{"54":1}}],["上进行了训练",{"2":{"44":1}}],["上使用",{"2":{"44":2}}],["上训练前一个模型检查点",{"2":{"31":1}}],["上实现了",{"2":{"6":5}}],["非常简单",{"2":{"148":1}}],["非常直观详细",{"2":{"79":1}}],["非常适合延迟敏感的应用程序",{"2":{"56":1}}],["非常重要的语言一致性奖励",{"2":{"30":1}}],["非推理",{"2":{"31":1}}],["精炼推理",{"2":{"31":1}}],["精炼涉及将更大",{"2":{"2":1}}],["问答",{"2":{"31":1}}],["问题是状态",{"2":{"75":1}}],["问题的一个例子",{"2":{"74":1}}],["问题",{"2":{"29":1,"67":1,"71":1}}],["问题并真正让",{"2":{"25":1}}],["问题被输入到旧模型中",{"2":{"18":1}}],["写作任务",{"2":{"32":1}}],["写作",{"2":{"31":1}}],["用大量示例和高质量数据来训练",{"2":{"75":1}}],["用两个骰子掷出",{"2":{"67":1}}],["用于一般技能",{"2":{"31":1}}],["用户可以选择重新训练",{"2":{"108":1}}],["用户向系统输入问题",{"2":{"85":1}}],["用户",{"2":{"22":2}}],["用户提出问题",{"2":{"22":2}}],["用户和助手之间的对话",{"2":{"22":2}}],["万个样本",{"2":{"31":1}}],["约",{"2":{"31":1}}],["漫无边际的推理或不相关的代码",{"2":{"31":1}}],["严格的过滤器会删除混合语言",{"2":{"31":1}}],["只需要在langchat模型配置页面中选择openai配置不同的模型即可",{"2":{"160":1}}],["只需要在aigc平台",{"2":{"142":1}}],["只需要按照模型供应商官方文档配置apikey即可",{"2":{"143":1}}],["只需要按照langchat模型配置页面",{"2":{"143":1}}],["只需要从上述两个方面进行考虑即可",{"2":{"92":1}}],["只不过我们下载的模型只支持生成单维度的向量数据",{"2":{"133":1}}],["只能接受指定向量的数据",{"2":{"127":1}}],["只有转换成和文档相同的向量纬度",{"2":{"86":1}}],["只有正确且推理充分的最佳输出才会被保留",{"2":{"31":1}}],["只要提供正确的激励",{"2":{"78":1}}],["只要它保持语言一致性",{"2":{"30":1}}],["只保留最好的样本以生成高质量的训练数据",{"2":{"31":1}}],["错误",{"2":{"31":1}}],["团队能够创建性能良好的",{"2":{"33":1}}],["团队希望获得绝对最佳示例以进一步训练模型",{"2":{"31":1}}],["团队有意保持这个模板简单并专注于结构",{"2":{"22":1}}],["拒绝抽样",{"0":{"31":1},"2":{"31":1}}],["细化奖励",{"2":{"30":1}}],["细化过程",{"2":{"28":1}}],["语言一致性奖励如何略微提高正确答案的总奖励",{"2":{"30":1}}],["请检查本地idea的maven配置",{"2":{"154":1}}],["请手动创建langchat数据库",{"2":{"122":1}}],["请查看此博客",{"2":{"71":1}}],["请确保根据要提取的模型格式化数据",{"2":{"61":1}}],["请注意",{"2":{"30":1,"73":1}}],["请记住",{"2":{"19":1}}],["英语",{"2":{"30":1}}],["假设一只老鼠需要学习寻找食物",{"2":{"74":1}}],["假设它的推理也是",{"2":{"30":1}}],["假设奖励分配如下",{"2":{"23":1}}],["此错误一般都是因为配置模型使用了第三方代理产生的",{"2":{"156":1}}],["此错误是因为没有修改application",{"2":{"155":1}}],["此表的向量维度就固定了",{"2":{"127":1}}],["此脚本包含了创建名为langchat的数据库",{"2":{"120":1}}],["此脚本在启动容器的时候会自动创建langchat数据库",{"2":{"93":1}}],["此处的图表表示",{"2":{"76":1}}],["此步骤确保模型可以在没有",{"2":{"66":1}}],["此阶段使用来自拒绝采样的顶级示例进一步改进推理",{"2":{"31":1}}],["此过程会产生约",{"2":{"31":1}}],["此",{"2":{"30":1}}],["此输出因正确答案而获得完美的准确度奖励",{"2":{"30":1}}],["此版本标志着ai民主化和实现尖端推理模型的实际应用迈出了重要一步",{"2":{"12":1}}],["则",{"2":{"30":1}}],["则增加了更多的复杂性",{"2":{"17":1}}],["还是推荐调用api",{"2":{"115":1}}],["还是个人学习",{"2":{"68":1}}],["还优先考虑其他任务",{"2":{"77":1}}],["还记得",{"2":{"30":1}}],["还需要学习正确构建其推理",{"2":{"21":1}}],["微调后",{"2":{"53":1}}],["微调后的模型可能会忘记预训练阶段的一般知识",{"2":{"47":1}}],["微调需要结构化的输入输出对",{"2":{"50":1}}],["微调大型语言模型",{"2":{"48":1}}],["微调大规模",{"2":{"47":1}}],["微调模型可以继承数据集中存在的偏差",{"2":{"47":1}}],["微调模型中的偏差",{"2":{"47":1}}],["微调可能需要几天或几周的时间",{"2":{"47":1}}],["微调中的常见挑战及其克服方法",{"0":{"47":1}}],["微调使模型能够更高效地执行聊天机器人交互",{"2":{"46":1}}],["微调允许针对医疗保健",{"2":{"46":1}}],["微调之所以重要",{"2":{"46":1}}],["微调是将",{"2":{"46":1}}],["微调",{"2":{"44":1,"47":1}}],["微调像",{"2":{"44":1}}],["微调的",{"2":{"30":1}}],["微调过程从输入开始",{"2":{"29":1}}],["重点",{"2":{"148":1}}],["重启后",{"2":{"133":1}}],["重启langchat后端项目",{"2":{"133":1}}],["重新导入知识库文档",{"0":{"134":1}}],["重新评估其先前步骤等行为",{"2":{"78":1}}],["重新调整项目结构设计",{"2":{"40":1}}],["重复该过程",{"2":{"30":1}}],["重复许多输入目标对",{"2":{"29":1}}],["重要的是那些",{"2":{"22":1}}],["反向传播和优化器会调整模型的权重以",{"2":{"29":1}}],["意味着预测距离正确标记越远",{"2":{"29":1}}],["意味着模型将优先保持更接近旧模型的行为和输出",{"2":{"18":1}}],["损失越大",{"2":{"29":1}}],["流程",{"2":{"29":1}}],["第三方代理一般有两种接入方式",{"2":{"159":1}}],["第一次本地部署项目",{"2":{"103":1}}],["第",{"2":{"29":1,"31":1,"32":1}}],["us",{"2":{"150":1}}],["use",{"2":{"26":1,"27":1,"28":1,"51":1}}],["user",{"2":{"22":8,"29":1,"104":2}}],["ui前端",{"0":{"101":1}}],["ui",{"0":{"102":1},"2":{"70":1,"96":4,"101":1,"102":1,"123":1}}],["upms",{"2":{"70":1}}],["unload",{"2":{"66":1}}],["unsloth",{"2":{"44":4,"48":1,"49":4,"53":1,"54":1}}],["under",{"2":{"38":1}}],["ummm",{"2":{"28":1}}],["混乱的",{"2":{"28":1}}],["混乱的推理和语言混乱",{"2":{"24":1}}],["存在问题",{"2":{"28":1}}],["直接测试就能引用知识库的内容了",{"2":{"137":1}}],["直接运行此compose也可启动",{"2":{"122":1}}],["直接提示",{"0":{"27":1},"2":{"27":1}}],["直接的答案",{"2":{"15":1}}],["看看奖励如何随着这个新的语言一致性奖励而变化",{"2":{"30":1}}],["看看推理是否会自行出现",{"2":{"14":1}}],["看到这些示例后",{"2":{"26":1}}],["东西只是将推理步骤与摘要分开的标记",{"2":{"26":1}}],["那我们进行一下向量检索测试",{"2":{"135":1}}],["那么",{"2":{"74":1}}],["那么我们需要了解",{"2":{"15":1}}],["那时我决定需要进一步调查",{"2":{"71":1}}],["那些",{"2":{"26":1}}],["fp16=true",{"2":{"64":1}}],["float16",{"2":{"62":1,"67":1}}],["flash",{"2":{"60":1,"62":2}}],["f",{"2":{"52":1,"61":2}}],["france",{"2":{"50":2}}],["front",{"2":{"34":1,"140":1}}],["from",{"2":{"27":1,"49":2,"50":1,"51":1,"61":2,"62":3,"63":1,"64":1,"65":2,"67":3,"110":1}}],["factor",{"2":{"63":1}}],["face",{"2":{"50":1}}],["fastlanguagemodel",{"2":{"49":2,"51":1}}],["far",{"2":{"26":1}}],["function",{"2":{"36":1,"50":2}}],["following",{"2":{"26":1}}],["formatted",{"2":{"61":3}}],["format",{"2":{"50":1,"61":3}}],["formula",{"2":{"26":1}}],["fork",{"2":{"34":1}}],["for",{"2":{"26":1,"50":1,"61":1,"62":1}}],["file",{"2":{"122":1}}],["files=",{"2":{"50":1}}],["final",{"2":{"66":4,"67":2}}],["finance",{"2":{"59":1}}],["finetuned",{"2":{"52":2,"64":1,"65":2,"66":2,"67":2}}],["fine",{"2":{"51":1,"67":1}}],["find",{"2":{"26":1}}],["first",{"2":{"22":2,"26":2}}],["|end|",{"2":{"61":1}}],["|end|>",{"2":{"61":2,"67":1}}],["|assistant|",{"2":{"61":1}}],["|assistant|>",{"2":{"53":1,"61":1,"67":1}}],["|user|",{"2":{"61":1}}],["|user|>",{"2":{"61":1,"67":1}}],["|user|>what",{"2":{"53":1}}],["|",{"2":{"26":14,"27":4,"28":6,"29":2}}],["就必然会出现类似此报错信息",{"2":{"133":1}}],["就用默认的安装命令",{"2":{"117":1}}],["就会变成英语和西班牙语的混杂",{"2":{"24":1}}],["就像他们在后期阶段可能会做的那样",{"2":{"19":1}}],["就像一步一步升级一样",{"2":{"14":1}}],["就像从无到有一样",{"2":{"14":1}}],["突然间",{"2":{"24":1}}],["让",{"2":{"75":1}}],["让模型来定义它的含义",{"2":{"24":1}}],["让我们假设一个用于遵循指令任务的数据集",{"2":{"50":1}}],["让我们探索如何使用",{"2":{"44":1}}],["让我们看看这些奖励如何与我们的示例输出一起发挥作用",{"2":{"30":1}}],["让我们看看原始模板并将其逐一分解",{"2":{"22":1}}],["让我们重新回顾之前的示例输出",{"2":{"30":1}}],["让我们直观地了解一下这个语言一致性奖励计算",{"2":{"30":1}}],["让我们直观地了解这个基于示例的学习",{"2":{"26":1}}],["让我们计算平均第一个奖励",{"2":{"23":1}}],["让我们使用我们的文本输入来了解创建",{"2":{"19":1}}],["让我们将其可视化",{"2":{"18":1}}],["让我们放大一下",{"2":{"18":1}}],["让我们逐一分解",{"2":{"18":1}}],["让我们首先直观地了解它的工作原理",{"2":{"16":1}}],["你能在langchat页面看到如下切面信息",{"2":{"135":1}}],["你在最初阶段就应该考虑哪种模型兼容哪种向量维度",{"2":{"133":1}}],["你应该会收到如下向量化失败错误",{"2":{"132":1}}],["你需要安装两者才行",{"2":{"122":1}}],["你需要再mysql8下创建一个名为langchat的数据库",{"2":{"98":1}}],["你需要已经准备好了开发环境",{"2":{"94":1}}],["你一定听说过",{"2":{"75":1}}],["你可以访问",{"2":{"114":1}}],["你可以在控制台直接交互",{"2":{"118":1}}],["你可以在本地创建application",{"2":{"99":1}}],["你可以在新数据可用时不断完善它",{"2":{"59":1}}],["你可以使用官方提供的本地安装方式",{"2":{"93":1}}],["你可以试用它们",{"2":{"72":1}}],["你可以通过在你的环境中使用",{"2":{"61":1}}],["你可以将其视为在真正激烈的",{"2":{"25":1}}],["你通常需要一个在真实世界场景中表现比任何预蒸馏模型都更好的模型",{"2":{"59":1}}],["你正在构建一个金融预测聊天机器人",{"2":{"59":1}}],["你将获得更小",{"2":{"33":1}}],["你必须使用特定的问题解决策略",{"2":{"24":1}}],["你必须使用反思性推理",{"2":{"24":1}}],["你必须使用分步推理",{"2":{"24":1}}],["你会奖励它",{"2":{"14":1}}],["甚至很好地处理了一般任务",{"2":{"32":1}}],["甚至为错误答案",{"2":{"30":1}}],["甚至在",{"2":{"24":1}}],["甚至可能是负奖励",{"2":{"20":1}}],["研究人员必须与人类价值观进行最后的调整",{"2":{"32":1}}],["研究人员引入了推理导向学习",{"2":{"30":1}}],["研究人员进行了冷启动数据收集并包括监督微调",{"2":{"25":1}}],["研究人员发现训练后的模型在推理测试中表现非常出色",{"2":{"24":1}}],["研究人员设计了一个特定的训练模板",{"2":{"22":1}}],["后缀",{"2":{"159":3}}],["后面将详细说明",{"2":{"143":1}}],["后面的部分就是引用的知识库文档",{"2":{"139":1}}],["后面langchat会做前端适配",{"2":{"125":1}}],["后端会提示向量化成功",{"2":{"134":1}}],["后端运行langchatapp",{"2":{"100":1}}],["后端",{"2":{"96":1}}],["后端的基础环境要求如下",{"2":{"92":1}}],["后端基础环境",{"0":{"92":1}}],["后端基于springboot3",{"2":{"68":1}}],["后端技术",{"2":{"68":1}}],["后台地址",{"2":{"34":1}}],["后处理细化",{"0":{"28":1}}],["后",{"2":{"24":1,"33":1}}],["90",{"2":{"61":1}}],["9",{"0":{"24":1,"88":1},"2":{"26":2}}],["94",{"2":{"6":2}}],["🚀",{"2":{"23":1}}],["整套服务从空服务器",{"2":{"141":1}}],["整理多样化且无偏差的数据集",{"2":{"47":1}}],["整体训练循环如下所示",{"2":{"23":1}}],["整个重点是让这些语言模型更好地思考问题并为你提供明智的答案",{"2":{"14":1}}],["始终使用正确的格式",{"2":{"23":1}}],["提出了一个模型",{"2":{"71":2}}],["提炼模型基准测试",{"2":{"58":1}}],["提炼模型是开源的",{"2":{"7":1}}],["提高准确性",{"2":{"46":1}}],["提示",{"2":{"29":1,"32":1}}],["提示或问题描述本身",{"2":{"29":1}}],["提示可能是",{"2":{"27":1}}],["提供aigc客户端应用",{"2":{"36":1}}],["提供项目二开合作",{"2":{"35":1}}],["提供项目架构讲解和aigc产品设计",{"2":{"35":1}}],["提供项目部署服务",{"2":{"35":1}}],["提供前后端nginx配置脚本",{"2":{"35":1}}],["提供docker一键部署脚本",{"2":{"35":1}}],["提供一些列商业化服务",{"2":{"35":1}}],["提供小幅正奖励",{"2":{"30":1}}],["提供了",{"2":{"30":1}}],["提供了一些问题示例以及非常详细的分步解决方案",{"2":{"26":1}}],["提供逻辑推理步骤",{"2":{"23":1}}],["每种方法都有各自的优点",{"2":{"57":1}}],["每次迭代逐渐提高模型结构化推理能力",{"2":{"29":1}}],["每次迭代都会逐渐提高模型的能力",{"2":{"23":1}}],["每个",{"2":{"61":1}}],["每个示例包括",{"2":{"61":1}}],["每个示例都展示了良好的逐步推理",{"2":{"28":1}}],["每个输出都根据以下条件分配奖励",{"2":{"23":1}}],["每个输出将根据正确性和推理质量进行评估并分配奖励",{"2":{"23":1}}],["工作",{"2":{"23":1}}],["发布了一篇名为",{"2":{"75":1}}],["发布了基于",{"2":{"58":1}}],["发散惩罚",{"2":{"23":1}}],["发现蒸馏通常能以更低的计算成本获得更好的性能",{"2":{"8":1}}],["发现的强大推理模式",{"2":{"3":1}}],["防止过大的更新",{"2":{"23":1}}],["裁剪机制",{"2":{"23":1}}],["获得此冷启动数据后",{"2":{"28":1}}],["获得负优势",{"2":{"23":1}}],["获得正优势",{"2":{"23":1}}],["近似值",{"2":{"23":1}}],["标记推理的结束",{"2":{"62":1}}],["标记推理的开始",{"2":{"62":1}}],["标记回合的结束",{"2":{"61":1}}],["标记模型响应的开始",{"2":{"61":1}}],["标记用户查询的开始",{"2":{"61":1}}],["标准差",{"2":{"23":1}}],["标签内加入思考标记的",{"2":{"75":1}}],["标签内的推理过程难以阅读",{"2":{"24":1}}],["标签内的内容",{"2":{"20":1}}],["标签正确格式化",{"2":{"23":1}}],["标签中",{"2":{"22":2}}],["标签",{"2":{"21":1,"22":1,"23":1}}],["标签包含",{"2":{"20":1}}],["平均奖励计算",{"2":{"23":1}}],["平均的含义",{"2":{"18":1}}],["总奖励",{"2":{"23":1}}],["输入嵌入",{"0":{"86":1}}],["输入问题并检索",{"0":{"85":1}}],["输入",{"2":{"29":1}}],["输入将如下所示",{"2":{"22":1}}],["输出最终的语义化文本内容给用户",{"2":{"89":1}}],["输出了正确的答案",{"2":{"75":1}}],["输出可能是",{"2":{"28":1}}],["输出",{"2":{"23":3,"33":2}}],["一定要在baseurl后面增加",{"2":{"159":3}}],["一个干净客观的奖励函数允许",{"2":{"78":1}}],["一个简单的编程问题",{"2":{"75":1}}],["一个策略函数",{"2":{"74":1}}],["一个是给出良好的输出",{"2":{"18":1}}],["一种专为高效模型自适应而设计的框架",{"2":{"44":1}}],["一旦达到这种平衡",{"2":{"32":1}}],["一般情况第三方代理会提示修改baseurl为xxxx",{"2":{"156":1}}],["一般",{"2":{"32":1}}],["一致说话",{"2":{"32":1}}],["一致性奖励计算",{"2":{"30":1}}],["一致",{"2":{"28":1}}],["一些胡言乱语的推理",{"2":{"23":1}}],["采用gun",{"2":{"38":1}}],["采样一组",{"2":{"23":1}}],["采取行动后",{"2":{"16":1}}],["采取行动的参与者",{"2":{"16":1}}],["生成api",{"2":{"146":1}}],["生成和格式化数据集",{"0":{"61":1}}],["生成奖励模型用于判断推理质量",{"2":{"31":1}}],["生成多个输出",{"2":{"30":1}}],["生成多个可能的输出",{"2":{"23":1}}],["生成输出",{"2":{"23":1}}],["生成的思维链推理示例被清理",{"2":{"77":1}}],["生成的下一个标记",{"2":{"75":1}}],["生成的输出",{"2":{"20":1}}],["生成的",{"2":{"4":1,"61":1}}],["=16g内存",{"2":{"117":1}}],["=",{"2":{"22":4,"23":6,"26":5,"27":2,"28":1,"29":1,"30":7,"49":3,"50":5,"51":2,"52":1,"61":7,"62":5,"63":1,"64":1,"65":2,"66":1,"67":5}}],["windows",{"2":{"122":1}}],["within",{"2":{"22":2}}],["with",{"2":{"22":2,"26":1,"62":1,"67":1}}],["workspace",{"2":{"70":3}}],["workflows",{"2":{"36":1}}],["warmup",{"2":{"64":1}}],["write",{"2":{"50":1}}],["www",{"2":{"34":1,"147":1}}],["welcome",{"2":{"152":1}}],["web",{"2":{"99":1}}],["web消息渠道",{"2":{"40":1}}],["we",{"2":{"28":1}}],["where",{"2":{"110":1}}],["which",{"2":{"26":1,"28":1}}],["what",{"2":{"22":1,"26":2,"27":1,"29":1,"50":1,"67":1}}],["时",{"2":{"22":1,"29":1,"71":1}}],["助手",{"2":{"22":2}}],["助手首先在脑海中思考推理过程",{"2":{"22":2}}],["助手解决该问题",{"2":{"22":2}}],["翻译等",{"2":{"31":1}}],["翻译",{"2":{"22":3}}],["implementation=",{"2":{"62":1}}],["import",{"2":{"49":1,"50":1,"51":1,"61":1,"62":1,"63":1,"64":1,"65":2,"67":1}}],["idea打开后会自动加载maven依赖",{"2":{"96":1}}],["id=tokenizer",{"2":{"67":1}}],["id",{"2":{"62":3,"67":2}}],["isolation",{"2":{"60":1}}],["is",{"2":{"22":1,"26":6,"27":3,"28":2,"29":2,"50":4,"53":1,"99":1,"129":1}}],["i",{"2":{"22":2,"27":1}}],["invalid",{"0":{"156":1,"158":1}}],["internal",{"2":{"70":1}}],["introduction",{"2":{"34":1}}],["inputs",{"2":{"50":4}}],["instruct",{"2":{"62":1}}],["instruction=inst",{"2":{"50":1}}],["instruction",{"2":{"50":6,"61":4}}],["inst",{"2":{"50":1}}],["installation",{"2":{"122":1}}],["install",{"2":{"48":1,"60":1,"91":1,"96":2,"101":1,"102":1}}],["in",{"2":{"22":2,"49":1,"50":1}}],["it",{"2":{"22":2}}],["quickstart",{"2":{"151":1}}],["quickstarts",{"2":{"151":1}}],["quot",{"2":{"92":3}}],["question",{"2":{"22":2}}],["q8",{"2":{"53":1}}],["q4",{"2":{"53":1}}],["q",{"2":{"51":1,"60":1,"63":1}}],["qa",{"2":{"32":1}}],["qwq",{"2":{"6":1}}],["qwen",{"2":{"0":1,"4":1,"5":5,"6":2,"8":3,"11":1,"33":1,"44":1,"58":2}}],["指令",{"2":{"61":1}}],["指导",{"2":{"22":1}}],["指的是对一组答案",{"2":{"18":1}}],["指的是评估在许多不同情况下平均发生的情况",{"2":{"18":1}}],["格式使所有内容统一且易于处理",{"2":{"28":1}}],["格式更好",{"2":{"28":1}}],["格式奖励",{"2":{"23":2}}],["格式奖励过程",{"2":{"21":1}}],["格式化奖励",{"0":{"21":1}}],["正常情况",{"2":{"133":1,"134":1,"135":1}}],["正常情况下我们的聊天都是sse类型流式接口",{"2":{"158":1}}],["正常情况下",{"2":{"117":1}}],["正常启动项目",{"2":{"99":1}}],["正确的最终答案",{"2":{"75":1}}],["正确但缺少标签",{"2":{"23":1}}],["正确",{"2":{"23":2,"31":1}}],["正确设置格式的奖励较少",{"2":{"21":1}}],["正如你已经知道的那样",{"2":{"17":1}}],["正如我之前所说",{"2":{"15":1}}],["txt文档",{"2":{"138":1}}],["ts",{"2":{"70":2}}],["turbo",{"2":{"70":1}}],["tuned",{"2":{"67":1}}],["tune",{"2":{"51":1}}],["two",{"2":{"67":1}}],["typescript",{"2":{"68":1}}],["type=",{"2":{"63":1,"64":1}}],["type",{"0":{"156":1,"158":1},"2":{"53":1,"63":1}}],["tycoding",{"2":{"34":1,"38":1,"43":2,"95":1,"112":1,"119":1,"140":1}}],["trl",{"2":{"65":1}}],["trust",{"2":{"62":2}}],["truncation=true",{"2":{"50":1}}],["transformers",{"2":{"48":1,"51":1,"60":1,"62":1,"64":1,"65":1,"67":1}}],["travels",{"2":{"26":2}}],["training",{"2":{"64":1,"65":1}}],["trainingarguments",{"2":{"64":2}}],["trainer",{"2":{"51":4,"52":1,"65":4,"66":1}}],["train",{"2":{"26":2,"50":2,"51":3,"61":3,"64":2,"65":3}}],["tab=readme",{"2":{"122":1}}],["target",{"2":{"51":1,"63":2}}],["task",{"2":{"50":1,"63":2}}],["tags",{"2":{"22":2}}],["tea",{"2":{"70":1}}],["temperature=0",{"2":{"67":1}}],["template",{"2":{"50":2}}],["terms",{"2":{"63":1}}],["text模型后",{"2":{"132":1}}],["text",{"0":{"156":1},"2":{"61":1,"67":2,"70":1,"128":1,"129":2,"130":1,"133":1}}],["test",{"2":{"50":2,"51":1,"61":3,"65":1}}],["tensor",{"2":{"11":1}}],["time",{"2":{"26":2}}],["times",{"2":{"26":1}}],["torch",{"2":{"48":1,"60":1,"62":1,"67":1}}],["total",{"2":{"30":1}}],["to",{"2":{"26":2,"27":3,"28":2,"29":1,"151":1}}],["tokens=5000",{"2":{"67":1}}],["tokens",{"2":{"62":6}}],["token=",{"2":{"61":1}}],["tokenized",{"2":{"50":1}}],["tokenizer=tokenizer",{"2":{"51":1,"65":1,"67":1}}],["tokenizer",{"0":{"49":1},"2":{"49":1,"50":1,"52":2,"62":5,"65":1,"66":1,"67":2}}],["token",{"2":{"26":7,"27":2,"28":3,"29":1,"61":1,"62":3,"67":3,"68":1}}],["threads",{"2":{"53":1}}],["that",{"2":{"50":2}}],["this",{"2":{"27":1,"28":1}}],["think>first",{"2":{"61":1}}],["think>",{"2":{"22":12,"28":2,"30":4,"61":1,"62":2}}],["thinks",{"2":{"22":2}}],["think",{"2":{"21":3,"22":8,"23":7,"62":4,"75":2,"125":1}}],["then",{"2":{"22":2,"26":2,"28":1,"61":1}}],["the",{"2":{"22":16,"26":5,"27":2,"28":2,"29":2,"38":1,"50":4,"52":2,"61":2,"63":1,"67":1,"129":1}}],["奖励是根据以下条件自动确定的",{"2":{"75":1}}],["奖励函数不再基于",{"2":{"75":1}}],["奖励由奖励",{"2":{"75":1}}],["奖励细分",{"2":{"23":1}}],["奖励训练模板",{"0":{"22":1}}],["奖励",{"2":{"20":1}}],["比如说",{"2":{"20":1}}],["并不是直接填写api",{"2":{"151":1}}],["并不是生成1024维度的数据",{"2":{"133":1}}],["并接收768维度的向量",{"2":{"133":1}}],["并结合向量库中匹配到的相似的数据分析",{"2":{"89":1}}],["并用于微调",{"2":{"77":1}}],["并在一组预定的测试用例上进行评估",{"2":{"75":1}}],["并采用最新的技术栈开发",{"2":{"68":1}}],["并安装必要的依赖项",{"2":{"48":1}}],["并超越其他模型的性能",{"2":{"32":1}}],["并将匹配结果吐给llm",{"2":{"110":1}}],["并将这些知识蒸馏成一个已经了解金融细微差别的较小模型",{"2":{"59":1}}],["并将模型推广到更广泛的任务",{"2":{"31":1}}],["并将最终答案包含在",{"2":{"21":1}}],["并通过强化学习推动它变得更好",{"2":{"30":1}}],["并要求它学习模仿这种风格",{"2":{"29":1}}],["并纠正任何错误",{"2":{"28":1}}],["并让人类标注者使其更清晰",{"2":{"28":1}}],["并降低具有低优势或负优势的输出",{"2":{"23":1}}],["并且模型名称是nomic",{"2":{"129":1}}],["并且模型会因",{"2":{"75":1}}],["并且可以查看文档是否已经被训练",{"2":{"108":1}}],["并且可以使用",{"2":{"21":1}}],["并且知道在给定文本序列的情况下它们可以预测哪些单词",{"2":{"72":1}}],["并且表现优于开源和闭源模型",{"2":{"13":1}}],["并专门检查",{"2":{"20":1}}],["系统会重新生成此表",{"2":{"133":1}}],["系统将通过embedding模型向量化文档数据",{"2":{"109":1}}],["系统将交由llm",{"2":{"88":1}}],["系统",{"2":{"79":1}}],["系统知道正确答案是",{"2":{"20":1}}],["系列",{"2":{"0":2,"4":1}}],["基础概念",{"0":{"114":1}}],["基础模型是预训练后立即出现的",{"2":{"72":1}}],["基础模型",{"0":{"72":1},"2":{"72":1}}],["基础模型其行动有多好",{"2":{"16":1}}],["基准上的准确率",{"2":{"76":1}}],["基准的准确率会随着训练迭代次数的增加而提高",{"2":{"76":1}}],["基准性能",{"2":{"59":1}}],["基于这",{"2":{"33":1}}],["基于示例的学习",{"2":{"26":1}}],["基于规则的奖励系统应运而生",{"2":{"23":1}}],["基于规则的检查",{"0":{"20":1},"2":{"20":1}}],["基本上任意笔记本都能安装",{"2":{"115":1}}],["基本上",{"2":{"25":1,"29":1}}],["确保了问题和文本块都位于同一向量空间中",{"2":{"86":1}}],["确保你拥有",{"2":{"48":1}}],["确保更新不会偏离原始模型太远",{"2":{"23":1}}],["确保模型逐渐学习并且不会疯狂跳跃",{"2":{"18":1}}],["确保变化不会太剧烈",{"2":{"18":1}}],["值控制模型应保持与参考模型的接近程度",{"2":{"18":1}}],["bce",{"2":{"145":1}}],["blue",{"2":{"129":1}}],["book",{"2":{"148":1}}],["bootstrap",{"2":{"70":2}}],["bom",{"2":{"70":1}}],["both",{"2":{"61":1}}],["bodmas",{"2":{"26":1,"29":1}}],["build",{"2":{"60":1}}],["biz",{"2":{"70":3}}],["bias",{"2":{"63":1}}],["bias=",{"2":{"51":1,"63":1}}],["bitsandbytes",{"2":{"48":1,"60":1}}],["bnb",{"2":{"49":1}}],["b",{"2":{"47":1}}],["baidu",{"2":{"145":1}}],["bashcd",{"2":{"96":1}}],["bashgit",{"2":{"95":1}}],["bash",{"2":{"91":3}}],["baseurl填写",{"2":{"130":1}}],["baseulr写",{"2":{"124":1}}],["base",{"2":{"16":1,"22":1,"23":2,"25":1,"26":1,"29":2}}],["baptiste",{"2":{"79":1}}],["batch",{"2":{"64":2}}],["batched=false",{"2":{"61":1}}],["batched=true",{"2":{"50":1}}],["backend",{"2":{"34":1,"140":1}}],["by",{"2":{"27":1,"28":1,"61":1}}],["bean",{"0":{"155":2}}],["because",{"2":{"129":1}}],["below",{"2":{"50":1}}],["before",{"2":{"22":1,"26":1,"27":2,"28":1}}],["between",{"2":{"22":2}}],["beta",{"2":{"18":2}}],["本教程给使用langchat的朋友学习如何本地部署deepseek",{"2":{"111":1}}],["本地下载embedding模型",{"0":{"128":1}}],["本地电脑就已经安装好了deepseek",{"2":{"117":1}}],["本地测试而言",{"2":{"115":1}}],["本地启动项目",{"0":{"94":1},"1":{"95":1,"96":1,"97":1,"98":1,"99":1,"100":1,"101":1,"102":1}}],["本地部署llama",{"2":{"53":1}}],["本项目选择使用",{"2":{"92":1}}],["本项目后端采用java单体服务",{"2":{"70":1}}],["本项目不可商用",{"2":{"35":1}}],["本例中为英语",{"2":{"30":1}}],["本质上",{"2":{"18":1}}],["本文将提炼模型与使用大规模",{"2":{"8":1}}],["本文开源了基于不同大小的",{"2":{"5":1}}],["方程",{"2":{"18":1}}],["好答案奖励",{"2":{"18":1}}],["结构和措辞",{"2":{"46":1}}],["结构化的推理输出",{"2":{"29":1}}],["结果如何",{"0":{"76":1}}],["结果",{"2":{"33":1}}],["结果是",{"2":{"18":1}}],["结束语",{"0":{"12":1,"54":1,"78":1}}],["相似",{"2":{"76":1}}],["相媲美",{"2":{"71":2}}],["相同",{"2":{"18":1}}],["相反",{"2":{"14":1}}],["乘以其优势分数",{"2":{"18":1}}],["×",{"2":{"18":2}}],["hl=zh",{"2":{"151":1}}],["hutool",{"2":{"68":1}}],["hub",{"2":{"67":1}}],["huggingface",{"2":{"67":1,"72":1}}],["hugging",{"2":{"50":1}}],["hf",{"2":{"61":1}}],["html",{"0":{"156":1},"2":{"58":1,"122":1}}],["http端口",{"2":{"114":1}}],["https",{"2":{"34":2,"43":2,"58":1,"91":6,"93":1,"95":1,"112":2,"115":1,"116":1,"119":3,"122":2,"128":1,"140":1,"145":1,"146":1,"147":1,"148":1,"150":1,"151":1,"152":1}}],["http",{"2":{"34":5,"101":1,"102":1,"112":1,"114":1,"118":1,"124":1,"129":2,"130":1,"140":3,"149":1}}],["hinton",{"2":{"56":1}}],["history",{"0":{"41":1}}],["how",{"2":{"26":1}}],["hours",{"2":{"26":2}}],["here",{"2":{"22":4}}],["h",{"2":{"18":1}}],["限制由一个称为",{"2":{"18":1}}],["以艰难的方式",{"2":{"77":1}}],["以及类似的错误",{"2":{"157":1}}],["以及如何使用langchat的agent功能构建知识库",{"2":{"111":1}}],["以及ai应用集成方案",{"2":{"68":1}}],["以及好多少",{"2":{"18":1}}],["以实现高效微调",{"0":{"63":1}}],["以在各种任务中表现良好",{"2":{"59":1}}],["以下是基础开发环境要求",{"2":{"90":1}}],["以下是推荐的配置",{"2":{"48":1}}],["以下是一些最常见的挑战及其解决方案",{"2":{"47":1}}],["以上",{"2":{"35":1}}],["以匹配",{"2":{"33":1}}],["以根据来自这些多样化数据的组合奖励信号优化模型",{"2":{"32":1}}],["以生成结构良好的响应",{"2":{"29":1}}],["以便更容易解释",{"2":{"29":1}}],["以增加生成具有高优势的输出",{"2":{"23":1}}],["以防止奖励黑客攻击并降低初始探索阶段的复杂性",{"2":{"21":1}}],["以防止偏差太大",{"2":{"18":1}}],["以反映其好坏程度或可取性",{"2":{"17":1}}],["组中答案分数的差异有多大",{"2":{"18":1}}],["组中分数的分布",{"2":{"18":1}}],["组中所有答案的平均奖励分数",{"2":{"18":1}}],["组的平均分数",{"2":{"18":1}}],["旧模型给出相同答案的可能性有多大",{"2":{"18":1}}],["旧策略",{"2":{"17":2}}],["新模型给出特定答案的可能性有多大",{"2":{"18":1}}],["告诉我们使用新模型给出此答案的几率是增加还是减少",{"2":{"18":1}}],["creating",{"0":{"155":1}}],["create",{"2":{"67":1}}],["c=embedding",{"2":{"128":1}}],["cd",{"2":{"96":1}}],["cspell",{"2":{"70":1}}],["custom",{"2":{"62":4}}],["cpp",{"2":{"53":2}}],["cpu",{"2":{"47":1}}],["causal",{"2":{"63":1}}],["cache",{"2":{"53":1}}],["capital",{"2":{"50":2}}],["call",{"2":{"36":1}}],["calculation",{"2":{"27":1}}],["calculate",{"2":{"26":1,"27":1}}],["cloud",{"2":{"151":2}}],["clone下来的代码",{"2":{"97":1}}],["clone",{"0":{"95":1},"2":{"95":1}}],["client分离的架构设计",{"2":{"104":1}}],["client前端",{"0":{"102":1}}],["client",{"2":{"96":2,"102":1}}],["client端业务架构",{"2":{"40":1}}],["cli",{"2":{"53":1}}],["claude",{"2":{"6":1,"34":1,"112":1}}],["c",{"2":{"38":1,"47":1}}],["cnv",{"2":{"53":1}}],["cn",{"2":{"34":5,"43":1,"112":1,"140":3,"147":1,"151":1}}],["charset=utf",{"0":{"156":1}}],["chat",{"2":{"67":3,"149":1}}],["changeratio",{"2":{"18":4}}],["checkpointing=true",{"2":{"51":1}}],["checking",{"2":{"27":1}}],["code",{"2":{"70":1}}],["code=true",{"2":{"62":2}}],["core",{"2":{"70":1}}],["cosine",{"2":{"64":1}}],["collator=data",{"2":{"65":1}}],["collator",{"2":{"65":4}}],["column",{"2":{"61":1}}],["columns=subset",{"2":{"61":1}}],["colab",{"2":{"47":1}}],["copyright",{"2":{"38":1}}],["compose一键部署脚本",{"2":{"93":1}}],["completes",{"2":{"50":1}}],["common",{"2":{"70":7}}],["com",{"2":{"34":2,"43":2,"91":4,"93":1,"95":1,"103":1,"112":2,"115":1,"116":1,"119":3,"122":2,"128":1,"140":1,"143":1,"145":1,"146":1,"148":1,"150":1,"151":1,"152":1}}],["comes",{"2":{"27":1}}],["content",{"0":{"156":1,"158":1}}],["consider",{"0":{"155":1}}],["consistency",{"2":{"30":1}}],["console",{"2":{"145":1}}],["config=peft",{"2":{"65":1}}],["config",{"2":{"63":1,"65":2,"70":3,"91":6}}],["conversation",{"2":{"22":2}}],["cot",{"0":{"26":1},"2":{"26":1,"61":3}}],["∑",{"2":{"18":1}}],["答案的正确性",{"2":{"75":1}}],["答案的分数",{"2":{"18":1}}],["答案是否正确",{"2":{"23":1}}],["答案在这里",{"2":{"22":2}}],["答案可能性的变化",{"2":{"18":1}}],["答案有多好或多差",{"2":{"18":1}}],["答案",{"2":{"18":6,"31":1}}],["nginx脚本",{"2":{"141":1}}],["npmjs",{"2":{"91":2}}],["npmmirror",{"2":{"91":3}}],["npmyarnpnpm",{"2":{"91":1}}],["npm",{"2":{"91":3}}],["naiveui",{"2":{"68":1}}],["names",{"2":{"61":1}}],["name=model",{"2":{"49":1}}],["name",{"2":{"49":2}}],["num",{"2":{"64":1}}],["nomic",{"2":{"128":1,"129":1,"130":1,"133":1}}],["notes",{"2":{"122":1}}],["node",{"2":{"68":1,"70":1,"91":1}}],["norm=0",{"2":{"64":1}}],["no",{"2":{"53":1,"60":1,"63":1}}],["none",{"2":{"51":1,"63":1}}],["new",{"2":{"67":1,"151":1}}],["nextjs全栈",{"2":{"37":1}}],["need",{"2":{"27":1}}],["n",{"2":{"18":1,"53":1,"61":5}}],["或者是模型信息填写的有错误导致模型配置加载失败",{"2":{"157":1}}],["或者本地用nginx搭建本地文件服务器",{"2":{"121":1}}],["或者",{"2":{"115":1}}],["或者录入文本数据进行向量化解析",{"2":{"107":1}}],["或者想要深入交流java生态aigc产品开发",{"2":{"37":1}}],["或任何其他部署框架部署",{"2":{"61":1}}],["或基于云的服务",{"2":{"47":1}}],["或数字相同的内容",{"2":{"20":1}}],["或",{"2":{"18":2,"47":2,"91":1}}],["auth定义了后台管理系统超级管理员账号的登录信息",{"2":{"99":1}}],["auth",{"2":{"70":3}}],["auto",{"2":{"62":1,"67":2}}],["automodelforcausallm",{"2":{"62":2,"67":1}}],["autotokenizer",{"2":{"62":2,"67":1}}],["aliyun",{"2":{"146":1}}],["align",{"2":{"61":1}}],["alpha16",{"2":{"67":1}}],["alpha=16",{"2":{"63":1}}],["alpha=32",{"2":{"51":1}}],["application",{"0":{"158":1},"2":{"93":1,"99":2}}],["apps",{"2":{"70":1}}],["appropriately",{"2":{"50":1}}],["api平台的代理接口方式",{"2":{"159":1}}],["apikey调用受限制",{"2":{"158":1}}],["apikey无效",{"2":{"158":1}}],["apikey任意填",{"2":{"124":1}}],["api",{"2":{"56":1,"129":2,"145":1,"149":1}}],["arxiv",{"2":{"58":1}}],["args",{"2":{"51":1,"64":1,"65":1}}],["args=training",{"2":{"51":1,"65":1}}],["are",{"2":{"22":2}}],["aws",{"2":{"47":1}}],["amp",{"0":{"95":1},"2":{"35":2,"69":1}}],["azure",{"2":{"34":1,"112":1,"150":1}}],["accumulation",{"2":{"64":1}}],["accuracy",{"2":{"30":1}}],["accelerate",{"2":{"48":1,"60":1}}],["according",{"2":{"29":1}}],["again",{"2":{"27":1}}],["attn",{"2":{"60":1,"62":1}}],["attention",{"2":{"51":1,"62":2,"63":1}}],["at",{"2":{"26":1}}],["adrien分享了使用",{"2":{"79":1}}],["administrator",{"2":{"103":1}}],["admin",{"2":{"70":1}}],["adamw",{"2":{"64":1}}],["additional",{"2":{"62":1}}],["addition",{"2":{"26":1,"27":2,"28":1}}],["add",{"2":{"22":1,"26":2,"27":1,"28":2,"62":2}}],["advantage",{"2":{"18":4}}],["about",{"2":{"22":2}}],["asks",{"2":{"22":2}}],["assistant",{"2":{"22":8,"29":1}}],["anthropic",{"2":{"152":1}}],["an",{"2":{"50":1}}],["and",{"2":{"22":10,"27":1,"28":1,"52":1,"66":1}}],["answer>",{"2":{"22":12,"28":2,"30":4}}],["answer",{"2":{"20":2,"21":3,"22":14,"23":8,"26":2,"27":1,"28":1,"29":1,"50":1}}],["a",{"0":{"155":1},"2":{"22":4,"47":1,"50":2,"67":1}}],["averageresult",{"2":{"18":1}}],["ai应用",{"0":{"136":1},"1":{"137":1,"138":1,"139":1},"2":{"136":1}}],["aigc产品开发思路",{"2":{"141":1}}],["aigc产品研发",{"2":{"34":1}}],["aigc",{"2":{"70":1,"104":1}}],["ai模型接入",{"2":{"40":1}}],["ai",{"2":{"11":1,"13":1,"34":1,"44":1,"47":1,"54":1,"58":2,"68":1,"70":2,"112":1,"150":1,"151":2}}],["aime",{"2":{"6":3,"24":1,"76":2}}],["首先我们需要在langchat模型管理页面配置ollama模型信息",{"2":{"149":1}}],["首先需要安装ollama官方客户端",{"2":{"148":1}}],["首先进入到langchat此页面",{"2":{"124":1}}],["首先进入到langchat的知识库管理页面",{"2":{"106":1}}],["首先你需要注册百度智能云账号",{"2":{"145":1}}],["首先你需要安装好pgvector和oss",{"2":{"126":1}}],["首先你需要修改后端springboot项目的配置文件才能运行",{"2":{"97":1}}],["首先你应该检查springboot的application",{"2":{"121":1}}],["首先本地idea打开langchat项目",{"2":{"119":1}}],["首先会检查本地有没有此模型",{"2":{"114":1}}],["首先把整个项目代码下载到本地",{"2":{"95":1}}],["首先安装库",{"2":{"60":1}}],["首先",{"2":{"18":1,"114":1,"159":1}}],["首先采取行动",{"2":{"16":1}}],["高自定义机器人执行流程",{"2":{"36":1}}],["高级rag",{"2":{"36":1}}],["高度优化的版本被命名为",{"2":{"32":1}}],["高质量推理示例",{"2":{"28":1}}],["高回报",{"2":{"18":1}}],["高于平均水平的答案获得正优势",{"2":{"17":1}}],["背后的目标函数",{"2":{"18":1}}],["背后",{"2":{"18":1}}],["显示出这种技术的强大之处",{"2":{"76":1}}],["显著降低了内存和计算要求",{"2":{"54":1}}],["显著优于其他开源模型",{"2":{"6":1}}],["显然",{"2":{"18":1,"71":1}}],["不允许调用",{"2":{"158":1}}],["不要用redis",{"2":{"122":1}}],["不应该用deepseek",{"2":{"114":1}}],["不是非要linux服务器",{"2":{"114":1}}],["不是从头开始训练的",{"2":{"14":1}}],["不需要任何其他命令加载",{"2":{"128":1}}],["不需要python",{"2":{"114":1}}],["不需要做权限配置",{"2":{"103":1}}],["不建议使用",{"2":{"91":1}}],["不同",{"2":{"45":1}}],["不如先将其可视化",{"2":{"29":1}}],["不太完美",{"2":{"24":1}}],["不正确且推理不佳",{"2":{"23":1}}],["不会对性能的大幅变化反应过度",{"2":{"18":1}}],["不会波动太大",{"2":{"18":1}}],["不会只得到一个答案",{"2":{"17":1}}],["称为思维链",{"2":{"26":1}}],["称为",{"2":{"17":1}}],["称为学生模型",{"2":{"1":1}}],["然而",{"2":{"17":1,"59":1}}],["然后不同的模型仍然在langchat不同的模型供应商下面配置",{"2":{"161":1}}],["然后直接执行命令",{"2":{"148":1}}],["然后选择一个模型即可",{"2":{"144":1}}],["然后在项目根目录找到langchat",{"2":{"98":1}}],["然后每个文本块都会通过嵌入模型",{"2":{"83":1}}],["然后通过多个高质量示例将其学习到的知识传授给",{"2":{"77":1}}],["然后进入",{"2":{"72":1}}],["然后进行",{"2":{"14":1}}],["然后用于训练学生模型",{"2":{"57":1}}],["然后他们会评估每个输出的正确性",{"2":{"31":1}}],["然后人类会对其进行改进",{"2":{"28":1}}],["然后仔细检查其答案",{"2":{"27":1}}],["然后为用户提供答案",{"2":{"22":2}}],["然后是奖励部分",{"2":{"18":1}}],["然后是更多",{"2":{"14":1}}],["然后是更多数据",{"2":{"14":1}}],["然后将所有这些计算的结果加在一起",{"2":{"18":1}}],["然后使用这些优势分数来更新旧策略",{"2":{"17":1}}],["然后评估每个答案并给出奖励分数",{"2":{"17":1}}],["然后",{"2":{"16":1,"23":1,"149":1}}],["然后对于真正的",{"2":{"14":1}}],["参与者",{"2":{"17":1}}],["算法",{"2":{"17":2,"30":1}}],["算法如何工作",{"0":{"17":1}}],["算法并尝试使用我们的文本输入来解决它",{"2":{"16":1}}],["gguf",{"2":{"53":2}}],["gridworld",{"2":{"74":1}}],["grad",{"2":{"64":1}}],["gradient",{"2":{"51":1,"64":1}}],["grpo",{"0":{"17":1,"18":1},"2":{"17":5,"18":4,"23":3,"30":2,"32":1}}],["google定义了谷歌搜索功能的key信息",{"2":{"99":1}}],["google",{"2":{"47":1,"151":3}}],["gpd1",{"2":{"67":1}}],["gpu",{"2":{"44":2,"47":1,"53":1,"54":1}}],["gpl",{"2":{"38":2}}],["gpt",{"2":{"6":1,"71":4}}],["gnu",{"2":{"38":1}}],["gitcode",{"2":{"119":2}}],["git",{"2":{"95":1}}],["github",{"2":{"34":2,"43":2,"93":1,"95":1,"112":2,"119":2,"122":1,"140":1}}],["gitee",{"2":{"34":3,"112":3,"119":2}}],["generative",{"2":{"151":1}}],["generation",{"2":{"67":1}}],["generated",{"2":{"67":1}}],["generate",{"2":{"67":1}}],["geoffrey",{"2":{"56":1}}],["gemini使用google",{"2":{"151":1}}],["gemini",{"2":{"34":1,"112":1}}],["get",{"2":{"28":1,"51":1}}],["gt",{"2":{"20":2,"21":6,"22":16,"23":15,"61":3,"62":4,"75":2,"91":1,"117":1,"125":1,"141":1,"142":1}}],["g",{"2":{"18":2,"23":1}}],["设置为官方镜像",{"2":{"91":3}}],["设置为国内镜像",{"2":{"91":3}}],["设置训练参数",{"0":{"64":1}}],["设置环境",{"0":{"48":1}}],["设置以及它们使用的",{"2":{"16":1}}],["设置中的策略模型",{"0":{"16":1}}],["积极的奖励意味着它做对了某件事",{"2":{"16":1}}],["环境配置",{"0":{"97":1},"1":{"98":1,"99":1}}],["环境准备",{"0":{"90":1},"1":{"91":1,"92":1,"93":1}}],["环境会给予奖励",{"2":{"16":1}}],["环境只是推理任务本身",{"2":{"16":1}}],["充当",{"2":{"16":1}}],["是不知道langchat是什么的",{"2":{"139":1}}],["是deekseek",{"2":{"125":1}}],["是java生态下企业级aigc项目解决方案",{"2":{"112":1}}],["是类似的",{"2":{"110":1}}],["是应用",{"2":{"57":1}}],["是由",{"2":{"45":1}}],["是否提供了除答案之外的有用背景",{"2":{"32":1}}],["是明显的障碍",{"2":{"24":1}}],["是一个迭代过程",{"2":{"23":1}}],["是",{"2":{"18":1}}],["是使用强化学习创建的",{"2":{"16":1}}],["是的",{"2":{"14":1}}],["实际上",{"2":{"115":1}}],["实际上非常令人印象深刻",{"2":{"71":1}}],["实现本地函数调用",{"2":{"36":1}}],["实现的起点",{"2":{"16":1}}],["实施快速概览",{"2":{"14":1}}],["最小的模型一般不需要gpu也可运行",{"2":{"148":1}}],["最初",{"2":{"74":1}}],["最终我们需要拿到上面创建应用的",{"2":{"145":1}}],["最终的效果完全取决于模型的能力",{"2":{"149":1}}],["最终的效果都是一样的",{"2":{"115":1}}],["最终的奖励信号成为准确度",{"2":{"32":1}}],["最终使用rag系统检索后的数据也是通过这种方式交给模型分析处理的",{"2":{"110":1}}],["最终出现的基础模型具有以下特点",{"2":{"72":1}}],["最终",{"2":{"32":1,"71":1,"89":1}}],["最后",{"2":{"15":1,"18":2,"31":1,"67":1}}],["最先进的开源模型",{"2":{"6":1}}],["简单理解就是",{"2":{"107":1}}],["简单的问题通过快速路径获得快速",{"2":{"15":1}}],["简介",{"0":{"74":1}}],["简化了指令跟随模型的监督微调",{"2":{"65":1}}],["简化训练过程",{"2":{"23":1}}],["简而言之",{"2":{"18":1}}],["简称",{"2":{"14":1}}],["快速管理客户端数据",{"2":{"36":1}}],["快速构建企业级aigc项目",{"2":{"34":1}}],["快速处理器用于简单的任务",{"2":{"15":1}}],["快速概览一下",{"2":{"14":1}}],["快速概览",{"0":{"14":1}}],["有很多不需要gpu的模型",{"2":{"148":1}}],["有就安装",{"2":{"114":1}}],["有一天会比人类更聪明",{"2":{"78":1}}],["有一些关键问题需要解决",{"2":{"24":1}}],["有人说这就是",{"2":{"75":1}}],["有效应对这些挑战可确保稳健高效的微调过程",{"2":{"47":1}}],["有用性和无害性分数的加权组合",{"2":{"32":1}}],["有用性",{"2":{"32":2}}],["有时还会使用思维链来完成复杂任务",{"2":{"31":1}}],["有时会对语言感到困惑并开始混淆它们吗",{"2":{"30":1}}],["有趣的是",{"2":{"22":1}}],["有复杂的数学💀总之",{"2":{"18":1}}],["有许多可用的",{"2":{"17":1}}],["有两条主要路径",{"2":{"15":1}}],["有点像一个实验",{"2":{"14":1}}],["架构",{"2":{"15":1}}],["架构的几个提炼模型",{"2":{"5":1}}],["而对于文档内容过多的时候会将一个文档拆分为多个部分进行向量化存储",{"2":{"109":1}}],["而非标准的json类型",{"2":{"158":1}}],["而非",{"2":{"92":1}}],["而获得奖励",{"2":{"75":1}}],["而生成的下一个令牌是动作",{"2":{"75":1}}],["而状态对应于到目前为止生成的标记",{"2":{"75":1}}],["而且解释得很好",{"2":{"71":1}}],["而且还要逐步明确地展示其推理",{"2":{"27":1}}],["而无需昂贵的硬件",{"2":{"54":1}}],["而其他输出则被拒绝",{"2":{"31":1}}],["而不仅仅是最终预测",{"2":{"57":1}}],["而不仅仅是吐出单词",{"2":{"14":1}}],["而不是很好地进行泛化",{"2":{"47":1}}],["而不是告诉模型如何推理",{"2":{"22":1}}],["而不会失去其实际意义",{"2":{"18":1}}],["而低于平均水平的答案获得负优势",{"2":{"17":1}}],["而是通过为模型提供正确的激励而发展起来的",{"2":{"78":1}}],["而是从老师模型的输出或中间表示中学习",{"2":{"56":1}}],["而是指示旧策略针对同一问题生成一组不同的答案",{"2":{"17":1}}],["而是使用了基于规则的奖励系统",{"2":{"19":1}}],["而是使用",{"2":{"15":1}}],["而",{"2":{"17":1}}],["而复杂的查询则通过专家系统得到详细关注",{"2":{"15":1}}],["它已经从",{"2":{"77":1}}],["它已经知道的东西来最大化它的奖励",{"2":{"74":1}}],["它特别奖励在",{"2":{"75":1}}],["它可能会导致有害的输出",{"2":{"72":1}}],["它可能无法提供有用的响应",{"2":{"72":1}}],["它可以在给定输入问题的情况下预测一组语法流畅的下一个标记",{"2":{"72":1}}],["它理解语言的结构",{"2":{"72":1}}],["它回答正确",{"2":{"71":1}}],["它不仅给出了正确的答案",{"2":{"71":1}}],["它不是直接在原始数据上训练学生模型",{"2":{"56":1}}],["它不是很复杂",{"2":{"18":1}}],["它没有意识到猫已经死了",{"2":{"71":2}}],["它没有说",{"2":{"24":1}}],["它直接提供了计算答案的步骤",{"2":{"67":1}}],["它们不会随着时间的推移而改进",{"2":{"59":1}}],["它通过将知识从大型复杂模型",{"2":{"55":1}}],["它在需要逻辑推理",{"2":{"45":1}}],["它也会获得",{"2":{"30":1}}],["它正确解决了问题并且还用英语进行推理",{"2":{"30":1}}],["它错误地计算了",{"2":{"30":1}}],["它只是说",{"2":{"24":1}}],["它避免对推理过程本身施加任何特定于内容的限制",{"2":{"24":1}}],["它会得到",{"2":{"20":1}}],["它会得到正奖励",{"2":{"20":1}}],["它会使用一个智能路由器在两条路径之间做出决定",{"2":{"15":1}}],["它将查看",{"2":{"20":1}}],["它有助于评估新模型与前一个模型相比所做的更改",{"2":{"18":1}}],["它确保",{"2":{"18":1}}],["它的回答是这样的",{"2":{"71":1}}],["它的",{"2":{"24":1}}],["它的计算方式如下",{"2":{"18":1}}],["它的主要优势在于其决策系统",{"2":{"15":1}}],["它着眼于",{"2":{"18":1}}],["它内部有点复杂",{"2":{"18":1}}],["它从向模型提出一个问题或提示开始",{"2":{"17":1}}],["它告诉",{"2":{"16":1}}],["它是",{"2":{"16":1,"75":1}}],["它首先会经过一个记忆系统",{"2":{"15":1}}],["它就像是一整套步骤",{"2":{"14":1}}],["它目前在",{"2":{"13":1}}],["做出有利于推理的事情时",{"2":{"14":1}}],["当前环境是什么就代表用了哪个配置文件",{"2":{"123":1}}],["当然你换一个能输出1024维度的embedding模型也是可以的",{"2":{"133":1}}],["当然如果你使用公有云模型",{"2":{"133":1}}],["当然我建议大家直接使用阿里云",{"2":{"128":1}}],["当然建议使用阿里云或七牛云",{"2":{"121":1}}],["当然也可以修改为dev环境使用application",{"2":{"99":1}}],["当然",{"2":{"92":1}}],["当我在",{"2":{"71":1}}],["当我问",{"2":{"71":1}}],["当我们计算",{"2":{"30":1}}],["当我们训练",{"2":{"22":1}}],["当你看到此输入",{"2":{"29":1}}],["当你输入问题时",{"2":{"15":1}}],["当被问到多语言问题时",{"2":{"24":1}}],["当",{"2":{"14":1}}],["为金融数据集生成推理轨迹",{"2":{"59":1}}],["为什么报错error",{"0":{"133":1}}],["为什么是切片",{"2":{"109":1}}],["为什么要向量化",{"2":{"107":1}}],["为什么要蒸馏自己的模型",{"0":{"59":1}}],["为什么它很重要",{"2":{"56":1}}],["为什么需要微调",{"0":{"46":1}}],["为语言一致性奖励分配较小的权重",{"2":{"30":1}}],["为简单起见",{"2":{"30":1}}],["为了增强模型的推理能力",{"2":{"62":1}}],["为了使访问更加民主化",{"2":{"58":1}}],["为了使奖励模型有效",{"2":{"22":1}}],["为了改进推理数据",{"2":{"31":1}}],["为了理解上面的图表",{"2":{"30":1}}],["为了解决这个问题",{"2":{"30":1,"77":1}}],["为了修复",{"2":{"25":1}}],["为了确定每个输出对模型性能的改善或恶化程度",{"2":{"23":1}}],["为了引导模型进行更好的推理",{"2":{"23":1}}],["为了让一切变得简单",{"2":{"13":2}}],["为此",{"2":{"14":1,"23":1,"31":1}}],["开发rag系统的第一步是准备文档",{"2":{"80":1}}],["开发",{"2":{"79":1}}],["开发人员可以根据其特定用例对其进行定制",{"2":{"46":1}}],["开发的开源推理模型",{"2":{"45":1}}],["开发文档会有所欠缺",{"2":{"37":1}}],["开源地址",{"2":{"34":1,"112":1,"119":1}}],["开源可用性",{"2":{"7":1}}],["开始",{"2":{"14":1,"75":1}}],["引导你了解",{"2":{"13":1}}],["等等付费支持服务",{"2":{"141":1}}],["等待maven加载完成",{"2":{"119":1}}],["等竞争性编程网站",{"2":{"75":1}}],["等流行架构的六个蒸馏变体",{"2":{"58":1}}],["等专门技术将",{"2":{"55":1}}],["等通用语言模型适应特定任务",{"2":{"46":1}}],["等大模型",{"2":{"34":1,"112":1}}],["等更高级的模型相似",{"2":{"24":1}}],["等更大的非推理模型",{"2":{"6":1}}],["等任务上的得分与",{"2":{"24":1}}],["等于多少",{"2":{"13":1,"19":1,"22":1,"23":1,"26":2,"27":1,"31":2,"32":1}}],["+1",{"2":{"20":1}}],["+",{"2":{"13":1,"19":1,"22":4,"23":3,"26":5,"27":4,"28":1,"29":2,"30":6,"31":3,"32":1,"50":1,"61":1,"115":1}}],["事实上",{"2":{"13":1,"76":1}}],["可与专有模型相媲美",{"2":{"44":1}}],["可读的格式",{"2":{"28":1}}],["可视化细化过程的工作原理如下",{"2":{"28":1}}],["可视化优势计算",{"2":{"23":1}}],["可以免费使用限额限速的模型",{"2":{"145":1}}],["可以免费学习使用",{"2":{"38":1}}],["可以看到未配置知识库",{"2":{"139":1}}],["可以拿未配置知识库的普通聊天做测试",{"2":{"139":1}}],["可以在这里搜索到",{"2":{"108":1}}],["可以在消费级硬件上进行有效训练",{"2":{"44":1}}],["可以更精确的匹配到相关联的文本关键词",{"2":{"107":1}}],["可以通过两种方式",{"2":{"107":1}}],["可以自由创建知识库",{"2":{"107":1}}],["可以确保",{"2":{"78":1}}],["可以使用大量数据来学习如何得出正确答案",{"2":{"78":1}}],["可以使用ollama或vllm等本地llm工具来运行deepseek",{"2":{"9":1}}],["可以一起交流langchat后续开发规划",{"2":{"37":1}}],["可以加入我的java微信交流群",{"2":{"37":1}}],["可以请作者喝一杯咖啡加入langchat交流群",{"2":{"34":1}}],["可以将其视为快速回忆你之前遇到过的类似情况",{"2":{"15":1}}],["可能",{"2":{"78":1}}],["可能的问题和答案",{"2":{"75":1}}],["可能使用",{"2":{"32":1}}],["可能得到了正确的答案或推理得很好",{"2":{"16":1}}],["可能听说过",{"2":{"13":1}}],["可能放不下",{"2":{"12":1}}],["模型没有开通收费",{"2":{"158":1}}],["模型管理页面",{"2":{"142":1}}],["模型只能生成768维度的数据",{"2":{"133":1}}],["模型版本填",{"2":{"130":1}}],["模型版本写",{"2":{"124":1}}],["模型进行处理",{"2":{"81":1}}],["模型在蒸馏前后的响应",{"2":{"67":1}}],["模型蒸馏有几种方法",{"2":{"57":1}}],["模型蒸馏是一种强大的技术",{"2":{"55":1}}],["模型训练成为可能",{"2":{"54":1}}],["模型面临多项挑战",{"2":{"47":1}}],["模型正在设定推理性能的新基准",{"2":{"44":1}}],["模型可以因输出正确的最终答案而获得积极的奖励",{"2":{"75":1}}],["模型可能需要大量资源",{"2":{"44":1}}],["模型可确保学习过程保持平稳",{"2":{"18":1}}],["模型就会在流行的基准数据集上进行评估",{"2":{"32":1}}],["模型得到改进",{"2":{"32":1}}],["模型会尝试优化其过程以给出更多正确的答案",{"2":{"75":1}}],["模型会得到一些数学问题",{"2":{"75":1}}],["模型会生成推理序列中的下一个单词",{"2":{"29":1}}],["模型会从错误中吸取教训",{"2":{"23":1}}],["模型应该学会以类似的格式给出答案",{"2":{"26":1}}],["模型应该学会偏爱奖励更高的输出",{"2":{"23":1}}],["模型改进为",{"2":{"24":1}}],["模型转变为",{"2":{"24":1}}],["模型有时会在同一个回答中混合使用多种语言",{"2":{"24":1}}],["模型上使用",{"2":{"24":1}}],["模型更有可能生成正确的推理步骤",{"2":{"23":1}}],["模型",{"2":{"23":1,"24":1,"29":1,"30":1,"76":1,"115":2,"149":1}}],["模型都会生成一组答案",{"2":{"18":1}}],["模型非常庞大",{"2":{"12":1}}],["模型的不同阶段",{"2":{"71":1,"77":1}}],["模型的输出",{"2":{"28":1}}],["模型的大小非常大",{"2":{"2":1}}],["模型的较小",{"2":{"2":1}}],["如下",{"2":{"148":1}}],["如下所示创建ai应用",{"2":{"136":1}}],["如下修改为768维度",{"2":{"133":1}}],["如下图所示",{"2":{"58":1}}],["如上说明embedding模型正在运行",{"2":{"129":1}}],["如上结果",{"2":{"128":1}}],["如上",{"2":{"118":1,"125":1,"138":1,"160":1}}],["如上图所示",{"2":{"117":1}}],["如此有效的秘诀",{"2":{"75":1}}],["如",{"2":{"23":2,"47":2,"55":2,"75":1}}],["如何部署langchat到云端服务器",{"0":{"140":1},"1":{"141":1}}],["如何登录系统",{"0":{"103":1},"1":{"104":1,"105":1}}],["如何推理",{"2":{"77":1}}],["如何入侵某人的电子邮件",{"2":{"72":1,"77":1}}],["如何产生高质量",{"2":{"29":1}}],["如何在强化学习过程中构建其响应",{"2":{"22":1}}],["如何思考",{"0":{"15":1}}],["如果仔细阅读过文档",{"2":{"153":1}}],["如果未开通直接调用api会提醒需要开通服务",{"2":{"145":1}}],["如果向量化成功",{"2":{"135":1}}],["如果向量维度一旦不匹配",{"2":{"133":1}}],["如果是自己手动安装的pgvector",{"2":{"122":1}}],["如果上面脚本执行成功",{"2":{"122":1}}],["如果不想麻烦可以用docker",{"2":{"122":1}}],["如果熟悉rag系统流程的朋友应该知道",{"2":{"110":1}}],["如果需要知识库向量化",{"2":{"114":1}}],["如果需要",{"2":{"81":1}}],["如果有java全栈",{"2":{"37":1}}],["如果想和作者深入交流langchat开发规划",{"2":{"34":1}}],["如果生成",{"2":{"32":1}}],["如果我们为准确度奖励分配权重",{"2":{"30":1}}],["如果它错了",{"2":{"20":1}}],["如果",{"2":{"20":1}}],["如果你是按照上面步骤的embedding模型",{"2":{"132":1}}],["如果你是中国用户并遇到下载速度问题",{"2":{"91":1}}],["如果你本地电脑是",{"2":{"117":1}}],["如果你希望将代码迁移到",{"2":{"92":1}}],["如果你想要迁移到",{"2":{"92":1}}],["如果你想要更多",{"2":{"71":1}}],["如果你有关于langchat的开发问题或者二开定制等需求",{"2":{"37":1}}],["如果你用英语问问题",{"2":{"30":1}}],["如果你用西班牙语问它问题",{"2":{"24":1}}],["如果你对",{"2":{"13":1}}],["如果你使用的是消费级",{"2":{"12":1}}],["如分析或专业知识",{"2":{"15":1}}],["如简单问题或常见请求",{"2":{"15":1}}],["如移动设备或边缘计算系统",{"2":{"1":1}}],["error",{"0":{"155":1,"156":1}}],["ernie",{"2":{"145":1}}],["expected",{"0":{"133":1}}],["example",{"2":{"61":3}}],["examples",{"2":{"26":1,"50":2}}],["embed",{"2":{"128":1,"129":2,"130":1,"132":1,"133":1}}],["embedding模型需要单独安装",{"2":{"114":1}}],["embedding模型要将文档解析为向量数据",{"2":{"109":1}}],["embeddings",{"2":{"62":1,"67":1,"129":2}}],["eslint",{"2":{"70":1}}],["es",{"2":{"70":1}}],["echart",{"2":{"68":1}}],["epoch",{"2":{"64":2}}],["epochs=3",{"2":{"64":1}}],["epsilon",{"2":{"18":1}}],["eos",{"2":{"62":1,"67":2}}],["evaluate",{"2":{"52":2}}],["eval",{"2":{"51":1,"52":2,"64":2,"65":1}}],["early",{"2":{"47":1}}],["eager",{"2":{"11":1}}],["equals",{"2":{"26":1}}],["e",{"2":{"22":2,"47":1}}],["en",{"2":{"150":1,"152":1}}],["enclosed",{"2":{"22":2}}],["enforce",{"2":{"11":1}}],["lr",{"2":{"64":1}}],["learn",{"2":{"150":1}}],["learning",{"2":{"64":1}}],["leetcode",{"2":{"75":2}}],["length=max",{"2":{"49":1,"50":1}}],["length",{"2":{"49":2,"50":1}}],["len",{"2":{"11":1,"62":1,"67":1}}],["lm",{"2":{"63":1}}],["layers",{"2":{"51":1,"53":1,"63":1}}],["langchain如何实现rag",{"0":{"79":1},"1":{"80":1,"81":1,"82":1,"83":1,"84":1,"85":1,"86":1,"87":1,"88":1,"89":1}}],["langchain4j",{"2":{"42":1,"68":1}}],["langchainchat",{"2":{"35":1,"37":2,"141":1}}],["langchat支持例如one",{"2":{"159":1}}],["langchat支持动态配置国内外数十家ai大模型",{"2":{"142":1}}],["langchat构建失败",{"0":{"154":1}}],["langchat产品技术问答支持",{"2":{"141":1}}],["langchat产品二开",{"2":{"141":1}}],["langchat产品官网",{"2":{"140":1}}],["langchat项目部署",{"2":{"141":1}}],["langchat项目本身是部署在云端的",{"2":{"140":1}}],["langchat客户端线上预览地址",{"2":{"140":1}}],["langchat服务端线上预览地址",{"2":{"140":1}}],["langchat开源地址",{"2":{"140":1}}],["langchat开发web",{"2":{"40":1}}],["langchat知识库配置已经结束",{"2":{"135":1}}],["langchat配置embedding",{"0":{"130":1}}],["langchat至少需要以下环境",{"2":{"119":1}}],["langchat如何接入deepseek",{"0":{"111":1},"1":{"112":1,"113":1,"114":1,"115":1,"116":1,"117":1,"118":1,"119":1,"120":1,"121":1,"122":1,"123":1,"124":1,"125":1,"126":1,"127":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1,"134":1,"135":1,"136":1,"137":1,"138":1,"139":1}}],["langchat同样提供了可视化的检索页面",{"2":{"110":1}}],["langchat使用server",{"2":{"104":1}}],["langchat都将为你提供丰富的学习案例",{"2":{"68":1}}],["langchat不仅为企业提供ai领域的产品解决方案",{"2":{"68":1}}],["langchat介绍",{"0":{"68":1},"1":{"69":1,"70":1}}],["langchat正式发布",{"2":{"40":1}}],["langchat完成分离server",{"2":{"40":1}}],["langchat完成多存储方案",{"2":{"40":1}}],["langchat文档地址",{"2":{"34":1}}],["langchat文档",{"2":{"34":1}}],["langchat官网",{"2":{"34":1}}],["langchat是java生态下企业级aigc项目解决方案",{"2":{"34":1}}],["langchat",{"0":{"34":1},"1":{"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1},"2":{"34":8,"43":1,"68":1,"70":17,"95":1,"96":4,"99":3,"101":1,"102":1,"103":5,"112":5,"119":5,"140":4}}],["language",{"2":{"30":1}}],["local文件",{"2":{"155":1}}],["localhost",{"2":{"101":1,"102":1,"129":2,"130":1}}],["local",{"2":{"99":1}}],["lock",{"2":{"70":1}}],["logging",{"2":{"64":2}}],["logits蒸馏中",{"2":{"57":1}}],["logits蒸馏",{"2":{"57":1}}],["logits",{"2":{"57":3}}],["low",{"2":{"63":1}}],["load",{"2":{"49":1,"50":2,"61":3,"62":1,"67":1}}],["lorar8",{"2":{"67":1}}],["loraconfig",{"2":{"63":2}}],["lora",{"0":{"51":1,"63":1},"2":{"44":3,"47":2,"51":4,"54":1,"55":1,"63":3,"65":1,"66":1}}],["looks",{"2":{"27":1}}],["list查看到下载的模型",{"2":{"128":1}}],["library",{"2":{"115":1,"148":1}}],["like",{"2":{"110":1}}],["license",{"2":{"38":1,"70":1}}],["licensed",{"2":{"38":1}}],["limitedchangeratio",{"2":{"18":3}}],["lt",{"2":{"20":2,"21":6,"22":16,"23":15,"61":3,"62":4,"75":2,"125":1}}],["llm将针对用户的问题",{"2":{"89":1}}],["llm学习了诸如重新阅读问题",{"2":{"78":1}}],["llm等",{"2":{"68":1}}],["llm基础框架",{"2":{"68":1}}],["llm",{"2":{"13":1,"14":2,"17":1,"45":1,"47":1,"48":1,"59":1,"61":1,"70":3,"71":2,"72":4,"73":1,"75":12,"76":2,"77":1,"78":3,"92":1}}],["llama3",{"2":{"148":1}}],["llama",{"2":{"0":1,"4":1,"5":3,"6":1,"33":1,"44":1,"49":1,"53":4,"58":1,"61":1}}],["v1",{"2":{"159":3}}],["v1后缀",{"2":{"156":1}}],["vectorstore定义了llm向量库的信息",{"2":{"99":1}}],["vector",{"2":{"92":1}}],["vertex",{"2":{"151":1}}],["vertex的认证方式",{"2":{"151":1}}],["vercel和nextjs",{"2":{"79":1}}],["verification",{"2":{"27":1}}],["verify",{"2":{"27":1}}],["vitest",{"2":{"70":2}}],["vben",{"2":{"70":1}}],["vue3",{"2":{"68":1}}],["v2",{"2":{"61":2}}],["v",{"2":{"51":1,"63":1}}],["vram",{"2":{"47":1}}],["vllm",{"0":{"11":1},"2":{"11":1}}],["v3开源协议",{"2":{"38":1}}],["v3",{"0":{"15":1,"16":1},"2":{"0":1,"3":1,"14":1,"15":5,"16":6,"17":1,"20":1,"22":1,"23":2,"24":1,"25":1,"26":1,"29":2,"30":2,"32":1,"38":1}}],["使模型可以清楚地学习结构",{"2":{"26":1}}],["使人类难以理解和分析",{"2":{"24":1}}],["使其更清晰",{"2":{"28":1}}],["使其更有可能在未来产生高于平均水平的答案",{"2":{"17":1}}],["使其更易于在资源受限的环境中部署",{"2":{"7":1}}],["使更广泛的受众能够使用高级推理功能",{"2":{"12":1}}],["使用第三方平台代理",{"2":{"159":3}}],["使用vpn",{"2":{"154":1}}],["使用如navicat等客户端工具删除langchat库中的表",{"2":{"133":1}}],["使用ollama下载embedding模型",{"2":{"128":1}}],["使用idea打开整个langchat项目文件夹",{"2":{"95":1}}],["使用最新的技术栈进行开发",{"2":{"92":1}}],["使用图例详细介绍rag系统的设计流程",{"2":{"79":1}}],["使用java生态",{"2":{"68":1}}],["使用模型进行推理",{"2":{"53":1}}],["使用聊天式提示模板格式化数据集",{"2":{"50":1}}],["使用包含特定领域数据和一般知识数据的混合数据集来保持整体模型准确性",{"2":{"47":1}}],["使用数据增强技术和正则化方法",{"2":{"47":1}}],["使用了拒绝抽样",{"2":{"31":1}}],["使用与之前相同的权重",{"2":{"30":1}}],["使用目标语言",{"2":{"30":1}}],["使用损失函数将其与比较目标标记",{"2":{"29":1}}],["使用长",{"0":{"26":1}}],["使用不同的推理问题重复上述步骤数千次",{"2":{"23":1}}],["使用计算出的优势来更新策略模型",{"2":{"23":1}}],["使用旧模型的答案几率",{"2":{"18":1}}],["使用新模型的答案几率",{"2":{"18":1}}],["使用一种称为",{"2":{"17":1}}],["使用",{"0":{"9":1,"10":1,"11":1},"1":{"10":1,"11":1},"2":{"30":1,"47":1,"49":1,"50":1,"59":1}}],["表明蒸馏是一种更经济",{"2":{"8":1}}],["训练的不稳定阶段",{"2":{"77":1}}],["训练的模型",{"2":{"8":1}}],["训练数据集还包含编码问题",{"2":{"75":1}}],["训练数据包括",{"2":{"32":1}}],["训练阶段之一",{"2":{"75":1}}],["训练典型",{"2":{"71":1}}],["训练成本也低得多",{"2":{"71":2}}],["训练后",{"2":{"52":1,"66":1}}],["训练时间长",{"2":{"47":1}}],["训练过程遵循迭代",{"2":{"32":1}}],["训练过程创建",{"2":{"24":1}}],["训练模型",{"0":{"65":1},"2":{"51":1}}],["训练模型以支持高优势输出",{"2":{"30":1}}],["训练模型的比较",{"0":{"8":1}}],["训练循环",{"2":{"30":1}}],["训练循环遵循我们之前看到的相同",{"2":{"30":1}}],["训练之前为模型提供良好的推理基础",{"2":{"25":1}}],["训练",{"2":{"17":1,"71":1,"77":1}}],["训练不是从头开始构建的",{"2":{"15":1}}],["与其他方法的主要区别在于它们在训练期间引入的特殊",{"2":{"73":1}}],["与其用详细的文字解释并让你难以理解",{"2":{"29":1}}],["与传统",{"2":{"45":1}}],["与",{"0":{"8":1}}],["转移的知识",{"2":{"7":1}}],["转移到较小",{"2":{"1":1,"55":1}}],["效率",{"2":{"7":1}}],["03",{"2":{"64":1}}],["05",{"2":{"51":1}}],["0912",{"2":{"24":1}}],["01",{"2":{"24":1}}],["0",{"2":{"6":1,"20":2,"23":10,"30":7,"53":1,"67":1,"71":2,"114":2,"118":2,"124":2,"149":4}}],["000",{"2":{"4":1}}],["multimodal",{"2":{"151":1}}],["multiplication",{"2":{"26":1,"27":2,"28":1}}],["multiply",{"2":{"22":1,"28":2}}],["m3",{"2":{"115":1}}],["mysql连接信息",{"2":{"121":1}}],["mysql8",{"2":{"119":1}}],["mysql和redis的安装这里不再说明",{"2":{"93":1}}],["mysql",{"2":{"92":1}}],["mybatis",{"2":{"68":1}}],["mjs",{"2":{"70":2}}],["md",{"2":{"70":2}}],["mvc框架",{"2":{"68":1}}],["merge",{"2":{"66":1}}],["meta",{"2":{"58":1}}],["m",{"2":{"53":1}}],["mini",{"2":{"55":2,"62":1,"67":1}}],["mind",{"2":{"22":2}}],["microsoft",{"2":{"55":2,"62":1,"150":1}}],["miles",{"2":{"26":2}}],["mph",{"2":{"26":2}}],["modules",{"2":{"70":1}}],["modules=",{"2":{"51":1,"63":1}}],["model=model",{"2":{"51":1,"65":1,"67":1}}],["model",{"2":{"11":1,"49":3,"50":2,"51":3,"52":3,"53":1,"62":6,"65":1,"66":3,"67":3,"129":1}}],["moe",{"0":{"15":1},"2":{"15":2}}],["maven",{"0":{"154":1}}],["mac",{"2":{"148":1}}],["macbook",{"2":{"115":1}}],["matrices",{"2":{"63":1}}],["math",{"2":{"6":2}}],["magpie",{"2":{"61":3}}],["map=",{"2":{"62":1,"67":2}}],["map",{"2":{"50":1,"61":1}}],["max",{"2":{"11":1,"49":2,"50":1,"64":1,"67":1}}],["mlm=false",{"2":{"65":1}}],["ml",{"2":{"1":1}}],["600k",{"2":{"31":1}}],["60",{"2":{"26":3}}],["6",{"0":{"8":1,"19":1,"20":1,"21":1,"52":1,"66":1,"85":1,"132":1},"1":{"20":1,"21":1},"2":{"6":1}}],["671b",{"2":{"2":1}}],["pull",{"2":{"128":2}}],["postgresapp",{"2":{"122":1}}],["postgres官网",{"2":{"122":1}}],["pom",{"2":{"70":4}}],["pgvector官方仓库",{"2":{"122":1}}],["pgvector可以用navicat等工具可视化查看数据表",{"2":{"122":1}}],["pgvector等",{"2":{"119":1}}],["pgvector",{"2":{"93":2,"122":2}}],["pgvector的开源地址",{"2":{"93":1}}],["pg",{"2":{"92":1}}],["pnpm",{"2":{"70":2,"91":3,"96":2,"101":2,"102":2}}],["phi",{"2":{"55":2,"61":1,"62":1,"64":1,"65":2,"66":2,"67":6}}],["per",{"2":{"64":2}}],["perplexity",{"2":{"52":2}}],["peft",{"2":{"51":1,"63":2,"65":2,"66":1}}],["pemdas",{"2":{"26":1,"29":1}}],["pipeline",{"2":{"67":5}}],["pip",{"2":{"48":1,"60":1}}],["python",{"2":{"48":1}}],["plus",{"2":{"26":1,"68":1}}],["print",{"2":{"52":1,"67":1}}],["preprocess",{"2":{"50":2}}],["pretrained",{"2":{"49":1,"52":2,"62":2,"65":1,"66":2,"67":2}}],["present",{"2":{"38":1}}],["preview",{"2":{"6":1}}],["pro测试",{"2":{"148":1}}],["probability",{"2":{"67":1}}],["problem",{"2":{"26":4,"27":1}}],["proj",{"2":{"51":2,"63":4}}],["prompt",{"2":{"22":3,"50":2,"53":1,"67":2,"92":1,"129":1}}],["provides",{"2":{"22":2}}],["process",{"2":{"22":6}}],["pc",{"2":{"12":1}}],["packages",{"2":{"70":1}}],["package",{"2":{"70":2}}],["paged",{"2":{"64":1}}],["pad",{"2":{"62":1}}],["paris",{"2":{"50":1}}],["parallel",{"2":{"11":1}}],["pass",{"2":{"6":5}}],["超越了",{"2":{"6":1}}],["512",{"2":{"148":1}}],["512版本",{"2":{"115":1}}],["50000samples",{"2":{"67":1}}],["500",{"2":{"6":2}}],["55",{"2":{"6":1}}],["5",{"0":{"7":1,"18":1,"51":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":2,"66":1,"67":1,"78":1,"84":1,"131":1},"1":{"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1},"2":{"6":3,"23":3,"26":3,"30":2,"44":1,"61":3,"64":1}}],["5b小模型",{"2":{"117":1}}],["5b",{"2":{"0":1,"5":1,"33":1,"115":2}}],["4k",{"2":{"62":1,"67":1}}],["4bit=true",{"2":{"49":1}}],["4bit",{"2":{"49":1}}],["4等于多少",{"2":{"22":1}}],["4o",{"2":{"6":1,"71":4}}],["4",{"0":{"6":1,"12":1,"17":1,"50":1,"59":1,"64":1,"77":1,"83":1,"123":1,"130":1},"2":{"13":1,"19":1,"22":4,"23":4,"26":4,"27":4,"28":2,"29":1,"30":3,"31":2,"32":1,"47":1,"49":1,"50":1}}],["3003",{"2":{"101":1}}],["30",{"2":{"40":1}}],["32768",{"2":{"11":1}}],["32bit",{"2":{"64":1}}],["32b",{"2":{"0":1,"5":1,"6":2,"8":3,"11":1}}],["3",{"0":{"5":1,"9":1,"10":1,"11":1,"16":1,"28":1,"49":1,"58":1,"63":1,"76":1,"82":1,"118":1,"122":1,"129":1},"1":{"10":1,"11":1},"2":{"6":2,"13":1,"19":1,"22":4,"23":3,"26":7,"27":4,"28":2,"29":1,"30":3,"31":2,"32":1,"44":1,"48":1,"55":2,"61":1,"62":1,"64":2,"65":2,"66":2,"67":3}}],["阶段之后",{"2":{"32":1}}],["阶段使用下一个标记预测在组合数据集",{"2":{"31":1}}],["阶段的总奖励时",{"2":{"30":1}}],["阶段的核心思想是使用监督学习来教",{"2":{"29":1}}],["阶段",{"2":{"4":1,"32":1,"71":1}}],["run",{"2":{"101":1,"102":1,"115":1,"128":1,"148":1}}],["rolling",{"2":{"67":1}}],["root",{"2":{"26":2}}],["rayleigh",{"2":{"129":1}}],["rag实际是通过将用户问题返回到向量数据库中匹配相似的文档",{"2":{"110":1}}],["rag",{"2":{"79":1}}],["ratio=0",{"2":{"64":1}}],["rate=2e",{"2":{"64":1}}],["rate",{"2":{"63":1}}],["rank",{"2":{"51":1,"63":2}}],["r=8",{"2":{"63":1}}],["r=16",{"2":{"51":1}}],["right",{"2":{"27":1}}],["redis信息",{"2":{"99":1}}],["redis",{"2":{"92":1}}],["registry",{"2":{"91":12}}],["readme",{"2":{"70":2}}],["reasoning",{"2":{"22":6,"27":2,"28":1,"61":2}}],["repo",{"2":{"67":1}}],["remote",{"2":{"62":2}}],["remove",{"2":{"61":1}}],["return",{"2":{"50":1,"61":1}}],["request",{"2":{"50":1}}],["reward",{"2":{"30":3}}],["resize",{"2":{"62":2,"67":1}}],["response",{"2":{"50":2,"61":2,"67":1}}],["respectively",{"2":{"22":2}}],["results",{"2":{"52":2}}],["result",{"2":{"27":1,"28":1}}],["rlhf",{"2":{"73":1,"75":1}}],["rl",{"0":{"8":1,"16":1,"32":1,"74":1},"2":{"4":1,"8":1,"14":4,"16":4,"17":3,"20":1,"23":1,"24":2,"25":1,"30":2,"32":2,"71":1,"73":2,"75":3,"76":1,"77":2,"78":1}}],["r1下载哪个版本",{"0":{"115":1}}],["r1是推理模型",{"2":{"114":1}}],["r1是由deepseek公司推出的开源大模型",{"2":{"113":1}}],["r1模型已经启动并配置好",{"2":{"125":1}}],["r1模型是否启动",{"0":{"118":1}}],["r1模型",{"0":{"111":1},"1":{"112":1,"113":1,"114":1,"115":1,"116":1,"117":1,"118":1,"119":1,"120":1,"121":1,"122":1,"123":1,"124":1,"125":1,"126":1,"127":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1,"134":1,"135":1,"136":1,"137":1,"138":1,"139":1},"2":{"111":1,"113":1,"117":1,"124":1,"136":1}}],["r1到自己的模型",{"0":{"55":1},"1":{"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1}}],["r1微调指南",{"0":{"44":1},"1":{"45":1,"46":1,"47":1,"48":1,"49":1,"50":1,"51":1,"52":1,"53":1,"54":1}}],["r1真正安全的最后一道工序",{"2":{"32":1}}],["r1的推理过程",{"2":{"125":1}}],["r1的推理能力分析",{"0":{"71":1},"1":{"72":1,"73":1,"74":1,"75":1,"76":1,"77":1,"78":1}}],["r1的哪个模型",{"2":{"114":1}}],["r1的核心概念",{"2":{"13":2}}],["r1的6",{"2":{"0":1}}],["r1架构和训练过程图解",{"0":{"13":1},"1":{"14":1,"15":1,"16":1,"17":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1}}],["r1",{"0":{"2":1,"9":1,"19":1,"23":1,"24":1,"45":1,"60":1,"75":1,"77":1,"113":1,"117":1},"1":{"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"10":1,"11":1,"20":1,"21":1,"46":1,"47":1,"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1,"114":1,"115":1,"116":1,"117":1,"118":1},"2":{"0":6,"2":4,"3":2,"4":1,"5":6,"6":3,"7":2,"8":3,"11":1,"12":2,"13":1,"14":3,"15":1,"16":3,"19":2,"21":3,"22":1,"24":7,"25":1,"28":4,"30":2,"32":1,"33":6,"44":6,"45":2,"46":2,"49":1,"52":2,"53":2,"54":1,"55":2,"58":2,"59":1,"61":4,"67":1,"71":2,"73":1,"75":2,"76":1,"77":10,"114":1,"115":2,"124":1}}],["r1已经在多个基准测试中超越了",{"2":{"0":1}}],["r1蒸馏模型",{"0":{"0":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1},"2":{"9":1}}],["但现在继续自己解决问题",{"2":{"77":1}}],["但并没有产生可读的输出",{"2":{"77":1}}],["但像这里使用的客观奖励意味着更干净的数据",{"2":{"75":1}}],["但在任何形式的监督微调之前",{"2":{"72":1}}],["但基准测试通常不能代表真实世界的任务",{"2":{"59":1}}],["但它们将相当熟练地掌握语言结构",{"2":{"72":1}}],["但它们可能仍然不适合你的特定工作量",{"2":{"59":1}}],["但它可以进行一些推理",{"2":{"28":1}}],["但蒸馏模型在各种基准测试中都表现出色",{"2":{"58":1}}],["但其庞大的规模和计算需求可能会成为实际应用的瓶颈",{"2":{"55":1}}],["但使用正确的工具",{"2":{"44":1}}],["但保留了",{"2":{"33":1}}],["但奖励系统现在还考虑",{"2":{"32":1}}],["但要真正使其成为顶级的人工智能助手",{"2":{"32":1}}],["但是其实还需要增加",{"2":{"156":1}}],["但是在服务器上一般必须通过代理实现",{"2":{"144":1}}],["但是不要尝试执行ollama",{"2":{"128":1}}],["但是很多朋友可能还想想本地部署",{"2":{"128":1}}],["但是考虑到向量库一般不能轻易改变",{"2":{"99":1}}],["但是",{"2":{"30":1,"61":1,"133":1}}],["但用英语呈现了其有缺陷的推理",{"2":{"30":1}}],["但这是结局吗",{"2":{"78":1}}],["但这一阶段真正的升级是奖励系统",{"2":{"30":1}}],["但这不仅仅是一个简单的训练课程",{"2":{"14":1}}],["但为了真正提高其推理能力",{"2":{"30":1}}],["但他们也注意到",{"2":{"24":1}}],["但他们想让它成为推理超级明星",{"2":{"14":1}}],["但缺少",{"2":{"23":1}}],["但我们假设它应该以推理为重点",{"2":{"23":1}}],["但我们会将其重写为更简单的形式",{"2":{"18":1}}],["但",{"2":{"21":1,"77":1}}],["但让我们放大它",{"2":{"18":1}}],["但变化率有限",{"2":{"18":1}}],["但传统的",{"2":{"17":1}}],["但由于从",{"2":{"7":1}}],["但不包括额外的强化学习",{"2":{"4":1}}],["但仍然需要较高的推理性能",{"2":{"3":1}}],["sky",{"2":{"129":1}}],["sys",{"2":{"104":1}}],["shellollama",{"2":{"148":1}}],["shellcurl",{"2":{"129":1}}],["shellcd",{"2":{"101":1,"102":1}}],["show",{"2":{"27":1}}],["sql",{"2":{"120":1}}],["sql脚本并导入表结构",{"2":{"98":1}}],["square",{"2":{"26":2}}],["sa",{"2":{"68":1}}],["sample=true",{"2":{"67":1}}],["save",{"2":{"52":3,"64":1,"65":2,"66":2}}],["scattering",{"2":{"129":1}}],["scaling",{"2":{"63":1}}],["scripts",{"2":{"70":1}}],["scheduler",{"2":{"64":1}}],["springboot前后端分离应用开发的同学",{"2":{"69":1}}],["springboot",{"2":{"68":1}}],["split",{"2":{"61":2}}],["speed",{"2":{"26":2,"145":1}}],["special",{"2":{"26":7,"27":2,"28":3,"29":1,"62":2}}],["sides",{"2":{"61":1}}],["size=2",{"2":{"64":2}}],["size=0",{"2":{"61":1}}],["size",{"2":{"11":1}}],["subtract",{"2":{"61":1}}],["summary",{"2":{"26":3,"27":1,"28":1,"29":1}}],["sumof",{"2":{"18":1}}],["sdk",{"2":{"36":1,"40":1}}],["services",{"2":{"150":1}}],["server和client两端的接口",{"2":{"104":1}}],["serve",{"2":{"11":1}}],["secret",{"2":{"145":1}}],["select中输入并回车即可",{"2":{"130":1}}],["select",{"2":{"110":1}}],["search",{"2":{"99":1,"128":1}}],["search等rag插件",{"2":{"36":1}}],["set",{"2":{"91":6}}],["seq",{"2":{"49":3,"50":1}}],["stylelint",{"2":{"70":1}}],["strategy=",{"2":{"64":3}}],["stopping",{"2":{"47":1}}],["start",{"2":{"65":1,"151":1}}],["star",{"0":{"41":1}}],["staystable",{"2":{"18":2}}],["staystablepart",{"2":{"18":2}}],["steps=50",{"2":{"64":1}}],["steps=4",{"2":{"64":1}}],["steps",{"2":{"64":1}}],["step",{"2":{"27":5,"28":2}}],["s",{"2":{"26":1,"67":1}}],["smallerof",{"2":{"18":1}}],["softmax",{"2":{"57":1}}],["so",{"2":{"26":1}}],["solve",{"2":{"27":2,"28":1,"50":1,"61":1}}],["solves",{"2":{"22":2}}],["solution",{"2":{"26":3}}],["solutions",{"2":{"26":1}}],["sonnet",{"2":{"6":1}}],["sota",{"2":{"0":2}}],["sfttrainer",{"2":{"65":3}}],["sft",{"2":{"4":1,"28":1,"29":4,"30":2,"31":1,"32":1,"33":1}}],["和模型的参数大小有关",{"2":{"149":1}}],["和内存资源的高端",{"2":{"47":1}}],["和偏好对",{"2":{"32":1}}],["和推理的可读性",{"2":{"31":1}}],["和专家系统用于复杂的问题",{"2":{"15":1}}],["和",{"2":{"4":1,"5":1,"6":1,"21":1,"22":3,"23":4,"30":1,"31":1,"44":4,"47":1,"54":1,"58":1,"62":1,"96":1}}],["例如我们想要在本地部署最新的llama3",{"2":{"148":1}}],["例如openai官方key就是在https",{"2":{"143":1}}],["例如阿里云的文档中",{"2":{"133":1}}],["例如pgvector",{"2":{"84":1}}],["例如监督微调和强化学习步骤",{"2":{"77":1}}],["例如食物",{"2":{"74":1}}],["例如它回答了一个流畅的句子但提供了不准确或不相关的答案的情况",{"2":{"72":1}}],["例如开放式推理任务",{"2":{"57":1}}],["例如",{"2":{"4":1,"6":1,"8":2,"18":2,"22":2,"23":1,"24":1,"26":1,"28":1,"30":1,"33":1,"56":1,"59":2,"61":1,"72":1,"77":2,"78":1}}],["8k",{"2":{"145":1}}],["8+",{"2":{"48":1}}],["8",{"0":{"23":1,"54":1,"87":1,"135":1,"156":1},"2":{"26":2,"92":1}}],["800k",{"2":{"33":2,"58":1}}],["800",{"2":{"4":1}}],["8b",{"2":{"0":1,"5":1,"49":1,"53":2,"115":2}}],["我使用的16",{"2":{"148":1}}],["我这里提供docker",{"2":{"93":1}}],["我认为不是",{"2":{"78":1}}],["我想在本博客中谈到的主要区别是奖励的定义方式",{"2":{"75":1}}],["我想他们一定是注意到普通人无法使用",{"2":{"3":1}}],["我将在这里简要解释这个想法",{"2":{"73":1}}],["我注意到",{"2":{"71":1}}],["我的一位读者在",{"2":{"71":1}}],["我写了一篇文章",{"2":{"71":1}}],["我们准备如下这个txt文档",{"2":{"134":1}}],["我们就可以重新导入文档进行向量化了",{"2":{"133":1}}],["我们找到排名第一的embedding模型",{"2":{"128":1}}],["我们先测试chat基础功能",{"2":{"125":1}}],["我们可能会训练它拒绝回答任何有害的问题",{"2":{"77":1}}],["我们可以直接通过命令行对话模型",{"2":{"148":1}}],["我们可以在控制台看到如下打印日志",{"2":{"139":1}}],["我们可以通过ollama",{"2":{"128":1}}],["我们可以高效地以",{"2":{"49":1}}],["我们可以计算出平均结果",{"2":{"18":1}}],["我们可以称之为",{"2":{"18":1}}],["我们引入了这些标记",{"2":{"62":1}}],["我们成功地在消费级",{"2":{"54":1}}],["我们获得了",{"2":{"32":1}}],["我们拒绝低于标准的样本",{"2":{"31":1}}],["我们会将这些结合起来",{"2":{"30":1}}],["我们希望推理和答案也是用英语",{"2":{"30":1}}],["我们希望你产生此目标输出",{"2":{"29":1}}],["我们采用",{"2":{"30":1}}],["我们告诉模型",{"2":{"29":1}}],["我们都会创建一个这样的对",{"2":{"29":1}}],["我们需要将冷启动数据格式化为输入",{"2":{"29":1}}],["我们向模型展示了许多良好推理的例子",{"2":{"29":1}}],["我们使用奖励值计算优势",{"2":{"23":1}}],["我们使用此模板为其提供提示",{"2":{"22":1}}],["我们假设目标语言是英语",{"2":{"30":1}}],["我们假设",{"2":{"23":1}}],["我们期望模型生成符合模板的输出",{"2":{"22":1}}],["我们在此提供一个问题和一个结构化的推理示例",{"2":{"29":1}}],["我们在",{"2":{"22":1}}],["我们的前提是仍用本地的embedding模型",{"2":{"133":1}}],["我们的目标是相应的结构良好的推理和答案",{"2":{"29":1}}],["我们的",{"2":{"20":1}}],["我们减去",{"2":{"18":1}}],["我们得出平均结果",{"2":{"18":1}}],["我们提出一个包含各种问题的模型",{"2":{"18":1}}],["我们将从",{"2":{"75":1}}],["我们将在此博客中重点介绍",{"2":{"71":1}}],["我们将在整个博客中使用字符串",{"2":{"13":1}}],["我们将使用",{"2":{"61":1}}],["我们将使用手绘流程图和简单的计算来帮助从头开始澄清deeoseek",{"2":{"13":2}}],["我们将介绍如何使用",{"2":{"55":1}}],["我们将介绍如何使用lora等技术将",{"2":{"55":1}}],["我们将介绍他们如何将",{"2":{"24":1}}],["我们将逐步指导你在消费级",{"2":{"44":2}}],["我们将讨论这个带有奖励模型的",{"2":{"16":1}}],["我们将深入研究6",{"2":{"0":1}}],["我们将深入研究deepseek",{"2":{"0":1}}],["我所说的起点是指它已经创建了",{"2":{"16":1}}],["我建议你尝试精简模型",{"2":{"12":1}}],["蒸馏后的",{"2":{"67":1}}],["蒸馏后的响应引入了一种更详细和结构化的方法",{"2":{"67":1}}],["蒸馏后的推理",{"2":{"67":1}}],["蒸馏后的模型旨在保留",{"2":{"3":1}}],["蒸馏前的",{"2":{"67":1}}],["蒸馏前的推理",{"2":{"67":1}}],["蒸馏你自己的模型可以让你针对确切的资源限制进行优化",{"2":{"59":1}}],["蒸馏类型",{"0":{"57":1}}],["蒸馏是一种机器学习技术",{"2":{"56":1}}],["蒸馏deepseek",{"0":{"55":1},"1":{"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1}}],["蒸馏",{"0":{"33":1}}],["蒸馏过程的工作原理如下",{"2":{"33":1}}],["蒸馏过程涉及对推理数据的监督微调",{"2":{"4":1}}],["蒸馏过程",{"0":{"4":1}}],["蒸馏的目的是让像",{"2":{"3":1}}],["蒸馏的目的",{"0":{"3":1}}],["蒸馏模型弥合了高性能和效率之间的差距",{"2":{"12":1}}],["蒸馏模型仍保留了强大的推理能力",{"2":{"7":1}}],["蒸馏模型比原始",{"2":{"7":1}}],["蒸馏模型的优势",{"0":{"7":1}}],["蒸馏模型的性能",{"0":{"6":1}}],["蒸馏模型在推理基准上取得了令人印象深刻的结果",{"2":{"6":1}}],["蒸馏模型变体",{"0":{"5":1}}],["蒸馏模型是通过使用",{"2":{"4":1}}],["蒸馏模型是较大的",{"2":{"2":1}}],["蒸馏模型",{"0":{"2":1,"9":1},"1":{"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"10":1,"11":1},"2":{"33":1}}],["因为run命令是针对chat模型的",{"2":{"128":1}}],["因为他是非标准的数据格式",{"2":{"125":1}}],["因为我们在langchat配置的",{"2":{"133":1}}],["因为我们使用的ollama部署的deepseek",{"2":{"124":1}}],["因为我使用的mac",{"2":{"122":1}}],["因为作者是16g笔记本",{"2":{"117":1}}],["因为都是阉割版的小参数模型",{"2":{"115":1}}],["因为都是阉割版的",{"2":{"114":1}}],["因为llm大模型的配置是在前端动态配置的",{"2":{"99":1}}],["因为答案是错误的",{"2":{"30":1}}],["因为",{"2":{"28":1}}],["因为它确保我们可以使用",{"2":{"75":1}}],["因为它们忽略了有助于使它们更适合生产的后续步骤",{"2":{"72":1}}],["因为它直接从一组动作的结果中找出基线",{"2":{"17":1}}],["因为它会动态地将每个请求定向到最合适的专家组件以进行高效处理",{"2":{"15":1}}],["因为它的规模太大",{"2":{"3":1}}],["因为原始",{"2":{"12":1}}],["因为这个模型已经在多个基准测试中超越了",{"2":{"0":1}}],["因此仅在langchat前端修改是无效的",{"2":{"127":1}}],["因此必须使用ollama配置",{"2":{"124":1}}],["因此不需要手动创建数据库",{"2":{"120":1}}],["因此不需要在配置文件中定义了",{"2":{"99":1}}],["因此llm能够在最小的样本数据中分析出来上下文的含义并做解答",{"2":{"110":1}}],["因此langchat项目中存在两台用户体系",{"2":{"104":1}}],["因此vectorstore的配置仍放在配置文件中",{"2":{"99":1}}],["因此观察到奖励",{"2":{"75":1}}],["因此概率显然是零",{"2":{"71":1}}],["因此它获得的语言一致性奖励为",{"2":{"30":1}}],["因此数据干净可靠",{"2":{"28":1}}],["因此",{"2":{"14":1,"17":2,"23":1,"25":1,"28":1,"59":1,"61":1,"75":1}}],["因此需要蒸馏模型",{"2":{"2":1}}],["因此无法在消费级设备上运行",{"2":{"2":1}}],["个",{"2":{"76":1}}],["个模型的一致预测",{"2":{"76":1}}],["个样本直接微调开源模型",{"2":{"58":1}}],["个样本进行微调",{"2":{"33":1}}],["个人可以免费是接入使用",{"2":{"38":1}}],["个推理样本",{"2":{"33":1}}],["个推理数据样本对较小的基础模型",{"2":{"4":1}}],["个高质量推理样本",{"2":{"31":1}}],["个输出",{"2":{"23":1}}],["个参数",{"2":{"2":1}}],["个蒸馏模型",{"2":{"0":2}}],["由于作者没有azure",{"2":{"150":1}}],["由于作者精力有限",{"2":{"37":1}}],["由于本项目使用了最新的技术栈",{"2":{"92":1}}],["由于我们通常希望",{"2":{"77":1}}],["由于假设推理",{"2":{"30":1}}],["由于",{"2":{"2":1,"75":1}}],["通过官方一行命令即可在本地下载并启动一个模型",{"2":{"148":1}}],["通过查询某个关键词",{"2":{"110":1}}],["通过查看许多问题及其各自的答案组中的这些答案",{"2":{"18":1}}],["通过反复试验",{"2":{"77":1}}],["通过",{"2":{"75":1}}],["通过冻结基础模型并仅训练小型适配器层来减少内存使用量",{"2":{"63":1}}],["通过蒸馏自己的模型",{"2":{"59":1}}],["通过对齐两个模型的隐藏表示",{"2":{"57":1}}],["通过利用",{"2":{"54":1}}],["通过微调",{"2":{"46":1}}],["通过选择较小的值",{"2":{"18":1}}],["通过评估不同问题中的这个组",{"2":{"18":1}}],["通过将每个答案与其组中其他答案的平均质量进行比较来计算每个答案的",{"2":{"17":1}}],["通过称为精炼的过程创建",{"2":{"2":1}}],["通常会将得到的最终答案框起来",{"2":{"75":1}}],["通常可以匹敌甚至超越更大模型的能力",{"2":{"58":1}}],["通常是旧模型",{"2":{"18":1}}],["通常优于",{"2":{"6":1}}],["通常称为教师模型",{"2":{"1":1}}],["更快的响应速度就必须配置更高参数的列表",{"2":{"149":1}}],["更快且具有良好推理能力的模型",{"2":{"33":1}}],["更抽象的特征",{"2":{"57":1}}],["更易于访问的",{"2":{"54":1}}],["更具成本效益的训练",{"2":{"44":1}}],["更多特性",{"2":{"36":1}}],["更多支持",{"2":{"35":1}}],["更结构化",{"2":{"28":1}}],["更新根据以下内容调整模型权重",{"2":{"23":1}}],["更有效的小型模型方法",{"2":{"8":1}}],["更小",{"2":{"7":1}}],["更高效的模型",{"2":{"55":1}}],["更高效的模型所利用",{"2":{"3":1}}],["更高效的版本",{"2":{"2":1}}],["更强大的模型",{"2":{"2":1}}],["更简单的模型",{"2":{"1":1}}],["2x",{"2":{"61":2}}],["250k",{"2":{"61":2}}],["2501",{"2":{"58":1}}],["21",{"2":{"40":1}}],["27",{"2":{"40":1}}],["2048",{"2":{"49":1}}],["20",{"2":{"23":2,"30":2,"31":2,"53":1}}],["2024b",{"2":{"58":1}}],["2024",{"2":{"6":3,"24":1,"38":1,"40":6,"58":1}}],["2+3",{"2":{"22":1}}],["2",{"0":{"2":1,"3":1,"4":2,"5":1,"6":1,"7":1,"8":1,"11":1,"15":1,"21":1,"27":1,"47":1,"48":1,"57":1,"62":1,"73":1,"74":1,"75":2,"81":1,"117":1,"121":1,"128":1},"1":{"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"74":1,"75":1},"2":{"11":1,"13":1,"18":2,"19":1,"22":4,"23":3,"26":8,"27":6,"28":4,"29":1,"30":9,"31":3,"32":3,"44":1,"50":2,"61":1,"62":1,"63":1}}],["中学到了很多东西",{"2":{"77":1}}],["中已经存在的",{"2":{"73":1}}],["中插入数学问题",{"2":{"22":1}}],["中",{"2":{"21":2,"55":2,"72":1,"75":1}}],["中的实际下一个标记进行比较",{"2":{"29":1}}],["中的每个答案进行计算",{"2":{"18":1}}],["中的模型蒸馏是一种用于将知识从大型复杂模型",{"2":{"1":1}}],["中部署模型特别有用",{"2":{"1":1}}],["这两者不是一个概念",{"2":{"114":1}}],["这和sql的",{"2":{"110":1}}],["这里说的是如果第三方代理使用openai接口格式转发不同模型供应商接口格式的情况",{"2":{"160":1}}],["这里的baseurl必须填写上述地址",{"2":{"149":1}}],["这里进需要关联我们刚才设置的deepseek",{"2":{"136":1}}],["这里是embedding模型",{"2":{"128":1}}],["这里教大家",{"2":{"128":1}}],["这里我只推荐pgvector",{"2":{"122":1}}],["这里会根据你的操作系统下载对应的安装包",{"2":{"116":1}}],["这里仅介绍使用ollama部署deepseek",{"2":{"113":1}}],["这里作者使用最新版本的idea演示如何本地启动项目",{"2":{"94":1}}],["这里不再考虑支持",{"2":{"92":1}}],["这样只需要配置apikey即可",{"2":{"128":1}}],["这样想",{"2":{"77":1}}],["这样的大型",{"2":{"44":1}}],["这样的大型模型的推理能力能够被更小",{"2":{"3":1}}],["这样的输出",{"2":{"31":1}}],["这迫使",{"2":{"75":1}}],["这使它能够确定应该采取什么行动来获得最大奖励",{"2":{"74":1}}],["这使得",{"2":{"77":1}}],["这使得更快",{"2":{"54":1}}],["这使得该过程更高效",{"2":{"4":1}}],["这使得较小的模型能够在推理任务上实现具有竞争力的性能",{"2":{"2":1}}],["这与",{"2":{"73":1}}],["这种情况需要检查后台日志",{"2":{"158":1}}],["这种问题实在不该出现",{"2":{"154":1}}],["这种分块可以在后期进行更有效的处理和分析",{"2":{"82":1}}],["这种方法保留了更多关于教师信心水平和决策过程的信息",{"2":{"57":1}}],["这种方法可以应用于广泛的任务",{"2":{"57":1}}],["这种结构化输出对于研究人员以后窥视模型的推理步骤非常重要",{"2":{"22":1}}],["这实际上是受到人类教育的启发",{"2":{"56":1}}],["这会训练模型",{"2":{"29":1}}],["这表明使用强化学习",{"2":{"24":1}}],["这确保在下一次迭代中",{"2":{"23":1}}],["这可能会破坏训练的稳定性",{"2":{"23":1}}],["这意味着它们",{"2":{"78":1}}],["这意味着它会为放入其环境中的给定问题生成答案和一些推理",{"2":{"16":1}}],["这意味着每个问题都会询问我们的",{"2":{"76":1}}],["这意味着应该阻止它们",{"2":{"23":1}}],["这意味着应该鼓励它们",{"2":{"23":1}}],["这无需单独的批评模型即可完成",{"2":{"17":1}}],["这节省了大量计算并使事情变得更有效率",{"2":{"17":1}}],["这基本上使计算成本翻倍",{"2":{"17":1}}],["这个看情况配置",{"2":{"99":1}}],["这个新的",{"2":{"78":1}}],["这个系统带你全面了解springboot3和vue3的前后端开发流程",{"2":{"68":1}}],["这个想法最早是在",{"2":{"56":1}}],["这个想法很简单",{"2":{"30":1}}],["这个想法是让模型通过示例学习并开始模仿这种分步推理风格",{"2":{"26":1}}],["这个过程很有帮助",{"2":{"75":1}}],["这个过程循环往复",{"2":{"29":1}}],["这个过程重复进行",{"2":{"17":1}}],["这个更新的模型成为新的",{"2":{"17":1}}],["这个批评家通常和参与者本身一样大和复杂",{"2":{"17":1}}],["这个反馈信号返回到",{"2":{"16":1}}],["这个奖励就像反馈",{"2":{"16":1}}],["这个路由器使",{"2":{"15":1}}],["这是典型的",{"2":{"75":1}}],["这是他们第二次使用它",{"2":{"75":1}}],["这是他们将最初的",{"2":{"24":1}}],["这是拒绝采样",{"2":{"31":1}}],["这是我们希望模型学习生成的理想输出",{"2":{"29":1}}],["这是我们输入到模型中的内容",{"2":{"29":1}}],["这是为了促进更仔细和周到的问题解决",{"2":{"27":1}}],["这是为了防止新模型发生太大的变化",{"2":{"18":1}}],["这是对给出良好答案的模型进行奖励的部分",{"2":{"18":1}}],["这是一个在创建最终版本之前存在一些错误的初始版本",{"2":{"16":1}}],["这是超简短的版本",{"2":{"14":1}}],["这些数据最终会存储到vectorstore向量数据库中",{"2":{"109":1}}],["这些文档将作为rag系统的基础输入数据",{"2":{"80":1}}],["这些",{"2":{"78":1}}],["这些步骤不仅优先考虑推理",{"2":{"77":1}}],["这些模型通常不适用于生产用例",{"2":{"72":1}}],["这些标记帮助模型学习生成结构化的",{"2":{"62":1}}],["这些示例涵盖了数学推理",{"2":{"61":1}}],["这些通常由根据人类偏好训练的单独奖励模型进行评估",{"2":{"32":1}}],["这些问题都不会出现",{"2":{"153":1}}],["这些问题",{"2":{"24":1}}],["这些答案形成一个组",{"2":{"18":1}}],["这些响应被组合成清晰",{"2":{"15":1}}],["这些包括",{"2":{"5":1}}],["这就是冷启动",{"2":{"77":1}}],["这就是强化学习在所有场景中的使命",{"2":{"32":1}}],["这就是",{"2":{"14":1}}],["这对于为复杂问题生成准确的响应非常有帮助",{"2":{"67":1}}],["这对于有限的计算资源特别有用",{"2":{"3":1}}],["这对于在资源受限的环境",{"2":{"1":1}}],["这看起来像是一个重大版本",{"2":{"0":1}}],["该问题将用于从矢量数据库中检索最相关的信息",{"2":{"85":1}}],["该数据库允许系统根据语义相似性有效地检索相关信息",{"2":{"84":1}}],["该模板有意简单且结构集中",{"2":{"24":1}}],["该模板充当蓝图",{"2":{"22":1}}],["该模型将块转换为向量",{"2":{"83":1}}],["该模型会提取文本",{"2":{"81":1}}],["该模型会产生多个答案",{"2":{"18":1}}],["该模型在几个推理基准上的表现与",{"2":{"76":1}}],["该模型因生成思考标记而获得奖励",{"2":{"75":1}}],["该模型的推理能力可与",{"2":{"71":2}}],["该模型为我们的文本输入生成以下四个输出",{"2":{"23":1}}],["该模型保留了较大模型的大部分性能",{"2":{"1":1}}],["该系统通过查找相关信息快速构建上下文",{"2":{"15":1}}],["该团队还发布了许多其他模型",{"2":{"0":1}}],["的数据库",{"2":{"133":1}}],["的数据集库加载数据集",{"2":{"50":1}}],["的主要原因",{"2":{"92":1}}],["的一个核心区别是冷启动",{"2":{"77":1}}],["的一小部分",{"2":{"71":2}}],["的代码输出可以简单地传递到编译器中",{"2":{"75":1}}],["的特殊奖励函数确定",{"2":{"75":1}}],["的论文",{"2":{"75":1}}],["的简化版本",{"2":{"75":1}}],["的强化学习策略",{"0":{"75":1}}],["的强化学习训练过程",{"0":{"23":1}}],["的方法",{"0":{"73":1},"1":{"74":1,"75":1},"2":{"72":1}}],["的不同阶段",{"2":{"71":1}}],["的情况下独立使用",{"2":{"66":1}}],["的训练",{"2":{"65":1}}],["的聊天模板格式",{"2":{"61":1}}],["的分步推理",{"2":{"61":1}}],["的行为就是从这个学习过程中发展而来的",{"2":{"78":1}}],["的行为",{"2":{"56":1}}],["的",{"2":{"55":2,"92":1}}],["的推理能力",{"2":{"76":1}}],["的推理能力蒸馏到较小的模型",{"2":{"55":2}}],["的推理过程透明",{"2":{"45":1}}],["的精简版本在",{"2":{"44":1}}],["的最新",{"2":{"44":1}}],["的大部分推理能力",{"2":{"33":1}}],["的蒸馏模型",{"0":{"58":1}}],["的蒸馏",{"2":{"33":1}}],["的总奖励为",{"2":{"30":1}}],["的总奖励变为",{"2":{"30":1}}],["的语言一致性奖励",{"2":{"30":1}}],["的输出代码",{"2":{"75":1}}],["的输出用作学生模型的目标",{"2":{"33":1}}],["的输出",{"2":{"28":1,"71":1}}],["的两个主要原因",{"2":{"24":1}}],["的两个主要问题",{"0":{"24":1}}],["的研究人员表示",{"2":{"24":1}}],["的问题在于",{"2":{"77":1}}],["的问题",{"2":{"24":1}}],["的概率是多少",{"2":{"67":1}}],["的概率",{"2":{"23":2}}],["的神经奖励模型",{"2":{"21":1}}],["的奖励建模是如何工作的",{"2":{"19":1}}],["的奖励建模",{"0":{"19":1},"1":{"20":1,"21":1}}],["的视觉表示",{"2":{"18":1}}],["的差异",{"2":{"18":1}}],["的小值决定",{"2":{"18":1}}],["的修改版本",{"2":{"18":1}}],["的目标函数有两个目标",{"2":{"18":1}}],["的目标函数",{"0":{"18":1}}],["的做法不同",{"2":{"17":1}}],["的东西来帮助主要决策部分",{"2":{"17":1}}],["的计算成本极高",{"2":{"17":1}}],["的思考方式",{"2":{"16":1}}],["的工作原理以及它为什么被称为",{"2":{"15":1}}],["的知识和推理能力转移到较小的模型中",{"2":{"2":1}}],["的技术",{"2":{"1":1}}],["的原始版本",{"2":{"0":1}}],["机器学习",{"2":{"1":1}}],["什么是蒸馏",{"0":{"1":1,"56":1}}],["7",{"0":{"22":1,"53":1,"67":1,"86":1,"134":1},"2":{"23":1,"40":4,"67":3,"115":2}}],["70",{"2":{"6":1}}],["70b",{"2":{"0":1,"5":1,"6":1,"61":1}}],["72",{"2":{"6":1}}],["7b",{"2":{"0":1,"5":1,"6":1,"115":1}}],["1模型",{"2":{"148":1}}],["17",{"2":{"92":1}}],["18",{"2":{"91":1}}],["1+1",{"2":{"53":1}}],["19",{"2":{"40":1}}],["16gb",{"2":{"115":1}}],["16",{"2":{"40":1,"53":1,"76":2}}],["1536等等",{"2":{"133":1}}],["15+基础环境",{"2":{"122":1}}],["15",{"0":{"33":1},"2":{"40":1,"61":1}}],["13",{"0":{"31":1}}],["11434",{"2":{"114":2,"118":1,"124":1,"129":2,"130":1,"149":2}}],["11",{"0":{"29":1},"2":{"40":2}}],["1024向量纬度",{"2":{"133":1}}],["1024",{"0":{"133":1},"2":{"133":1}}],["1002",{"2":{"102":1}}],["100",{"2":{"30":2}}],["10",{"0":{"25":1,"26":1,"27":1,"28":1,"89":1},"1":{"26":1,"27":1,"28":1},"2":{"61":2,"75":1}}],["127",{"2":{"114":1,"118":1,"124":1,"149":2}}],["12948v1",{"2":{"58":1}}],["120",{"2":{"26":2}}],["12",{"0":{"30":1},"2":{"22":4,"23":2,"26":3,"27":2,"28":3,"30":2}}],["14",{"0":{"32":1},"2":{"20":2,"22":5,"23":3,"26":2,"27":2,"28":3,"29":1,"30":2,"31":2}}],["14b以上模型",{"2":{"115":1}}],["14b",{"2":{"0":1,"5":1,"33":1}}],["1",{"0":{"1":1,"3":1,"10":1,"14":1,"20":1,"26":1,"45":1,"46":2,"47":1,"56":1,"61":1,"72":1,"74":1,"80":1,"116":1,"120":1,"127":1},"1":{"46":1,"47":1},"2":{"0":1,"5":1,"6":5,"18":3,"23":10,"27":2,"28":1,"29":1,"30":11,"33":1,"61":1,"93":1,"114":1,"115":2,"118":1,"124":1,"148":1,"149":2}}],["dashscope",{"2":{"146":1}}],["datacollatorforlanguagemodeling",{"2":{"65":2}}],["data",{"2":{"50":3,"65":4}}],["dataset=formatted",{"2":{"65":2}}],["dataset=tokenized",{"2":{"51":2}}],["dataset",{"2":{"50":5,"51":2,"61":12,"65":2}}],["datasets",{"2":{"48":1,"50":1,"60":1,"61":1}}],["db",{"2":{"110":1}}],["dtype=torch",{"2":{"62":1,"67":1}}],["demo",{"2":{"99":1}}],["dev为是否开启演示环境",{"2":{"99":1}}],["dev",{"2":{"93":1,"99":2,"101":1,"102":1,"155":1}}],["device",{"2":{"62":1,"64":2,"67":2}}],["defining",{"0":{"155":1}}],["def",{"2":{"50":1,"61":1}}],["describes",{"2":{"50":1}}],["deepseekmath",{"2":{"75":1}}],["deepseek",{"0":{"0":1,"2":1,"9":1,"13":1,"15":1,"16":1,"19":1,"23":1,"44":1,"45":1,"58":1,"60":1,"71":1,"73":1,"75":1,"77":1,"115":1},"1":{"1":1,"2":1,"3":2,"4":2,"5":2,"6":2,"7":2,"8":2,"9":1,"10":2,"11":2,"12":1,"14":1,"15":1,"16":1,"17":1,"18":1,"19":1,"20":2,"21":2,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"45":1,"46":2,"47":2,"48":1,"49":1,"50":1,"51":1,"52":1,"53":1,"54":1,"61":1,"62":1,"63":1,"64":1,"65":1,"66":1,"67":1,"72":1,"73":1,"74":2,"75":2,"76":1,"77":1,"78":1},"2":{"0":9,"2":4,"3":3,"4":1,"5":6,"6":3,"7":2,"8":3,"11":2,"12":1,"13":2,"14":5,"15":5,"16":7,"17":1,"20":1,"21":3,"22":3,"23":3,"24":3,"25":2,"26":1,"29":2,"30":3,"31":2,"32":2,"33":6,"34":1,"44":6,"45":3,"46":2,"49":1,"52":2,"53":2,"54":1,"55":2,"58":4,"59":1,"61":4,"64":1,"65":2,"66":2,"67":3,"71":8,"72":1,"73":1,"74":1,"75":4,"76":2,"77":10,"112":1,"113":1,"114":1,"115":2,"124":1,"125":1}}],["d",{"2":{"47":1,"129":1}}],["dropout=0",{"2":{"51":1,"63":1}}],["dropout",{"2":{"47":1,"63":1}}],["downloads",{"2":{"122":1}}],["dockercompose一键部署脚本",{"2":{"141":1}}],["docker以及其他复杂的过程",{"2":{"114":1}}],["docker",{"2":{"70":1}}],["docs",{"2":{"34":1,"70":1,"151":1,"152":2}}],["document",{"0":{"34":1},"1":{"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1}}],["doing",{"2":{"28":1}}],["do",{"2":{"26":1,"67":1}}],["dice",{"2":{"67":1}}],["dir=",{"2":{"64":1}}],["divide",{"2":{"61":1}}],["distance",{"2":{"26":2}}],["distill",{"2":{"0":2,"5":6,"6":3,"8":1,"11":1,"49":1,"53":2,"67":1}}],["differencefromreferencemodel",{"2":{"18":1}}],["即可进行知识库问答了",{"2":{"137":1}}],["即可进入配置页面",{"2":{"107":1}}],["即可正常启动langchat",{"2":{"123":1}}],["即捕获文本语义的数字表示",{"2":{"83":1}}],["即使它们是由人类建造的",{"2":{"78":1}}],["即使它们的参数较少",{"2":{"3":1}}],["即使是那些",{"2":{"57":1}}],["即强化学习更新之前的",{"2":{"23":1}}],["即一种良好动作的参考点",{"2":{"17":1}}],["即",{"2":{"0":1,"2":1,"17":1,"22":2}}],["在如下页面配置你的应用",{"2":{"145":1}}],["在左侧点击不同的模型供应商配置即可",{"2":{"143":1}}],["在向量数据库中",{"2":{"134":1}}],["在上面配置好nomic",{"2":{"132":1}}],["在mysql中执行此脚本",{"2":{"120":1}}],["在docs",{"2":{"120":1}}],["在langchat中使用第三方代理配置模型",{"0":{"159":1},"1":{"160":1,"161":1}}],["在langchat中配置模型",{"0":{"142":1},"1":{"143":1,"144":1,"145":1,"146":1,"147":1,"148":1,"149":1,"150":1,"151":1,"152":1}}],["在langchat中配置知识库",{"0":{"106":1},"1":{"107":1,"108":1,"109":1,"110":1}}],["在langchat的聊天助手页面的右上角选择刚刚配置的ollama模型即可快速使用",{"2":{"149":1}}],["在langchat的切片管理页面可以轻松的查看到不同文档最终分割的切片数据集",{"2":{"109":1}}],["在langchat管理端修改",{"2":{"133":1}}],["在启动项目之前",{"2":{"94":1}}],["在运行项目之前",{"2":{"90":1}}],["在回答之前多",{"2":{"78":1}}],["在回答之前找出答案",{"2":{"75":1}}],["在计算准确率时将",{"2":{"76":1}}],["在美国数学邀请考试",{"2":{"76":1}}],["在生成输出时更好地推理",{"2":{"75":1}}],["在数据蒸馏中",{"2":{"57":1}}],["在本地一般我们会用科学上网实现",{"2":{"144":1}}],["在本博客中",{"2":{"55":2}}],["在本例中为",{"2":{"2":1}}],["在小型数据集上进行训练可能会导致模型记住响应",{"2":{"47":1}}],["在小型数据集上过度拟合",{"2":{"47":1}}],["在rbac权限体系的基础上",{"2":{"34":1}}],["在推理性能和一致性",{"2":{"32":1}}],["在推理基准测试中的表现优于",{"2":{"8":1}}],["在更新模型参数中",{"2":{"29":1}}],["在预测下一个标记中",{"2":{"29":1}}],["在下一节中",{"2":{"24":1}}],["在解决推理问题方面变得更加准确和有效",{"2":{"23":1}}],["在新策略与旧策略下生成输出的概率",{"2":{"23":1}}],["在一次训练迭代中",{"2":{"23":1}}],["在此过程中",{"2":{"18":1}}],["在接下来的部分中",{"2":{"16":1}}],["在这篇博文中",{"2":{"44":2}}],["在这篇文章中",{"2":{"0":2}}],["在这里",{"2":{"30":1}}],["在这个阶段",{"2":{"74":1,"77":1}}],["在这个",{"2":{"18":1}}],["在这种情况下",{"2":{"16":1,"59":1,"160":1}}],["在理解你的输入后",{"2":{"15":1}}],["在我们研究每个步骤的疯狂细节之前",{"2":{"14":1}}],["在介绍技术细节之前",{"2":{"14":1}}],["在",{"2":{"0":1,"6":5,"24":1,"32":1,"33":1,"57":1,"72":1,"92":1}}],["ov",{"2":{"122":1}}],["ocr",{"2":{"81":1}}],["ocr文本提取",{"0":{"81":1}}],["oss信息",{"2":{"121":1}}],["oss",{"2":{"70":1}}],["ops应用都是通过此端口和模型交互的",{"2":{"114":1}}],["ops",{"2":{"70":2}}],["optim=",{"2":{"64":1}}],["open",{"0":{"95":1}}],["openai接口格式",{"0":{"160":1}}],["openai接口默认是不可访问的",{"2":{"144":1}}],["openai账号",{"2":{"150":1}}],["openai官方只需要填写api",{"2":{"144":1}}],["openai",{"0":{"150":1},"2":{"0":2,"24":1,"34":1,"71":4,"76":1,"112":1,"143":1,"150":1}}],["operations",{"2":{"22":1,"26":1,"27":2,"28":1,"29":1}}],["o",{"2":{"63":1}}],["org",{"2":{"58":1,"91":2}}],["order",{"2":{"22":1,"26":1,"27":2,"28":1,"29":1}}],["output",{"2":{"50":2,"64":1,"67":2}}],["outlook",{"2":{"43":1,"103":1}}],["o4",{"2":{"23":4}}],["o3",{"2":{"23":4}}],["o2",{"2":{"23":4,"30":3}}],["of",{"2":{"22":1,"26":3,"27":2,"28":1,"29":1,"50":2,"63":1,"67":1,"129":1}}],["ollama默认会暴露一个http端口",{"2":{"149":1}}],["ollama的官网",{"2":{"148":1}}],["ollama的run启动模型后会暴露",{"2":{"114":1}}],["ollama的run命令执行后",{"2":{"114":1}}],["ollama简化了模型的部署方式",{"2":{"148":1}}],["ollama是一种本地模型部署方案",{"2":{"148":1}}],["ollama是安装模型最简单的方式",{"2":{"114":1}}],["ollama模型很小",{"2":{"128":1}}],["ollama官网地址",{"2":{"116":1}}],["ollama地址",{"2":{"115":1}}],["ollama客户端兼容全平台",{"2":{"114":1}}],["ollama",{"0":{"10":1},"2":{"34":1,"61":1,"112":1,"115":2,"116":1,"128":3,"148":1}}],["o1",{"2":{"0":2,"23":4,"30":4,"71":4,"76":1}}]],"serializationVersion":2}';export{e as default};
